#!/usr/bin/env python3

import sys
import shutil
import subprocess
import logging
import argparse
from datetime import datetime
from pathlib import Path
import time
import multiprocessing

'''
Sample Usage:

python autotune.py winograd 1286.mlir --tunepy-opt lhs-dims=bmk rhs-dims=bkn tile-dims=*mnk --devices 1 --num-candidates 64

'''


# Default values for num_candidates and devices, change it as needed
DEFAULT_NUM_CANDIDATES = 1024
DEFAULT_DEVICE_LIST = [0]
# GPU_LIST = ["GPU-32623464-6662-6132-6439-393336303539", "GPU-64393336-6231-3033-6630-653365353764", "GPU-39303930-3934-6363-3438-613361623536", "GPU-64656437-3233-6431-3763-303765373765", "GPU-32666166-3865-3732-3734-623364356137", "GPU-37353231-3735-3232-6131-393633373830"]

def abort(result):
    # usage exmaple: abort( run_command(...) ) for debug option
    if result.stderr:
        print(f"Command aborted, check log file")
        sys.exit(1)

def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Autotune script")

    # Required arguments
    parser.add_argument('mode', choices=['default', 'winograd'], help="Compilation mode")
    parser.add_argument('input_file', type=Path, help="Path to the input benchmark file (.mlir)")

    # General options
    parser.add_argument('--verbose', '-v', action='store_true', help="Enable verbose output to stdout")
    parser.add_argument('--num-candidates', type=int, default=DEFAULT_NUM_CANDIDATES, help=f"Number of candidates to be generated by tune.py (default: {DEFAULT_NUM_CANDIDATES})")
    
    # Device options
    parser.add_argument('--devices', type=int, nargs='+', default=DEFAULT_DEVICE_LIST, help="List of GPU indices (default: [0]). Usage example: --devices 0 2")
    
    # TODO: going to invoke tune.py feature directly in future, fix this argument parsing later
    parser.add_argument('--tunepy-opt', "-t", nargs='+', metavar='option', help="Extra options passed to tune.py (e.g., lhs-dims=bmk Xtune='--opt=val' Xtune='--opt2=val2')")

    return parser.parse_args()

def setup_logging(args: argparse.Namespace, log_dir: Path) -> Path:
    """Set up logging environment.

    Args:
        args (argparse.Namespace): Parsed command line arguments.
        log_dir (Path): The directory where logs are stored.

    Returns:
        Path: The path to the autotune.py log file
    """
    log_file_name = f"autotune_{args.mode}_{args.input_file.stem}.log"
    log_file = log_dir / log_file_name

    handlers = [logging.FileHandler(log_file)]
    if args.verbose:
        handlers.append(logging.StreamHandler())
        pass

    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers=handlers)

    
    logging.info(f"Input file: {args.input_file}")
    logging.info(f"Mode: {args.mode}")
    logging.info(f"Number of candidates: {args.num_candidates}")
    logging.info(f"Devices: {args.devices}")
    logging.info(f"Extra options for tune.py: {args.tunepy_opt}")
    logging.info(f"Device for Unet candidates: {args.devices[0]}") # Default use the first gpu from the user input --device list

    return log_file

def init_worker_id(queue: multiprocessing.Queue) -> None:
    """Assign a static GPU indice to current process as the Worker ID
    
    Args:
        queue (multiprocessing.Queue): The queue containing the worker IDs (GPU indcies).
    """
    global worker_id
    worker_id = queue.get()

def create_worker_id_queue(device_ids: list[int]) -> multiprocessing.Queue:
    """Create a queue of worker IDs from a list of device IDs.
    
    Args:
        device_ids (list[int]): List of device IDs.
        
    Returns:
        multiprocessing.Queue: A queue containing the worker IDs.
    """
    worker_id_queue = multiprocessing.Manager().Queue()
    for i in device_ids:
        worker_id_queue.put(i)
    return worker_id_queue

def run_command(args: argparse.Namespace, command: list[str], check: bool = True) -> subprocess.CompletedProcess:
    """Run a shell command and log the output.

    Args:
        args (argparse.Namespace): Parsed command line arguments.
        command (list): The command to run as a list of strings.
        check (bool, optional): Whether to check the command's exit status. Defaults to True.

    Returns:
        subprocess.CompletedProcess: The result of the command execution.
    """
    try:
        # Convert the command list to a command string for logging
        command_str = ' '.join(command)
        if args.verbose:
            print(command_str)
        result = subprocess.run(command, check=check, capture_output=True, text=True)
        if result.stdout:
            logging.info(result.stdout)
        if result.stderr:
            logging.error(result.stderr)
            print(f"[warning] error flag raised by: {command_str}")
        return result
    except subprocess.CalledProcessError as e:
        print(f"Command '{e.cmd}' returned non-zero exit status {e.returncode}.")
        print(e.output)
        
        logging.error(f"Command '{command_str}' returned non-zero exit status {e.returncode}.")
        logging.error(f"Command '{command_str}' failed with error: {e.stderr}")
        if check:
            raise

def generate_candidates(args: argparse.Namespace, base_dir: Path) -> tuple[list[Path], Path]:
    """Generate candidate files for tuning.

    Args:
        args (argparse.Namespace): Parsed command line arguments.
        base_dir (Path): The base directory for the tuning process.

    Returns:
        tuple[list[Path], Path]: A tuple containing a list of candidate files and the candidates directory.
    """
    try:
        shutil.copy("config_prolog.mlir", base_dir / "config_prolog.mlir")
        shutil.copy("config_epilog.mlir", base_dir / "config_epilog.mlir")
    except FileNotFoundError as e:
        logging.error(f"Configuration file not found: {e}")
        sys.exit(1)
    
    template_mlir = base_dir / "template.mlir"
    candidates_dir = base_dir / "candidates"

    shutil.copy(args.input_file, template_mlir)
    
    # TODO: change to invoke python function instead of calling shell command
    command = ["./tune.py", f"{template_mlir}", "-o", f"{candidates_dir}", "-l", f"{args.num_candidates}"]
    if args.tunepy_opt:
        flag_list = ['--' + opt for opt in args.tunepy_opt]
        command.extend(flag_list)

    run_command(args, command)

    candidates = sorted(candidates_dir.glob("*.mlir"))

    return candidates, candidates_dir

def compile_candidates(args: argparse.Namespace, candidates: list[Path], candidate_dir: Path) -> tuple[list[Path], Path]:
    """Compile candidate files.

    Args:
        args (argparse.Namespace): Parsed command line arguments.
        candidates (list[Path]): A list of candidate files to compile.
        candidate_dir (Path): The directory for the candidates.

    Returns:
        tuple[list[Path], Path]: A tuple containing a list of compiled files and the compiled files directory.
    """

    worker_id_queue = create_worker_id_queue(args.devices)
    worker_pool = multiprocessing.Pool(len(args.devices), init_worker_id, (worker_id_queue,))
    task_list = []

    for candidate in candidates:
        if "_config.mlir" not in candidate.name:
            command = ["./compile_candidate.sh", f"{args.mode}", f"{candidate}"]
            check=False
            # run_command(command, check)
            task_list.append((args, command, check))

    worker_pool.starmap(run_command, task_list)

    compiled_dir = candidate_dir / "compiled"
    compiled_files = sorted(compiled_dir.glob("*.vmfb"))

    return compiled_files, compiled_dir

def benchmark_top_candidates(args: argparse.Namespace, base_dir: Path, candidates_dir: Path, compiled_files: list[Path]) -> Path:
    """Benchmark the top candidate files.

    Args:
        base_dir (Path): The base directory for the tuning process.
        candidates_dir (Path): The directory containing candidate files.
        compiled_files (list[Path]): A list of compiled files to benchmark.

    Returns:
        Path: The path to the log file containing the best benchmark results.
    """
    benchmark_results = []
    for compiled_file in compiled_files:
        command = ["./benchmark_dispatch.sh", f"{compiled_file}"]
        command.extend([str(device) for device in args.devices])
        check = False
        result = run_command(args, command, check=check)
        benchmark_results.append(result.stdout)

    results_log = base_dir / "results.log"
    with results_log.open('w') as log_file:
        log_file.writelines(benchmark_results)
    
    best_results = []
    with results_log.open('r') as log_file:
        for line in log_file:
            if "failed" not in line:
                parts = line.split()
                best_results.append((parts[-1], f"{candidates_dir}/{parts[0]}.mlir", f"{candidates_dir}/configs/{parts[0]}_spec.mlir"))

    best_results = sorted(best_results, key=lambda x: x[0])[:20]
    best_log = base_dir / "best.log"
    with best_log.open('w') as log_file:
        for result in best_results:
            log_file.write(f"{result[0]}\t{result[1]}\t{result[2]}\n")
    
    return best_log

def compile_unet_candidates(args: argparse.Namespace, base_dir: Path, best_log: Path) -> list[str]:
    """Compile U-Net candidate files.

    Args:
        args (argparse.Namespace): Parsed command line arguments.
        base_dir (Path): The base directory for the tuning process.
        best_log (Path): The path to the log file containing the best benchmark results.

    Returns:
        list[str]: A list of U-Net candidate files.
    """

    with best_log.open('r') as log_file:
        for line in log_file:
            if '/0.mlir' not in line:
                # parts = line.split('\t')
                command = ["./compile_unet_candidate.sh", f"{args.mode}", f"{args.devices[0]}"] # Default use the first gpu from the user input --device list
                run_command(args, command)

    unet_candidates = ["unet_baseline.vmfb"] + list(base_dir.glob("*.vmfb")) + ["unet_baseline.vmfb"]

    return unet_candidates

def benchmark_unet(args: argparse.Namespace, unet_candidates: list[str]) -> None:
    """Benchmark U-Net candidate files.

    Args:
        args (argparse.Namespace): Parsed command line arguments.
        unet_candidates (list[str]): A list of U-Net candidate files to benchmark.
    """
    for unet_candidate in unet_candidates:
        command = ["./benchmark_unet_candidate.sh", f"{unet_candidate}", f"{args.devices[0]}"] # Default use the first gpu from the user input --device list
        run_command(args, command)
        time.sleep(10)


def main():
    args = parse_arguments()

    base_dir = Path(f"tuning_{datetime.now().strftime('%Y_%m_%d_%H_%M')}")
    base_dir.mkdir(parents=True, exist_ok=True)

    print("Setup logging\n")
    log_file_path = setup_logging(args, log_dir=base_dir)

    print("Gnerating candidates...")
    candidates, candidates_dir = generate_candidates(args, base_dir)
    print(f"Generated [{args.num_candidates}] candidates in {candidates_dir}\n")

    print("Compiling candidates...")
    compiled_files, compiled_dir = compile_candidates(args, candidates, candidates_dir)
    print(f"Compiled files in {compiled_dir}\n")

    print("Benchmarking top candidates...")
    best_log = benchmark_top_candidates(args, base_dir, candidates_dir, compiled_files)
    print("Top candidates selected\n")

    print("Compiling unet candidtes...")
    unet_candidates = compile_unet_candidates(args, base_dir, best_log)
    print("Unet candidtes compiled\n")

    print("Bnechmarking unet candidtes...")
    benchmark_unet(args, unet_candidates)
    print("Done\n")

    print("Check result in log file:")
    print(log_file_path)

if __name__ == "__main__":
    main()