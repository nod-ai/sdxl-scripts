module @compiled_vae {
  util.global private @__auto.post_quant_conv.weight = #stream.parameter.named<"model"::"post_quant_conv.weight"> : tensor<4x4x1x1xf16>
  util.global private @__auto.post_quant_conv.bias = #stream.parameter.named<"model"::"post_quant_conv.bias"> : tensor<4xf16>
  util.global private @__auto.decoder.conv_in.weight = #stream.parameter.named<"model"::"decoder.conv_in.weight"> : tensor<512x4x3x3xf16>
  util.global private @__auto.decoder.conv_in.bias = #stream.parameter.named<"model"::"decoder.conv_in.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.group_norm.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.group_norm.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_q.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_q.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_k.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_k.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_v.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_v.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_out.0.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_out.0.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv1.weight"> : tensor<256x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<256x512x1x1xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.upsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.upsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv1.weight"> : tensor<128x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv_shortcut.weight"> : tensor<128x256x1x1xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv_shortcut.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.conv_norm_out.bias = #stream.parameter.named<"model"::"decoder.conv_norm_out.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.conv_norm_out.weight = #stream.parameter.named<"model"::"decoder.conv_norm_out.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.conv_out.weight = #stream.parameter.named<"model"::"decoder.conv_out.weight"> : tensor<3x128x3x3xf16>
  util.global private @__auto.decoder.conv_out.bias = #stream.parameter.named<"model"::"decoder.conv_out.bias"> : tensor<3xf16>
  func.func @decode(%arg0: !torch.vtensor<[1,4,128,128],f16>) -> !torch.vtensor<[1,3,1024,1024],f16> attributes {iree.reflection = {input_dtypes = "['float16']", input_shapes = "[(1, 4, 128, 128)]", model_name = "vae_decode", output_dtypes = "['float32']", output_shapes = "[(3, 1024, 1024)]"}, torch.assume_strict_symbolic_shapes} {
    %float7.677540e00 = torch.constant.float 7.6775431861804221
    %0 = torch.aten.mul.Scalar %arg0, %float7.677540e00 : !torch.vtensor<[1,4,128,128],f16>, !torch.float -> !torch.vtensor<[1,4,128,128],f16>
    %__auto.post_quant_conv.weight = util.global.load @__auto.post_quant_conv.weight : tensor<4x4x1x1xf16>
    %1 = torch_c.from_builtin_tensor %__auto.post_quant_conv.weight : tensor<4x4x1x1xf16> -> !torch.vtensor<[4,4,1,1],f16>
    %__auto.post_quant_conv.bias = util.global.load @__auto.post_quant_conv.bias : tensor<4xf16>
    %2 = torch_c.from_builtin_tensor %__auto.post_quant_conv.bias : tensor<4xf16> -> !torch.vtensor<[4],f16>
    %int1 = torch.constant.int 1
    %int1_0 = torch.constant.int 1
    %3 = torch.prim.ListConstruct %int1, %int1_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0 = torch.constant.int 0
    %int0_1 = torch.constant.int 0
    %4 = torch.prim.ListConstruct %int0, %int0_1 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_2 = torch.constant.int 1
    %int1_3 = torch.constant.int 1
    %5 = torch.prim.ListConstruct %int1_2, %int1_3 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0_4 = torch.constant.int 0
    %int0_5 = torch.constant.int 0
    %6 = torch.prim.ListConstruct %int0_4, %int0_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_6 = torch.constant.int 1
    %7 = torch.aten.convolution %0, %1, %2, %3, %4, %5, %false, %6, %int1_6 : !torch.vtensor<[1,4,128,128],f16>, !torch.vtensor<[4,4,1,1],f16>, !torch.vtensor<[4],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,4,128,128],f16>
    %__auto.decoder.conv_in.weight = util.global.load @__auto.decoder.conv_in.weight : tensor<512x4x3x3xf16>
    %8 = torch_c.from_builtin_tensor %__auto.decoder.conv_in.weight : tensor<512x4x3x3xf16> -> !torch.vtensor<[512,4,3,3],f16>
    %__auto.decoder.conv_in.bias = util.global.load @__auto.decoder.conv_in.bias : tensor<512xf16>
    %9 = torch_c.from_builtin_tensor %__auto.decoder.conv_in.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_7 = torch.constant.int 1
    %int1_8 = torch.constant.int 1
    %10 = torch.prim.ListConstruct %int1_7, %int1_8 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_9 = torch.constant.int 1
    %int1_10 = torch.constant.int 1
    %11 = torch.prim.ListConstruct %int1_9, %int1_10 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_11 = torch.constant.int 1
    %int1_12 = torch.constant.int 1
    %12 = torch.prim.ListConstruct %int1_11, %int1_12 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_13 = torch.constant.bool false
    %int0_14 = torch.constant.int 0
    %int0_15 = torch.constant.int 0
    %13 = torch.prim.ListConstruct %int0_14, %int0_15 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_16 = torch.constant.int 1
    %14 = torch.aten.convolution %7, %8, %9, %10, %11, %12, %false_13, %13, %int1_16 : !torch.vtensor<[1,4,128,128],f16>, !torch.vtensor<[512,4,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_17 = torch.constant.int 1
    %int32 = torch.constant.int 32
    %int16 = torch.constant.int 16
    %int16384 = torch.constant.int 16384
    %15 = torch.prim.ListConstruct %int1_17, %int32, %int16, %int16384 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6 = torch.constant.int 6
    %17 = torch.prims.convert_element_type %16, %int6 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2 = torch.constant.int 2
    %int3 = torch.constant.int 3
    %18 = torch.prim.ListConstruct %int2, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_18 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %17, %18, %int0_18, %true : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07 = torch.constant.float 9.9999999999999995E-7
    %int1_19 = torch.constant.int 1
    %19 = torch.aten.add.Scalar %result0, %float9.999990e-07, %int1_19 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %20 = torch.aten.rsqrt %19 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_20 = torch.constant.int 1
    %21 = torch.aten.sub.Tensor %16, %result1, %int1_20 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %22 = torch.aten.mul.Tensor %21, %20 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_21 = torch.constant.int 1
    %int512 = torch.constant.int 512
    %int128 = torch.constant.int 128
    %int128_22 = torch.constant.int 128
    %23 = torch.prim.ListConstruct %int1_21, %int512, %int128, %int128_22 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %24 = torch.aten.view %22, %23 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.0.norm1.bias = util.global.load @__auto.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16>
    %25 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_23 = torch.constant.int 0
    %26 = torch.aten.unsqueeze %25, %int0_23 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_24 = torch.constant.int 2
    %27 = torch.aten.unsqueeze %26, %int2_24 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_25 = torch.constant.int 3
    %28 = torch.aten.unsqueeze %27, %int3_25 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.0.norm1.weight = util.global.load @__auto.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16>
    %29 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_26 = torch.constant.int 0
    %30 = torch.aten.unsqueeze %29, %int0_26 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_27 = torch.constant.int 2
    %31 = torch.aten.unsqueeze %30, %int2_27 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_28 = torch.constant.int 3
    %32 = torch.aten.unsqueeze %31, %int3_28 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %33 = torch.aten.mul.Tensor %24, %32 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_29 = torch.constant.int 1
    %34 = torch.aten.add.Tensor %33, %28, %int1_29 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5 = torch.constant.int 5
    %35 = torch.prims.convert_element_type %34, %int5 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %36 = torch.aten.silu %35 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.0.conv1.weight = util.global.load @__auto.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %37 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.0.conv1.bias = util.global.load @__auto.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16>
    %38 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_30 = torch.constant.int 1
    %int1_31 = torch.constant.int 1
    %39 = torch.prim.ListConstruct %int1_30, %int1_31 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_32 = torch.constant.int 1
    %int1_33 = torch.constant.int 1
    %40 = torch.prim.ListConstruct %int1_32, %int1_33 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_34 = torch.constant.int 1
    %int1_35 = torch.constant.int 1
    %41 = torch.prim.ListConstruct %int1_34, %int1_35 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_36 = torch.constant.bool false
    %int0_37 = torch.constant.int 0
    %int0_38 = torch.constant.int 0
    %42 = torch.prim.ListConstruct %int0_37, %int0_38 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_39 = torch.constant.int 1
    %43 = torch.aten.convolution %36, %37, %38, %39, %40, %41, %false_36, %42, %int1_39 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_40 = torch.constant.int 1
    %int32_41 = torch.constant.int 32
    %int16_42 = torch.constant.int 16
    %int16384_43 = torch.constant.int 16384
    %44 = torch.prim.ListConstruct %int1_40, %int32_41, %int16_42, %int16384_43 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %45 = torch.aten.view %43, %44 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_44 = torch.constant.int 6
    %46 = torch.prims.convert_element_type %45, %int6_44 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_45 = torch.constant.int 2
    %int3_46 = torch.constant.int 3
    %47 = torch.prim.ListConstruct %int2_45, %int3_46 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_47 = torch.constant.int 0
    %true_48 = torch.constant.bool true
    %result0_49, %result1_50 = torch.aten.var_mean.correction %46, %47, %int0_47, %true_48 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_51 = torch.constant.float 9.9999999999999995E-7
    %int1_52 = torch.constant.int 1
    %48 = torch.aten.add.Scalar %result0_49, %float9.999990e-07_51, %int1_52 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %49 = torch.aten.rsqrt %48 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_53 = torch.constant.int 1
    %50 = torch.aten.sub.Tensor %45, %result1_50, %int1_53 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %51 = torch.aten.mul.Tensor %50, %49 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_54 = torch.constant.int 1
    %int512_55 = torch.constant.int 512
    %int128_56 = torch.constant.int 128
    %int128_57 = torch.constant.int 128
    %52 = torch.prim.ListConstruct %int1_54, %int512_55, %int128_56, %int128_57 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %53 = torch.aten.view %51, %52 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.0.norm2.bias = util.global.load @__auto.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16>
    %54 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_58 = torch.constant.int 0
    %55 = torch.aten.unsqueeze %54, %int0_58 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_59 = torch.constant.int 2
    %56 = torch.aten.unsqueeze %55, %int2_59 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_60 = torch.constant.int 3
    %57 = torch.aten.unsqueeze %56, %int3_60 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.0.norm2.weight = util.global.load @__auto.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16>
    %58 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_61 = torch.constant.int 0
    %59 = torch.aten.unsqueeze %58, %int0_61 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_62 = torch.constant.int 2
    %60 = torch.aten.unsqueeze %59, %int2_62 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_63 = torch.constant.int 3
    %61 = torch.aten.unsqueeze %60, %int3_63 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %62 = torch.aten.mul.Tensor %53, %61 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_64 = torch.constant.int 1
    %63 = torch.aten.add.Tensor %62, %57, %int1_64 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_65 = torch.constant.int 5
    %64 = torch.prims.convert_element_type %63, %int5_65 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %65 = torch.aten.silu %64 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none = torch.constant.none
    %66 = torch.aten.clone %65, %none : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.0.conv2.weight = util.global.load @__auto.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %67 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.0.conv2.bias = util.global.load @__auto.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16>
    %68 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_66 = torch.constant.int 1
    %int1_67 = torch.constant.int 1
    %69 = torch.prim.ListConstruct %int1_66, %int1_67 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_68 = torch.constant.int 1
    %int1_69 = torch.constant.int 1
    %70 = torch.prim.ListConstruct %int1_68, %int1_69 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_70 = torch.constant.int 1
    %int1_71 = torch.constant.int 1
    %71 = torch.prim.ListConstruct %int1_70, %int1_71 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_72 = torch.constant.bool false
    %int0_73 = torch.constant.int 0
    %int0_74 = torch.constant.int 0
    %72 = torch.prim.ListConstruct %int0_73, %int0_74 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_75 = torch.constant.int 1
    %73 = torch.aten.convolution %66, %67, %68, %69, %70, %71, %false_72, %72, %int1_75 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_76 = torch.constant.int 1
    %74 = torch.aten.add.Tensor %14, %73, %int1_76 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_77 = torch.constant.int 1
    %75 = torch.aten.div.Scalar %74, %int1_77 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_78 = torch.constant.int 1
    %int512_79 = torch.constant.int 512
    %int16384_80 = torch.constant.int 16384
    %76 = torch.prim.ListConstruct %int1_78, %int512_79, %int16384_80 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %77 = torch.aten.view %75, %76 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f16>
    %int1_81 = torch.constant.int 1
    %int2_82 = torch.constant.int 2
    %78 = torch.aten.transpose.int %77, %int1_81, %int2_82 : !torch.vtensor<[1,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int1_83 = torch.constant.int 1
    %int2_84 = torch.constant.int 2
    %79 = torch.aten.transpose.int %78, %int1_83, %int2_84 : !torch.vtensor<[1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_85 = torch.constant.int 1
    %int32_86 = torch.constant.int 32
    %int16_87 = torch.constant.int 16
    %int16384_88 = torch.constant.int 16384
    %80 = torch.prim.ListConstruct %int1_85, %int32_86, %int16_87, %int16384_88 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %81 = torch.aten.view %79, %80 : !torch.vtensor<[1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_89 = torch.constant.int 6
    %82 = torch.prims.convert_element_type %81, %int6_89 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_90 = torch.constant.int 2
    %int3_91 = torch.constant.int 3
    %83 = torch.prim.ListConstruct %int2_90, %int3_91 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_92 = torch.constant.int 0
    %true_93 = torch.constant.bool true
    %result0_94, %result1_95 = torch.aten.var_mean.correction %82, %83, %int0_92, %true_93 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_96 = torch.constant.float 9.9999999999999995E-7
    %int1_97 = torch.constant.int 1
    %84 = torch.aten.add.Scalar %result0_94, %float9.999990e-07_96, %int1_97 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %85 = torch.aten.rsqrt %84 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_98 = torch.constant.int 1
    %86 = torch.aten.sub.Tensor %81, %result1_95, %int1_98 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %87 = torch.aten.mul.Tensor %86, %85 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_99 = torch.constant.int 1
    %int512_100 = torch.constant.int 512
    %int16384_101 = torch.constant.int 16384
    %88 = torch.prim.ListConstruct %int1_99, %int512_100, %int16384_101 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %89 = torch.aten.view %87, %88 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f32>
    %__auto.decoder.mid_block.attentions.0.group_norm.bias = util.global.load @__auto.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16>
    %90 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_102 = torch.constant.int 0
    %91 = torch.aten.unsqueeze %90, %int0_102 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_103 = torch.constant.int 2
    %92 = torch.aten.unsqueeze %91, %int2_103 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %__auto.decoder.mid_block.attentions.0.group_norm.weight = util.global.load @__auto.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16>
    %93 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_104 = torch.constant.int 0
    %94 = torch.aten.unsqueeze %93, %int0_104 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_105 = torch.constant.int 2
    %95 = torch.aten.unsqueeze %94, %int2_105 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %96 = torch.aten.mul.Tensor %89, %95 : !torch.vtensor<[1,512,16384],f32>, !torch.vtensor<[1,512,1],f16> -> !torch.vtensor<[1,512,16384],f32>
    %int1_106 = torch.constant.int 1
    %97 = torch.aten.add.Tensor %96, %92, %int1_106 : !torch.vtensor<[1,512,16384],f32>, !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,16384],f32>
    %int5_107 = torch.constant.int 5
    %98 = torch.prims.convert_element_type %97, %int5_107 : !torch.vtensor<[1,512,16384],f32>, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_108 = torch.constant.int 1
    %int2_109 = torch.constant.int 2
    %99 = torch.aten.transpose.int %98, %int1_108, %int2_109 : !torch.vtensor<[1,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_q.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16>
    %100 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_110 = torch.constant.int 0
    %int1_111 = torch.constant.int 1
    %101 = torch.aten.transpose.int %100, %int0_110, %int1_111 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_112 = torch.constant.int 16384
    %int512_113 = torch.constant.int 512
    %102 = torch.prim.ListConstruct %int16384_112, %int512_113 : (!torch.int, !torch.int) -> !torch.list<int>
    %103 = torch.aten.view %99, %102 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %104 = torch.aten.mm %103, %101 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_114 = torch.constant.int 1
    %int16384_115 = torch.constant.int 16384
    %int512_116 = torch.constant.int 512
    %105 = torch.prim.ListConstruct %int1_114, %int16384_115, %int512_116 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %106 = torch.aten.view %104, %105 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_q.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16>
    %107 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_117 = torch.constant.int 1
    %108 = torch.aten.add.Tensor %106, %107, %int1_117 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_k.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16>
    %109 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_118 = torch.constant.int 0
    %int1_119 = torch.constant.int 1
    %110 = torch.aten.transpose.int %109, %int0_118, %int1_119 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_120 = torch.constant.int 16384
    %int512_121 = torch.constant.int 512
    %111 = torch.prim.ListConstruct %int16384_120, %int512_121 : (!torch.int, !torch.int) -> !torch.list<int>
    %112 = torch.aten.view %99, %111 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %113 = torch.aten.mm %112, %110 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_122 = torch.constant.int 1
    %int16384_123 = torch.constant.int 16384
    %int512_124 = torch.constant.int 512
    %114 = torch.prim.ListConstruct %int1_122, %int16384_123, %int512_124 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %115 = torch.aten.view %113, %114 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_k.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16>
    %116 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_125 = torch.constant.int 1
    %117 = torch.aten.add.Tensor %115, %116, %int1_125 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_v.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16>
    %118 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_126 = torch.constant.int 0
    %int1_127 = torch.constant.int 1
    %119 = torch.aten.transpose.int %118, %int0_126, %int1_127 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_128 = torch.constant.int 16384
    %int512_129 = torch.constant.int 512
    %120 = torch.prim.ListConstruct %int16384_128, %int512_129 : (!torch.int, !torch.int) -> !torch.list<int>
    %121 = torch.aten.view %99, %120 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %122 = torch.aten.mm %121, %119 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_130 = torch.constant.int 1
    %int16384_131 = torch.constant.int 16384
    %int512_132 = torch.constant.int 512
    %123 = torch.prim.ListConstruct %int1_130, %int16384_131, %int512_132 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %124 = torch.aten.view %122, %123 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_v.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16>
    %125 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_133 = torch.constant.int 1
    %126 = torch.aten.add.Tensor %124, %125, %int1_133 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int1_134 = torch.constant.int 1
    %int-1 = torch.constant.int -1
    %int1_135 = torch.constant.int 1
    %int512_136 = torch.constant.int 512
    %127 = torch.prim.ListConstruct %int1_134, %int-1, %int1_135, %int512_136 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %128 = torch.aten.view %108, %127 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_137 = torch.constant.int 1
    %int2_138 = torch.constant.int 2
    %129 = torch.aten.transpose.int %128, %int1_137, %int2_138 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_139 = torch.constant.int 1
    %int-1_140 = torch.constant.int -1
    %int1_141 = torch.constant.int 1
    %int512_142 = torch.constant.int 512
    %130 = torch.prim.ListConstruct %int1_139, %int-1_140, %int1_141, %int512_142 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %131 = torch.aten.view %117, %130 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_143 = torch.constant.int 1
    %int2_144 = torch.constant.int 2
    %132 = torch.aten.transpose.int %131, %int1_143, %int2_144 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_145 = torch.constant.int 1
    %int-1_146 = torch.constant.int -1
    %int1_147 = torch.constant.int 1
    %int512_148 = torch.constant.int 512
    %133 = torch.prim.ListConstruct %int1_145, %int-1_146, %int1_147, %int512_148 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %134 = torch.aten.view %126, %133 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_149 = torch.constant.int 1
    %int2_150 = torch.constant.int 2
    %135 = torch.aten.transpose.int %134, %int1_149, %int2_150 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %float2.102240e-01 = torch.constant.float 0.21022410381342863
    %136 = torch.aten.mul.Scalar %129, %float2.102240e-01 : !torch.vtensor<[1,1,16384,512],f16>, !torch.float -> !torch.vtensor<[1,1,16384,512],f16>
    %int-2 = torch.constant.int -2
    %int-1_151 = torch.constant.int -1
    %137 = torch.aten.transpose.int %132, %int-2, %int-1_151 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,512,16384],f16>
    %float2.102240e-01_152 = torch.constant.float 0.21022410381342863
    %138 = torch.aten.mul.Scalar %137, %float2.102240e-01_152 : !torch.vtensor<[1,1,512,16384],f16>, !torch.float -> !torch.vtensor<[1,1,512,16384],f16>
    %int1_153 = torch.constant.int 1
    %int1_154 = torch.constant.int 1
    %int16384_155 = torch.constant.int 16384
    %int512_156 = torch.constant.int 512
    %139 = torch.prim.ListConstruct %int1_153, %int1_154, %int16384_155, %int512_156 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_157 = torch.constant.bool false
    %140 = torch.aten.expand %136, %139, %false_157 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_158 = torch.constant.int 1
    %int16384_159 = torch.constant.int 16384
    %int512_160 = torch.constant.int 512
    %141 = torch.prim.ListConstruct %int1_158, %int16384_159, %int512_160 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %142 = torch.aten.view %140, %141 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %int1_161 = torch.constant.int 1
    %int1_162 = torch.constant.int 1
    %int512_163 = torch.constant.int 512
    %int16384_164 = torch.constant.int 16384
    %143 = torch.prim.ListConstruct %int1_161, %int1_162, %int512_163, %int16384_164 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_165 = torch.constant.bool false
    %144 = torch.aten.expand %138, %143, %false_165 : !torch.vtensor<[1,1,512,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,512,16384],f16>
    %int1_166 = torch.constant.int 1
    %int512_167 = torch.constant.int 512
    %int16384_168 = torch.constant.int 16384
    %145 = torch.prim.ListConstruct %int1_166, %int512_167, %int16384_168 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %146 = torch.aten.view %144, %145 : !torch.vtensor<[1,1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f16>
    %147 = torch.aten.bmm %142, %146 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[1,512,16384],f16> -> !torch.vtensor<[1,16384,16384],f16>
    %int1_169 = torch.constant.int 1
    %int1_170 = torch.constant.int 1
    %int16384_171 = torch.constant.int 16384
    %int16384_172 = torch.constant.int 16384
    %148 = torch.prim.ListConstruct %int1_169, %int1_170, %int16384_171, %int16384_172 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %149 = torch.aten.view %147, %148 : !torch.vtensor<[1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,1,16384,16384],f16>
    %int-1_173 = torch.constant.int -1
    %false_174 = torch.constant.bool false
    %150 = torch.aten._softmax %149, %int-1_173, %false_174 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.int, !torch.bool -> !torch.vtensor<[1,1,16384,16384],f16>
    %int1_175 = torch.constant.int 1
    %int1_176 = torch.constant.int 1
    %int16384_177 = torch.constant.int 16384
    %int16384_178 = torch.constant.int 16384
    %151 = torch.prim.ListConstruct %int1_175, %int1_176, %int16384_177, %int16384_178 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_179 = torch.constant.bool false
    %152 = torch.aten.expand %150, %151, %false_179 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,16384],f16>
    %int1_180 = torch.constant.int 1
    %int16384_181 = torch.constant.int 16384
    %int16384_182 = torch.constant.int 16384
    %153 = torch.prim.ListConstruct %int1_180, %int16384_181, %int16384_182 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %154 = torch.aten.view %152, %153 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,16384],f16>
    %int1_183 = torch.constant.int 1
    %int1_184 = torch.constant.int 1
    %int16384_185 = torch.constant.int 16384
    %int512_186 = torch.constant.int 512
    %155 = torch.prim.ListConstruct %int1_183, %int1_184, %int16384_185, %int512_186 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_187 = torch.constant.bool false
    %156 = torch.aten.expand %135, %155, %false_187 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_188 = torch.constant.int 1
    %int16384_189 = torch.constant.int 16384
    %int512_190 = torch.constant.int 512
    %157 = torch.prim.ListConstruct %int1_188, %int16384_189, %int512_190 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %158 = torch.aten.view %156, %157 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %159 = torch.aten.bmm %154, %158 : !torch.vtensor<[1,16384,16384],f16>, !torch.vtensor<[1,16384,512],f16> -> !torch.vtensor<[1,16384,512],f16>
    %int1_191 = torch.constant.int 1
    %int1_192 = torch.constant.int 1
    %int16384_193 = torch.constant.int 16384
    %int512_194 = torch.constant.int 512
    %160 = torch.prim.ListConstruct %int1_191, %int1_192, %int16384_193, %int512_194 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %161 = torch.aten.view %159, %160 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_195 = torch.constant.int 1
    %int2_196 = torch.constant.int 2
    %162 = torch.aten.transpose.int %161, %int1_195, %int2_196 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_197 = torch.constant.int 1
    %int-1_198 = torch.constant.int -1
    %int512_199 = torch.constant.int 512
    %163 = torch.prim.ListConstruct %int1_197, %int-1_198, %int512_199 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %164 = torch.aten.view %162, %163 : !torch.vtensor<[1,16384,1,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %int5_200 = torch.constant.int 5
    %165 = torch.prims.convert_element_type %164, %int5_200 : !torch.vtensor<[1,16384,512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int16384_201 = torch.constant.int 16384
    %int512_202 = torch.constant.int 512
    %166 = torch.prim.ListConstruct %int16384_201, %int512_202 : (!torch.int, !torch.int) -> !torch.list<int>
    %167 = torch.aten.view %165, %166 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_out.0.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16>
    %168 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_203 = torch.constant.int 0
    %int1_204 = torch.constant.int 1
    %169 = torch.aten.transpose.int %168, %int0_203, %int1_204 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_out.0.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16>
    %170 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int6_205 = torch.constant.int 6
    %171 = torch.prims.convert_element_type %170, %int6_205 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[512],f32>
    %int6_206 = torch.constant.int 6
    %172 = torch.prims.convert_element_type %167, %int6_206 : !torch.vtensor<[16384,512],f16>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int6_207 = torch.constant.int 6
    %173 = torch.prims.convert_element_type %169, %int6_207 : !torch.vtensor<[512,512],f16>, !torch.int -> !torch.vtensor<[512,512],f32>
    %174 = torch.aten.mm %172, %173 : !torch.vtensor<[16384,512],f32>, !torch.vtensor<[512,512],f32> -> !torch.vtensor<[16384,512],f32>
    %int1_208 = torch.constant.int 1
    %175 = torch.aten.mul.Scalar %174, %int1_208 : !torch.vtensor<[16384,512],f32>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int1_209 = torch.constant.int 1
    %176 = torch.aten.mul.Scalar %171, %int1_209 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],f32>
    %int1_210 = torch.constant.int 1
    %177 = torch.aten.add.Tensor %175, %176, %int1_210 : !torch.vtensor<[16384,512],f32>, !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int5_211 = torch.constant.int 5
    %178 = torch.prims.convert_element_type %177, %int5_211 : !torch.vtensor<[16384,512],f32>, !torch.int -> !torch.vtensor<[16384,512],f16>
    %int1_212 = torch.constant.int 1
    %int16384_213 = torch.constant.int 16384
    %int512_214 = torch.constant.int 512
    %179 = torch.prim.ListConstruct %int1_212, %int16384_213, %int512_214 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %180 = torch.aten.view %178, %179 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %none_215 = torch.constant.none
    %181 = torch.aten.clone %180, %none_215 : !torch.vtensor<[1,16384,512],f16>, !torch.none -> !torch.vtensor<[1,16384,512],f16>
    %int-1_216 = torch.constant.int -1
    %int-2_217 = torch.constant.int -2
    %182 = torch.aten.transpose.int %181, %int-1_216, %int-2_217 : !torch.vtensor<[1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_218 = torch.constant.int 1
    %int512_219 = torch.constant.int 512
    %int128_220 = torch.constant.int 128
    %int128_221 = torch.constant.int 128
    %183 = torch.prim.ListConstruct %int1_218, %int512_219, %int128_220, %int128_221 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %184 = torch.aten.view %182, %183 : !torch.vtensor<[1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f16>
    %int1_222 = torch.constant.int 1
    %185 = torch.aten.add.Tensor %184, %75, %int1_222 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_223 = torch.constant.int 1
    %186 = torch.aten.div.Scalar %185, %int1_223 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_224 = torch.constant.int 1
    %int32_225 = torch.constant.int 32
    %int16_226 = torch.constant.int 16
    %int16384_227 = torch.constant.int 16384
    %187 = torch.prim.ListConstruct %int1_224, %int32_225, %int16_226, %int16384_227 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %188 = torch.aten.view %186, %187 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_228 = torch.constant.int 6
    %189 = torch.prims.convert_element_type %188, %int6_228 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_229 = torch.constant.int 2
    %int3_230 = torch.constant.int 3
    %190 = torch.prim.ListConstruct %int2_229, %int3_230 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_231 = torch.constant.int 0
    %true_232 = torch.constant.bool true
    %result0_233, %result1_234 = torch.aten.var_mean.correction %189, %190, %int0_231, %true_232 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_235 = torch.constant.float 9.9999999999999995E-7
    %int1_236 = torch.constant.int 1
    %191 = torch.aten.add.Scalar %result0_233, %float9.999990e-07_235, %int1_236 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %192 = torch.aten.rsqrt %191 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_237 = torch.constant.int 1
    %193 = torch.aten.sub.Tensor %188, %result1_234, %int1_237 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %194 = torch.aten.mul.Tensor %193, %192 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_238 = torch.constant.int 1
    %int512_239 = torch.constant.int 512
    %int128_240 = torch.constant.int 128
    %int128_241 = torch.constant.int 128
    %195 = torch.prim.ListConstruct %int1_238, %int512_239, %int128_240, %int128_241 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %196 = torch.aten.view %194, %195 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.1.norm1.bias = util.global.load @__auto.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16>
    %197 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_242 = torch.constant.int 0
    %198 = torch.aten.unsqueeze %197, %int0_242 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_243 = torch.constant.int 2
    %199 = torch.aten.unsqueeze %198, %int2_243 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_244 = torch.constant.int 3
    %200 = torch.aten.unsqueeze %199, %int3_244 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.1.norm1.weight = util.global.load @__auto.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16>
    %201 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_245 = torch.constant.int 0
    %202 = torch.aten.unsqueeze %201, %int0_245 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_246 = torch.constant.int 2
    %203 = torch.aten.unsqueeze %202, %int2_246 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_247 = torch.constant.int 3
    %204 = torch.aten.unsqueeze %203, %int3_247 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %205 = torch.aten.mul.Tensor %196, %204 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_248 = torch.constant.int 1
    %206 = torch.aten.add.Tensor %205, %200, %int1_248 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_249 = torch.constant.int 5
    %207 = torch.prims.convert_element_type %206, %int5_249 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %208 = torch.aten.silu %207 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.1.conv1.weight = util.global.load @__auto.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %209 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.1.conv1.bias = util.global.load @__auto.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16>
    %210 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_250 = torch.constant.int 1
    %int1_251 = torch.constant.int 1
    %211 = torch.prim.ListConstruct %int1_250, %int1_251 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_252 = torch.constant.int 1
    %int1_253 = torch.constant.int 1
    %212 = torch.prim.ListConstruct %int1_252, %int1_253 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_254 = torch.constant.int 1
    %int1_255 = torch.constant.int 1
    %213 = torch.prim.ListConstruct %int1_254, %int1_255 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_256 = torch.constant.bool false
    %int0_257 = torch.constant.int 0
    %int0_258 = torch.constant.int 0
    %214 = torch.prim.ListConstruct %int0_257, %int0_258 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_259 = torch.constant.int 1
    %215 = torch.aten.convolution %208, %209, %210, %211, %212, %213, %false_256, %214, %int1_259 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_260 = torch.constant.int 1
    %int32_261 = torch.constant.int 32
    %int16_262 = torch.constant.int 16
    %int16384_263 = torch.constant.int 16384
    %216 = torch.prim.ListConstruct %int1_260, %int32_261, %int16_262, %int16384_263 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %217 = torch.aten.view %215, %216 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_264 = torch.constant.int 6
    %218 = torch.prims.convert_element_type %217, %int6_264 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_265 = torch.constant.int 2
    %int3_266 = torch.constant.int 3
    %219 = torch.prim.ListConstruct %int2_265, %int3_266 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_267 = torch.constant.int 0
    %true_268 = torch.constant.bool true
    %result0_269, %result1_270 = torch.aten.var_mean.correction %218, %219, %int0_267, %true_268 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_271 = torch.constant.float 9.9999999999999995E-7
    %int1_272 = torch.constant.int 1
    %220 = torch.aten.add.Scalar %result0_269, %float9.999990e-07_271, %int1_272 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %221 = torch.aten.rsqrt %220 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_273 = torch.constant.int 1
    %222 = torch.aten.sub.Tensor %217, %result1_270, %int1_273 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %223 = torch.aten.mul.Tensor %222, %221 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_274 = torch.constant.int 1
    %int512_275 = torch.constant.int 512
    %int128_276 = torch.constant.int 128
    %int128_277 = torch.constant.int 128
    %224 = torch.prim.ListConstruct %int1_274, %int512_275, %int128_276, %int128_277 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %225 = torch.aten.view %223, %224 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.1.norm2.bias = util.global.load @__auto.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16>
    %226 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_278 = torch.constant.int 0
    %227 = torch.aten.unsqueeze %226, %int0_278 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_279 = torch.constant.int 2
    %228 = torch.aten.unsqueeze %227, %int2_279 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_280 = torch.constant.int 3
    %229 = torch.aten.unsqueeze %228, %int3_280 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.1.norm2.weight = util.global.load @__auto.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16>
    %230 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_281 = torch.constant.int 0
    %231 = torch.aten.unsqueeze %230, %int0_281 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_282 = torch.constant.int 2
    %232 = torch.aten.unsqueeze %231, %int2_282 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_283 = torch.constant.int 3
    %233 = torch.aten.unsqueeze %232, %int3_283 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %234 = torch.aten.mul.Tensor %225, %233 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_284 = torch.constant.int 1
    %235 = torch.aten.add.Tensor %234, %229, %int1_284 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_285 = torch.constant.int 5
    %236 = torch.prims.convert_element_type %235, %int5_285 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %237 = torch.aten.silu %236 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_286 = torch.constant.none
    %238 = torch.aten.clone %237, %none_286 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.1.conv2.weight = util.global.load @__auto.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %239 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.1.conv2.bias = util.global.load @__auto.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16>
    %240 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_287 = torch.constant.int 1
    %int1_288 = torch.constant.int 1
    %241 = torch.prim.ListConstruct %int1_287, %int1_288 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_289 = torch.constant.int 1
    %int1_290 = torch.constant.int 1
    %242 = torch.prim.ListConstruct %int1_289, %int1_290 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_291 = torch.constant.int 1
    %int1_292 = torch.constant.int 1
    %243 = torch.prim.ListConstruct %int1_291, %int1_292 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_293 = torch.constant.bool false
    %int0_294 = torch.constant.int 0
    %int0_295 = torch.constant.int 0
    %244 = torch.prim.ListConstruct %int0_294, %int0_295 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_296 = torch.constant.int 1
    %245 = torch.aten.convolution %238, %239, %240, %241, %242, %243, %false_293, %244, %int1_296 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_297 = torch.constant.int 1
    %246 = torch.aten.add.Tensor %186, %245, %int1_297 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_298 = torch.constant.int 1
    %247 = torch.aten.div.Scalar %246, %int1_298 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_299 = torch.constant.int 5
    %248 = torch.prims.convert_element_type %247, %int5_299 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_300 = torch.constant.int 1
    %int32_301 = torch.constant.int 32
    %int16_302 = torch.constant.int 16
    %int16384_303 = torch.constant.int 16384
    %249 = torch.prim.ListConstruct %int1_300, %int32_301, %int16_302, %int16384_303 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %250 = torch.aten.view %248, %249 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_304 = torch.constant.int 6
    %251 = torch.prims.convert_element_type %250, %int6_304 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_305 = torch.constant.int 2
    %int3_306 = torch.constant.int 3
    %252 = torch.prim.ListConstruct %int2_305, %int3_306 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_307 = torch.constant.int 0
    %true_308 = torch.constant.bool true
    %result0_309, %result1_310 = torch.aten.var_mean.correction %251, %252, %int0_307, %true_308 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_311 = torch.constant.float 9.9999999999999995E-7
    %int1_312 = torch.constant.int 1
    %253 = torch.aten.add.Scalar %result0_309, %float9.999990e-07_311, %int1_312 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %254 = torch.aten.rsqrt %253 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_313 = torch.constant.int 1
    %255 = torch.aten.sub.Tensor %250, %result1_310, %int1_313 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %256 = torch.aten.mul.Tensor %255, %254 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_314 = torch.constant.int 1
    %int512_315 = torch.constant.int 512
    %int128_316 = torch.constant.int 128
    %int128_317 = torch.constant.int 128
    %257 = torch.prim.ListConstruct %int1_314, %int512_315, %int128_316, %int128_317 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %258 = torch.aten.view %256, %257 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16>
    %259 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_318 = torch.constant.int 0
    %260 = torch.aten.unsqueeze %259, %int0_318 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_319 = torch.constant.int 2
    %261 = torch.aten.unsqueeze %260, %int2_319 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_320 = torch.constant.int 3
    %262 = torch.aten.unsqueeze %261, %int3_320 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16>
    %263 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_321 = torch.constant.int 0
    %264 = torch.aten.unsqueeze %263, %int0_321 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_322 = torch.constant.int 2
    %265 = torch.aten.unsqueeze %264, %int2_322 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_323 = torch.constant.int 3
    %266 = torch.aten.unsqueeze %265, %int3_323 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %267 = torch.aten.mul.Tensor %258, %266 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_324 = torch.constant.int 1
    %268 = torch.aten.add.Tensor %267, %262, %int1_324 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_325 = torch.constant.int 5
    %269 = torch.prims.convert_element_type %268, %int5_325 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %270 = torch.aten.silu %269 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %271 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16>
    %272 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_326 = torch.constant.int 1
    %int1_327 = torch.constant.int 1
    %273 = torch.prim.ListConstruct %int1_326, %int1_327 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_328 = torch.constant.int 1
    %int1_329 = torch.constant.int 1
    %274 = torch.prim.ListConstruct %int1_328, %int1_329 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_330 = torch.constant.int 1
    %int1_331 = torch.constant.int 1
    %275 = torch.prim.ListConstruct %int1_330, %int1_331 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_332 = torch.constant.bool false
    %int0_333 = torch.constant.int 0
    %int0_334 = torch.constant.int 0
    %276 = torch.prim.ListConstruct %int0_333, %int0_334 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_335 = torch.constant.int 1
    %277 = torch.aten.convolution %270, %271, %272, %273, %274, %275, %false_332, %276, %int1_335 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_336 = torch.constant.int 1
    %int32_337 = torch.constant.int 32
    %int16_338 = torch.constant.int 16
    %int16384_339 = torch.constant.int 16384
    %278 = torch.prim.ListConstruct %int1_336, %int32_337, %int16_338, %int16384_339 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %279 = torch.aten.view %277, %278 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_340 = torch.constant.int 6
    %280 = torch.prims.convert_element_type %279, %int6_340 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_341 = torch.constant.int 2
    %int3_342 = torch.constant.int 3
    %281 = torch.prim.ListConstruct %int2_341, %int3_342 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_343 = torch.constant.int 0
    %true_344 = torch.constant.bool true
    %result0_345, %result1_346 = torch.aten.var_mean.correction %280, %281, %int0_343, %true_344 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_347 = torch.constant.float 9.9999999999999995E-7
    %int1_348 = torch.constant.int 1
    %282 = torch.aten.add.Scalar %result0_345, %float9.999990e-07_347, %int1_348 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %283 = torch.aten.rsqrt %282 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_349 = torch.constant.int 1
    %284 = torch.aten.sub.Tensor %279, %result1_346, %int1_349 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %285 = torch.aten.mul.Tensor %284, %283 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_350 = torch.constant.int 1
    %int512_351 = torch.constant.int 512
    %int128_352 = torch.constant.int 128
    %int128_353 = torch.constant.int 128
    %286 = torch.prim.ListConstruct %int1_350, %int512_351, %int128_352, %int128_353 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %287 = torch.aten.view %285, %286 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16>
    %288 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_354 = torch.constant.int 0
    %289 = torch.aten.unsqueeze %288, %int0_354 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_355 = torch.constant.int 2
    %290 = torch.aten.unsqueeze %289, %int2_355 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_356 = torch.constant.int 3
    %291 = torch.aten.unsqueeze %290, %int3_356 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16>
    %292 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_357 = torch.constant.int 0
    %293 = torch.aten.unsqueeze %292, %int0_357 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_358 = torch.constant.int 2
    %294 = torch.aten.unsqueeze %293, %int2_358 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_359 = torch.constant.int 3
    %295 = torch.aten.unsqueeze %294, %int3_359 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %296 = torch.aten.mul.Tensor %287, %295 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_360 = torch.constant.int 1
    %297 = torch.aten.add.Tensor %296, %291, %int1_360 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_361 = torch.constant.int 5
    %298 = torch.prims.convert_element_type %297, %int5_361 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %299 = torch.aten.silu %298 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_362 = torch.constant.none
    %300 = torch.aten.clone %299, %none_362 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %301 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16>
    %302 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_363 = torch.constant.int 1
    %int1_364 = torch.constant.int 1
    %303 = torch.prim.ListConstruct %int1_363, %int1_364 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_365 = torch.constant.int 1
    %int1_366 = torch.constant.int 1
    %304 = torch.prim.ListConstruct %int1_365, %int1_366 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_367 = torch.constant.int 1
    %int1_368 = torch.constant.int 1
    %305 = torch.prim.ListConstruct %int1_367, %int1_368 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_369 = torch.constant.bool false
    %int0_370 = torch.constant.int 0
    %int0_371 = torch.constant.int 0
    %306 = torch.prim.ListConstruct %int0_370, %int0_371 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_372 = torch.constant.int 1
    %307 = torch.aten.convolution %300, %301, %302, %303, %304, %305, %false_369, %306, %int1_372 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_373 = torch.constant.int 1
    %308 = torch.aten.add.Tensor %248, %307, %int1_373 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00 = torch.constant.float 1.000000e+00
    %309 = torch.aten.div.Scalar %308, %float1.000000e00 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int1_374 = torch.constant.int 1
    %int32_375 = torch.constant.int 32
    %int16_376 = torch.constant.int 16
    %int16384_377 = torch.constant.int 16384
    %310 = torch.prim.ListConstruct %int1_374, %int32_375, %int16_376, %int16384_377 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %311 = torch.aten.view %309, %310 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_378 = torch.constant.int 6
    %312 = torch.prims.convert_element_type %311, %int6_378 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_379 = torch.constant.int 2
    %int3_380 = torch.constant.int 3
    %313 = torch.prim.ListConstruct %int2_379, %int3_380 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_381 = torch.constant.int 0
    %true_382 = torch.constant.bool true
    %result0_383, %result1_384 = torch.aten.var_mean.correction %312, %313, %int0_381, %true_382 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_385 = torch.constant.float 9.9999999999999995E-7
    %int1_386 = torch.constant.int 1
    %314 = torch.aten.add.Scalar %result0_383, %float9.999990e-07_385, %int1_386 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %315 = torch.aten.rsqrt %314 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_387 = torch.constant.int 1
    %316 = torch.aten.sub.Tensor %311, %result1_384, %int1_387 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %317 = torch.aten.mul.Tensor %316, %315 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_388 = torch.constant.int 1
    %int512_389 = torch.constant.int 512
    %int128_390 = torch.constant.int 128
    %int128_391 = torch.constant.int 128
    %318 = torch.prim.ListConstruct %int1_388, %int512_389, %int128_390, %int128_391 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %319 = torch.aten.view %317, %318 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16>
    %320 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_392 = torch.constant.int 0
    %321 = torch.aten.unsqueeze %320, %int0_392 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_393 = torch.constant.int 2
    %322 = torch.aten.unsqueeze %321, %int2_393 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_394 = torch.constant.int 3
    %323 = torch.aten.unsqueeze %322, %int3_394 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16>
    %324 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_395 = torch.constant.int 0
    %325 = torch.aten.unsqueeze %324, %int0_395 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_396 = torch.constant.int 2
    %326 = torch.aten.unsqueeze %325, %int2_396 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_397 = torch.constant.int 3
    %327 = torch.aten.unsqueeze %326, %int3_397 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %328 = torch.aten.mul.Tensor %319, %327 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_398 = torch.constant.int 1
    %329 = torch.aten.add.Tensor %328, %323, %int1_398 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_399 = torch.constant.int 5
    %330 = torch.prims.convert_element_type %329, %int5_399 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %331 = torch.aten.silu %330 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %332 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16>
    %333 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_400 = torch.constant.int 1
    %int1_401 = torch.constant.int 1
    %334 = torch.prim.ListConstruct %int1_400, %int1_401 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_402 = torch.constant.int 1
    %int1_403 = torch.constant.int 1
    %335 = torch.prim.ListConstruct %int1_402, %int1_403 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_404 = torch.constant.int 1
    %int1_405 = torch.constant.int 1
    %336 = torch.prim.ListConstruct %int1_404, %int1_405 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_406 = torch.constant.bool false
    %int0_407 = torch.constant.int 0
    %int0_408 = torch.constant.int 0
    %337 = torch.prim.ListConstruct %int0_407, %int0_408 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_409 = torch.constant.int 1
    %338 = torch.aten.convolution %331, %332, %333, %334, %335, %336, %false_406, %337, %int1_409 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_410 = torch.constant.int 1
    %int32_411 = torch.constant.int 32
    %int16_412 = torch.constant.int 16
    %int16384_413 = torch.constant.int 16384
    %339 = torch.prim.ListConstruct %int1_410, %int32_411, %int16_412, %int16384_413 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %340 = torch.aten.view %338, %339 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_414 = torch.constant.int 6
    %341 = torch.prims.convert_element_type %340, %int6_414 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_415 = torch.constant.int 2
    %int3_416 = torch.constant.int 3
    %342 = torch.prim.ListConstruct %int2_415, %int3_416 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_417 = torch.constant.int 0
    %true_418 = torch.constant.bool true
    %result0_419, %result1_420 = torch.aten.var_mean.correction %341, %342, %int0_417, %true_418 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_421 = torch.constant.float 9.9999999999999995E-7
    %int1_422 = torch.constant.int 1
    %343 = torch.aten.add.Scalar %result0_419, %float9.999990e-07_421, %int1_422 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %344 = torch.aten.rsqrt %343 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_423 = torch.constant.int 1
    %345 = torch.aten.sub.Tensor %340, %result1_420, %int1_423 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %346 = torch.aten.mul.Tensor %345, %344 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_424 = torch.constant.int 1
    %int512_425 = torch.constant.int 512
    %int128_426 = torch.constant.int 128
    %int128_427 = torch.constant.int 128
    %347 = torch.prim.ListConstruct %int1_424, %int512_425, %int128_426, %int128_427 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %348 = torch.aten.view %346, %347 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16>
    %349 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_428 = torch.constant.int 0
    %350 = torch.aten.unsqueeze %349, %int0_428 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_429 = torch.constant.int 2
    %351 = torch.aten.unsqueeze %350, %int2_429 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_430 = torch.constant.int 3
    %352 = torch.aten.unsqueeze %351, %int3_430 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16>
    %353 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_431 = torch.constant.int 0
    %354 = torch.aten.unsqueeze %353, %int0_431 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_432 = torch.constant.int 2
    %355 = torch.aten.unsqueeze %354, %int2_432 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_433 = torch.constant.int 3
    %356 = torch.aten.unsqueeze %355, %int3_433 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %357 = torch.aten.mul.Tensor %348, %356 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_434 = torch.constant.int 1
    %358 = torch.aten.add.Tensor %357, %352, %int1_434 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_435 = torch.constant.int 5
    %359 = torch.prims.convert_element_type %358, %int5_435 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %360 = torch.aten.silu %359 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_436 = torch.constant.none
    %361 = torch.aten.clone %360, %none_436 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %362 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16>
    %363 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_437 = torch.constant.int 1
    %int1_438 = torch.constant.int 1
    %364 = torch.prim.ListConstruct %int1_437, %int1_438 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_439 = torch.constant.int 1
    %int1_440 = torch.constant.int 1
    %365 = torch.prim.ListConstruct %int1_439, %int1_440 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_441 = torch.constant.int 1
    %int1_442 = torch.constant.int 1
    %366 = torch.prim.ListConstruct %int1_441, %int1_442 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_443 = torch.constant.bool false
    %int0_444 = torch.constant.int 0
    %int0_445 = torch.constant.int 0
    %367 = torch.prim.ListConstruct %int0_444, %int0_445 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_446 = torch.constant.int 1
    %368 = torch.aten.convolution %361, %362, %363, %364, %365, %366, %false_443, %367, %int1_446 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_447 = torch.constant.int 1
    %369 = torch.aten.add.Tensor %309, %368, %int1_447 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00_448 = torch.constant.float 1.000000e+00
    %370 = torch.aten.div.Scalar %369, %float1.000000e00_448 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int1_449 = torch.constant.int 1
    %int32_450 = torch.constant.int 32
    %int16_451 = torch.constant.int 16
    %int16384_452 = torch.constant.int 16384
    %371 = torch.prim.ListConstruct %int1_449, %int32_450, %int16_451, %int16384_452 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %372 = torch.aten.view %370, %371 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_453 = torch.constant.int 6
    %373 = torch.prims.convert_element_type %372, %int6_453 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_454 = torch.constant.int 2
    %int3_455 = torch.constant.int 3
    %374 = torch.prim.ListConstruct %int2_454, %int3_455 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_456 = torch.constant.int 0
    %true_457 = torch.constant.bool true
    %result0_458, %result1_459 = torch.aten.var_mean.correction %373, %374, %int0_456, %true_457 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_460 = torch.constant.float 9.9999999999999995E-7
    %int1_461 = torch.constant.int 1
    %375 = torch.aten.add.Scalar %result0_458, %float9.999990e-07_460, %int1_461 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %376 = torch.aten.rsqrt %375 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_462 = torch.constant.int 1
    %377 = torch.aten.sub.Tensor %372, %result1_459, %int1_462 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %378 = torch.aten.mul.Tensor %377, %376 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_463 = torch.constant.int 1
    %int512_464 = torch.constant.int 512
    %int128_465 = torch.constant.int 128
    %int128_466 = torch.constant.int 128
    %379 = torch.prim.ListConstruct %int1_463, %int512_464, %int128_465, %int128_466 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %380 = torch.aten.view %378, %379 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16>
    %381 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_467 = torch.constant.int 0
    %382 = torch.aten.unsqueeze %381, %int0_467 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_468 = torch.constant.int 2
    %383 = torch.aten.unsqueeze %382, %int2_468 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_469 = torch.constant.int 3
    %384 = torch.aten.unsqueeze %383, %int3_469 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16>
    %385 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_470 = torch.constant.int 0
    %386 = torch.aten.unsqueeze %385, %int0_470 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_471 = torch.constant.int 2
    %387 = torch.aten.unsqueeze %386, %int2_471 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_472 = torch.constant.int 3
    %388 = torch.aten.unsqueeze %387, %int3_472 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %389 = torch.aten.mul.Tensor %380, %388 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_473 = torch.constant.int 1
    %390 = torch.aten.add.Tensor %389, %384, %int1_473 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_474 = torch.constant.int 5
    %391 = torch.prims.convert_element_type %390, %int5_474 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %392 = torch.aten.silu %391 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %393 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16>
    %394 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_475 = torch.constant.int 1
    %int1_476 = torch.constant.int 1
    %395 = torch.prim.ListConstruct %int1_475, %int1_476 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_477 = torch.constant.int 1
    %int1_478 = torch.constant.int 1
    %396 = torch.prim.ListConstruct %int1_477, %int1_478 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_479 = torch.constant.int 1
    %int1_480 = torch.constant.int 1
    %397 = torch.prim.ListConstruct %int1_479, %int1_480 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_481 = torch.constant.bool false
    %int0_482 = torch.constant.int 0
    %int0_483 = torch.constant.int 0
    %398 = torch.prim.ListConstruct %int0_482, %int0_483 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_484 = torch.constant.int 1
    %399 = torch.aten.convolution %392, %393, %394, %395, %396, %397, %false_481, %398, %int1_484 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_485 = torch.constant.int 1
    %int32_486 = torch.constant.int 32
    %int16_487 = torch.constant.int 16
    %int16384_488 = torch.constant.int 16384
    %400 = torch.prim.ListConstruct %int1_485, %int32_486, %int16_487, %int16384_488 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %401 = torch.aten.view %399, %400 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_489 = torch.constant.int 6
    %402 = torch.prims.convert_element_type %401, %int6_489 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_490 = torch.constant.int 2
    %int3_491 = torch.constant.int 3
    %403 = torch.prim.ListConstruct %int2_490, %int3_491 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_492 = torch.constant.int 0
    %true_493 = torch.constant.bool true
    %result0_494, %result1_495 = torch.aten.var_mean.correction %402, %403, %int0_492, %true_493 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_496 = torch.constant.float 9.9999999999999995E-7
    %int1_497 = torch.constant.int 1
    %404 = torch.aten.add.Scalar %result0_494, %float9.999990e-07_496, %int1_497 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %405 = torch.aten.rsqrt %404 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_498 = torch.constant.int 1
    %406 = torch.aten.sub.Tensor %401, %result1_495, %int1_498 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %407 = torch.aten.mul.Tensor %406, %405 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_499 = torch.constant.int 1
    %int512_500 = torch.constant.int 512
    %int128_501 = torch.constant.int 128
    %int128_502 = torch.constant.int 128
    %408 = torch.prim.ListConstruct %int1_499, %int512_500, %int128_501, %int128_502 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %409 = torch.aten.view %407, %408 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16>
    %410 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_503 = torch.constant.int 0
    %411 = torch.aten.unsqueeze %410, %int0_503 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_504 = torch.constant.int 2
    %412 = torch.aten.unsqueeze %411, %int2_504 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_505 = torch.constant.int 3
    %413 = torch.aten.unsqueeze %412, %int3_505 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16>
    %414 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_506 = torch.constant.int 0
    %415 = torch.aten.unsqueeze %414, %int0_506 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_507 = torch.constant.int 2
    %416 = torch.aten.unsqueeze %415, %int2_507 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_508 = torch.constant.int 3
    %417 = torch.aten.unsqueeze %416, %int3_508 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %418 = torch.aten.mul.Tensor %409, %417 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_509 = torch.constant.int 1
    %419 = torch.aten.add.Tensor %418, %413, %int1_509 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_510 = torch.constant.int 5
    %420 = torch.prims.convert_element_type %419, %int5_510 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %421 = torch.aten.silu %420 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_511 = torch.constant.none
    %422 = torch.aten.clone %421, %none_511 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %423 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16>
    %424 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_512 = torch.constant.int 1
    %int1_513 = torch.constant.int 1
    %425 = torch.prim.ListConstruct %int1_512, %int1_513 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_514 = torch.constant.int 1
    %int1_515 = torch.constant.int 1
    %426 = torch.prim.ListConstruct %int1_514, %int1_515 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_516 = torch.constant.int 1
    %int1_517 = torch.constant.int 1
    %427 = torch.prim.ListConstruct %int1_516, %int1_517 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_518 = torch.constant.bool false
    %int0_519 = torch.constant.int 0
    %int0_520 = torch.constant.int 0
    %428 = torch.prim.ListConstruct %int0_519, %int0_520 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_521 = torch.constant.int 1
    %429 = torch.aten.convolution %422, %423, %424, %425, %426, %427, %false_518, %428, %int1_521 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_522 = torch.constant.int 1
    %430 = torch.aten.add.Tensor %370, %429, %int1_522 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00_523 = torch.constant.float 1.000000e+00
    %431 = torch.aten.div.Scalar %430, %float1.000000e00_523 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int6_524 = torch.constant.int 6
    %432 = torch.prims.convert_element_type %431, %int6_524 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int256 = torch.constant.int 256
    %int6_525 = torch.constant.int 6
    %none_526 = torch.constant.none
    %cpu = torch.constant.device "cpu"
    %false_527 = torch.constant.bool false
    %433 = torch.aten.arange %int256, %int6_525, %none_526, %cpu, %false_527 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %int1_528 = torch.constant.int 1
    %434 = torch.aten.add.Scalar %433, %float0.000000e00, %int1_528 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %435 = torch.aten.mul.Scalar %434, %float5.000000e-01 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4 = torch.constant.int 4
    %436 = torch.prims.convert_element_type %435, %int4 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %int-1_529 = torch.constant.int -1
    %437 = torch.aten.unsqueeze %436, %int-1_529 : !torch.vtensor<[256],si64>, !torch.int -> !torch.vtensor<[256,1],si64>
    %int256_530 = torch.constant.int 256
    %int6_531 = torch.constant.int 6
    %none_532 = torch.constant.none
    %cpu_533 = torch.constant.device "cpu"
    %false_534 = torch.constant.bool false
    %438 = torch.aten.arange %int256_530, %int6_531, %none_532, %cpu_533, %false_534 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00_535 = torch.constant.float 0.000000e+00
    %int1_536 = torch.constant.int 1
    %439 = torch.aten.add.Scalar %438, %float0.000000e00_535, %int1_536 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01_537 = torch.constant.float 5.000000e-01
    %440 = torch.aten.mul.Scalar %439, %float5.000000e-01_537 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4_538 = torch.constant.int 4
    %441 = torch.prims.convert_element_type %440, %int4_538 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %none_539 = torch.constant.none
    %none_540 = torch.constant.none
    %442 = torch.prim.ListConstruct %none_539, %none_540, %437, %441 : (!torch.none, !torch.none, !torch.vtensor<[256,1],si64>, !torch.vtensor<[256],si64>) -> !torch.list<optional<vtensor>>
    %443 = torch.aten.index.Tensor %432, %442 : !torch.vtensor<[1,512,128,128],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,512,256,256],f32>
    %int2_541 = torch.constant.int 2
    %444 = torch.aten.clone %443, %int2_541 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_542 = torch.constant.int 5
    %445 = torch.prims.convert_element_type %444, %int5_542 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.0.upsamplers.0.conv.weight = util.global.load @__auto.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %446 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.upsamplers.0.conv.bias = util.global.load @__auto.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16>
    %447 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_543 = torch.constant.int 1
    %int1_544 = torch.constant.int 1
    %448 = torch.prim.ListConstruct %int1_543, %int1_544 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_545 = torch.constant.int 1
    %int1_546 = torch.constant.int 1
    %449 = torch.prim.ListConstruct %int1_545, %int1_546 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_547 = torch.constant.int 1
    %int1_548 = torch.constant.int 1
    %450 = torch.prim.ListConstruct %int1_547, %int1_548 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_549 = torch.constant.bool false
    %int0_550 = torch.constant.int 0
    %int0_551 = torch.constant.int 0
    %451 = torch.prim.ListConstruct %int0_550, %int0_551 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_552 = torch.constant.int 1
    %452 = torch.aten.convolution %445, %446, %447, %448, %449, %450, %false_549, %451, %int1_552 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_553 = torch.constant.int 1
    %int32_554 = torch.constant.int 32
    %int16_555 = torch.constant.int 16
    %int65536 = torch.constant.int 65536
    %453 = torch.prim.ListConstruct %int1_553, %int32_554, %int16_555, %int65536 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %454 = torch.aten.view %452, %453 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_556 = torch.constant.int 6
    %455 = torch.prims.convert_element_type %454, %int6_556 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_557 = torch.constant.int 2
    %int3_558 = torch.constant.int 3
    %456 = torch.prim.ListConstruct %int2_557, %int3_558 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_559 = torch.constant.int 0
    %true_560 = torch.constant.bool true
    %result0_561, %result1_562 = torch.aten.var_mean.correction %455, %456, %int0_559, %true_560 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_563 = torch.constant.float 9.9999999999999995E-7
    %int1_564 = torch.constant.int 1
    %457 = torch.aten.add.Scalar %result0_561, %float9.999990e-07_563, %int1_564 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %458 = torch.aten.rsqrt %457 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_565 = torch.constant.int 1
    %459 = torch.aten.sub.Tensor %454, %result1_562, %int1_565 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %460 = torch.aten.mul.Tensor %459, %458 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_566 = torch.constant.int 1
    %int512_567 = torch.constant.int 512
    %int256_568 = torch.constant.int 256
    %int256_569 = torch.constant.int 256
    %461 = torch.prim.ListConstruct %int1_566, %int512_567, %int256_568, %int256_569 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %462 = torch.aten.view %460, %461 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16>
    %463 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_570 = torch.constant.int 0
    %464 = torch.aten.unsqueeze %463, %int0_570 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_571 = torch.constant.int 2
    %465 = torch.aten.unsqueeze %464, %int2_571 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_572 = torch.constant.int 3
    %466 = torch.aten.unsqueeze %465, %int3_572 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16>
    %467 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_573 = torch.constant.int 0
    %468 = torch.aten.unsqueeze %467, %int0_573 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_574 = torch.constant.int 2
    %469 = torch.aten.unsqueeze %468, %int2_574 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_575 = torch.constant.int 3
    %470 = torch.aten.unsqueeze %469, %int3_575 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %471 = torch.aten.mul.Tensor %462, %470 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_576 = torch.constant.int 1
    %472 = torch.aten.add.Tensor %471, %466, %int1_576 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_577 = torch.constant.int 5
    %473 = torch.prims.convert_element_type %472, %int5_577 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %474 = torch.aten.silu %473 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %475 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16>
    %476 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_578 = torch.constant.int 1
    %int1_579 = torch.constant.int 1
    %477 = torch.prim.ListConstruct %int1_578, %int1_579 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_580 = torch.constant.int 1
    %int1_581 = torch.constant.int 1
    %478 = torch.prim.ListConstruct %int1_580, %int1_581 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_582 = torch.constant.int 1
    %int1_583 = torch.constant.int 1
    %479 = torch.prim.ListConstruct %int1_582, %int1_583 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_584 = torch.constant.bool false
    %int0_585 = torch.constant.int 0
    %int0_586 = torch.constant.int 0
    %480 = torch.prim.ListConstruct %int0_585, %int0_586 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_587 = torch.constant.int 1
    %481 = torch.aten.convolution %474, %475, %476, %477, %478, %479, %false_584, %480, %int1_587 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_588 = torch.constant.int 1
    %int32_589 = torch.constant.int 32
    %int16_590 = torch.constant.int 16
    %int65536_591 = torch.constant.int 65536
    %482 = torch.prim.ListConstruct %int1_588, %int32_589, %int16_590, %int65536_591 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %483 = torch.aten.view %481, %482 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_592 = torch.constant.int 6
    %484 = torch.prims.convert_element_type %483, %int6_592 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_593 = torch.constant.int 2
    %int3_594 = torch.constant.int 3
    %485 = torch.prim.ListConstruct %int2_593, %int3_594 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_595 = torch.constant.int 0
    %true_596 = torch.constant.bool true
    %result0_597, %result1_598 = torch.aten.var_mean.correction %484, %485, %int0_595, %true_596 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_599 = torch.constant.float 9.9999999999999995E-7
    %int1_600 = torch.constant.int 1
    %486 = torch.aten.add.Scalar %result0_597, %float9.999990e-07_599, %int1_600 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %487 = torch.aten.rsqrt %486 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_601 = torch.constant.int 1
    %488 = torch.aten.sub.Tensor %483, %result1_598, %int1_601 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %489 = torch.aten.mul.Tensor %488, %487 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_602 = torch.constant.int 1
    %int512_603 = torch.constant.int 512
    %int256_604 = torch.constant.int 256
    %int256_605 = torch.constant.int 256
    %490 = torch.prim.ListConstruct %int1_602, %int512_603, %int256_604, %int256_605 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %491 = torch.aten.view %489, %490 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16>
    %492 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_606 = torch.constant.int 0
    %493 = torch.aten.unsqueeze %492, %int0_606 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_607 = torch.constant.int 2
    %494 = torch.aten.unsqueeze %493, %int2_607 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_608 = torch.constant.int 3
    %495 = torch.aten.unsqueeze %494, %int3_608 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16>
    %496 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_609 = torch.constant.int 0
    %497 = torch.aten.unsqueeze %496, %int0_609 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_610 = torch.constant.int 2
    %498 = torch.aten.unsqueeze %497, %int2_610 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_611 = torch.constant.int 3
    %499 = torch.aten.unsqueeze %498, %int3_611 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %500 = torch.aten.mul.Tensor %491, %499 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_612 = torch.constant.int 1
    %501 = torch.aten.add.Tensor %500, %495, %int1_612 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_613 = torch.constant.int 5
    %502 = torch.prims.convert_element_type %501, %int5_613 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %503 = torch.aten.silu %502 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_614 = torch.constant.none
    %504 = torch.aten.clone %503, %none_614 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %505 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16>
    %506 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_615 = torch.constant.int 1
    %int1_616 = torch.constant.int 1
    %507 = torch.prim.ListConstruct %int1_615, %int1_616 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_617 = torch.constant.int 1
    %int1_618 = torch.constant.int 1
    %508 = torch.prim.ListConstruct %int1_617, %int1_618 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_619 = torch.constant.int 1
    %int1_620 = torch.constant.int 1
    %509 = torch.prim.ListConstruct %int1_619, %int1_620 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_621 = torch.constant.bool false
    %int0_622 = torch.constant.int 0
    %int0_623 = torch.constant.int 0
    %510 = torch.prim.ListConstruct %int0_622, %int0_623 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_624 = torch.constant.int 1
    %511 = torch.aten.convolution %504, %505, %506, %507, %508, %509, %false_621, %510, %int1_624 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_625 = torch.constant.int 1
    %512 = torch.aten.add.Tensor %452, %511, %int1_625 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_626 = torch.constant.float 1.000000e+00
    %513 = torch.aten.div.Scalar %512, %float1.000000e00_626 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int1_627 = torch.constant.int 1
    %int32_628 = torch.constant.int 32
    %int16_629 = torch.constant.int 16
    %int65536_630 = torch.constant.int 65536
    %514 = torch.prim.ListConstruct %int1_627, %int32_628, %int16_629, %int65536_630 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %515 = torch.aten.view %513, %514 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_631 = torch.constant.int 6
    %516 = torch.prims.convert_element_type %515, %int6_631 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_632 = torch.constant.int 2
    %int3_633 = torch.constant.int 3
    %517 = torch.prim.ListConstruct %int2_632, %int3_633 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_634 = torch.constant.int 0
    %true_635 = torch.constant.bool true
    %result0_636, %result1_637 = torch.aten.var_mean.correction %516, %517, %int0_634, %true_635 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_638 = torch.constant.float 9.9999999999999995E-7
    %int1_639 = torch.constant.int 1
    %518 = torch.aten.add.Scalar %result0_636, %float9.999990e-07_638, %int1_639 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %519 = torch.aten.rsqrt %518 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_640 = torch.constant.int 1
    %520 = torch.aten.sub.Tensor %515, %result1_637, %int1_640 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %521 = torch.aten.mul.Tensor %520, %519 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_641 = torch.constant.int 1
    %int512_642 = torch.constant.int 512
    %int256_643 = torch.constant.int 256
    %int256_644 = torch.constant.int 256
    %522 = torch.prim.ListConstruct %int1_641, %int512_642, %int256_643, %int256_644 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %523 = torch.aten.view %521, %522 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16>
    %524 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_645 = torch.constant.int 0
    %525 = torch.aten.unsqueeze %524, %int0_645 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_646 = torch.constant.int 2
    %526 = torch.aten.unsqueeze %525, %int2_646 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_647 = torch.constant.int 3
    %527 = torch.aten.unsqueeze %526, %int3_647 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16>
    %528 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_648 = torch.constant.int 0
    %529 = torch.aten.unsqueeze %528, %int0_648 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_649 = torch.constant.int 2
    %530 = torch.aten.unsqueeze %529, %int2_649 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_650 = torch.constant.int 3
    %531 = torch.aten.unsqueeze %530, %int3_650 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %532 = torch.aten.mul.Tensor %523, %531 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_651 = torch.constant.int 1
    %533 = torch.aten.add.Tensor %532, %527, %int1_651 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_652 = torch.constant.int 5
    %534 = torch.prims.convert_element_type %533, %int5_652 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %535 = torch.aten.silu %534 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %536 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16>
    %537 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_653 = torch.constant.int 1
    %int1_654 = torch.constant.int 1
    %538 = torch.prim.ListConstruct %int1_653, %int1_654 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_655 = torch.constant.int 1
    %int1_656 = torch.constant.int 1
    %539 = torch.prim.ListConstruct %int1_655, %int1_656 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_657 = torch.constant.int 1
    %int1_658 = torch.constant.int 1
    %540 = torch.prim.ListConstruct %int1_657, %int1_658 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_659 = torch.constant.bool false
    %int0_660 = torch.constant.int 0
    %int0_661 = torch.constant.int 0
    %541 = torch.prim.ListConstruct %int0_660, %int0_661 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_662 = torch.constant.int 1
    %542 = torch.aten.convolution %535, %536, %537, %538, %539, %540, %false_659, %541, %int1_662 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_663 = torch.constant.int 1
    %int32_664 = torch.constant.int 32
    %int16_665 = torch.constant.int 16
    %int65536_666 = torch.constant.int 65536
    %543 = torch.prim.ListConstruct %int1_663, %int32_664, %int16_665, %int65536_666 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %544 = torch.aten.view %542, %543 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_667 = torch.constant.int 6
    %545 = torch.prims.convert_element_type %544, %int6_667 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_668 = torch.constant.int 2
    %int3_669 = torch.constant.int 3
    %546 = torch.prim.ListConstruct %int2_668, %int3_669 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_670 = torch.constant.int 0
    %true_671 = torch.constant.bool true
    %result0_672, %result1_673 = torch.aten.var_mean.correction %545, %546, %int0_670, %true_671 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_674 = torch.constant.float 9.9999999999999995E-7
    %int1_675 = torch.constant.int 1
    %547 = torch.aten.add.Scalar %result0_672, %float9.999990e-07_674, %int1_675 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %548 = torch.aten.rsqrt %547 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_676 = torch.constant.int 1
    %549 = torch.aten.sub.Tensor %544, %result1_673, %int1_676 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %550 = torch.aten.mul.Tensor %549, %548 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_677 = torch.constant.int 1
    %int512_678 = torch.constant.int 512
    %int256_679 = torch.constant.int 256
    %int256_680 = torch.constant.int 256
    %551 = torch.prim.ListConstruct %int1_677, %int512_678, %int256_679, %int256_680 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %552 = torch.aten.view %550, %551 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16>
    %553 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_681 = torch.constant.int 0
    %554 = torch.aten.unsqueeze %553, %int0_681 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_682 = torch.constant.int 2
    %555 = torch.aten.unsqueeze %554, %int2_682 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_683 = torch.constant.int 3
    %556 = torch.aten.unsqueeze %555, %int3_683 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16>
    %557 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_684 = torch.constant.int 0
    %558 = torch.aten.unsqueeze %557, %int0_684 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_685 = torch.constant.int 2
    %559 = torch.aten.unsqueeze %558, %int2_685 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_686 = torch.constant.int 3
    %560 = torch.aten.unsqueeze %559, %int3_686 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %561 = torch.aten.mul.Tensor %552, %560 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_687 = torch.constant.int 1
    %562 = torch.aten.add.Tensor %561, %556, %int1_687 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_688 = torch.constant.int 5
    %563 = torch.prims.convert_element_type %562, %int5_688 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %564 = torch.aten.silu %563 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_689 = torch.constant.none
    %565 = torch.aten.clone %564, %none_689 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %566 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16>
    %567 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_690 = torch.constant.int 1
    %int1_691 = torch.constant.int 1
    %568 = torch.prim.ListConstruct %int1_690, %int1_691 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_692 = torch.constant.int 1
    %int1_693 = torch.constant.int 1
    %569 = torch.prim.ListConstruct %int1_692, %int1_693 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_694 = torch.constant.int 1
    %int1_695 = torch.constant.int 1
    %570 = torch.prim.ListConstruct %int1_694, %int1_695 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_696 = torch.constant.bool false
    %int0_697 = torch.constant.int 0
    %int0_698 = torch.constant.int 0
    %571 = torch.prim.ListConstruct %int0_697, %int0_698 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_699 = torch.constant.int 1
    %572 = torch.aten.convolution %565, %566, %567, %568, %569, %570, %false_696, %571, %int1_699 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_700 = torch.constant.int 1
    %573 = torch.aten.add.Tensor %513, %572, %int1_700 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_701 = torch.constant.float 1.000000e+00
    %574 = torch.aten.div.Scalar %573, %float1.000000e00_701 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int1_702 = torch.constant.int 1
    %int32_703 = torch.constant.int 32
    %int16_704 = torch.constant.int 16
    %int65536_705 = torch.constant.int 65536
    %575 = torch.prim.ListConstruct %int1_702, %int32_703, %int16_704, %int65536_705 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %576 = torch.aten.view %574, %575 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_706 = torch.constant.int 6
    %577 = torch.prims.convert_element_type %576, %int6_706 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_707 = torch.constant.int 2
    %int3_708 = torch.constant.int 3
    %578 = torch.prim.ListConstruct %int2_707, %int3_708 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_709 = torch.constant.int 0
    %true_710 = torch.constant.bool true
    %result0_711, %result1_712 = torch.aten.var_mean.correction %577, %578, %int0_709, %true_710 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_713 = torch.constant.float 9.9999999999999995E-7
    %int1_714 = torch.constant.int 1
    %579 = torch.aten.add.Scalar %result0_711, %float9.999990e-07_713, %int1_714 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %580 = torch.aten.rsqrt %579 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_715 = torch.constant.int 1
    %581 = torch.aten.sub.Tensor %576, %result1_712, %int1_715 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %582 = torch.aten.mul.Tensor %581, %580 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_716 = torch.constant.int 1
    %int512_717 = torch.constant.int 512
    %int256_718 = torch.constant.int 256
    %int256_719 = torch.constant.int 256
    %583 = torch.prim.ListConstruct %int1_716, %int512_717, %int256_718, %int256_719 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %584 = torch.aten.view %582, %583 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16>
    %585 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_720 = torch.constant.int 0
    %586 = torch.aten.unsqueeze %585, %int0_720 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_721 = torch.constant.int 2
    %587 = torch.aten.unsqueeze %586, %int2_721 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_722 = torch.constant.int 3
    %588 = torch.aten.unsqueeze %587, %int3_722 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16>
    %589 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_723 = torch.constant.int 0
    %590 = torch.aten.unsqueeze %589, %int0_723 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_724 = torch.constant.int 2
    %591 = torch.aten.unsqueeze %590, %int2_724 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_725 = torch.constant.int 3
    %592 = torch.aten.unsqueeze %591, %int3_725 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %593 = torch.aten.mul.Tensor %584, %592 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_726 = torch.constant.int 1
    %594 = torch.aten.add.Tensor %593, %588, %int1_726 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_727 = torch.constant.int 5
    %595 = torch.prims.convert_element_type %594, %int5_727 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %596 = torch.aten.silu %595 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %597 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16>
    %598 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_728 = torch.constant.int 1
    %int1_729 = torch.constant.int 1
    %599 = torch.prim.ListConstruct %int1_728, %int1_729 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_730 = torch.constant.int 1
    %int1_731 = torch.constant.int 1
    %600 = torch.prim.ListConstruct %int1_730, %int1_731 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_732 = torch.constant.int 1
    %int1_733 = torch.constant.int 1
    %601 = torch.prim.ListConstruct %int1_732, %int1_733 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_734 = torch.constant.bool false
    %int0_735 = torch.constant.int 0
    %int0_736 = torch.constant.int 0
    %602 = torch.prim.ListConstruct %int0_735, %int0_736 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_737 = torch.constant.int 1
    %603 = torch.aten.convolution %596, %597, %598, %599, %600, %601, %false_734, %602, %int1_737 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_738 = torch.constant.int 1
    %int32_739 = torch.constant.int 32
    %int16_740 = torch.constant.int 16
    %int65536_741 = torch.constant.int 65536
    %604 = torch.prim.ListConstruct %int1_738, %int32_739, %int16_740, %int65536_741 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %605 = torch.aten.view %603, %604 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_742 = torch.constant.int 6
    %606 = torch.prims.convert_element_type %605, %int6_742 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_743 = torch.constant.int 2
    %int3_744 = torch.constant.int 3
    %607 = torch.prim.ListConstruct %int2_743, %int3_744 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_745 = torch.constant.int 0
    %true_746 = torch.constant.bool true
    %result0_747, %result1_748 = torch.aten.var_mean.correction %606, %607, %int0_745, %true_746 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_749 = torch.constant.float 9.9999999999999995E-7
    %int1_750 = torch.constant.int 1
    %608 = torch.aten.add.Scalar %result0_747, %float9.999990e-07_749, %int1_750 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %609 = torch.aten.rsqrt %608 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_751 = torch.constant.int 1
    %610 = torch.aten.sub.Tensor %605, %result1_748, %int1_751 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %611 = torch.aten.mul.Tensor %610, %609 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_752 = torch.constant.int 1
    %int512_753 = torch.constant.int 512
    %int256_754 = torch.constant.int 256
    %int256_755 = torch.constant.int 256
    %612 = torch.prim.ListConstruct %int1_752, %int512_753, %int256_754, %int256_755 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %613 = torch.aten.view %611, %612 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16>
    %614 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_756 = torch.constant.int 0
    %615 = torch.aten.unsqueeze %614, %int0_756 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_757 = torch.constant.int 2
    %616 = torch.aten.unsqueeze %615, %int2_757 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_758 = torch.constant.int 3
    %617 = torch.aten.unsqueeze %616, %int3_758 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16>
    %618 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_759 = torch.constant.int 0
    %619 = torch.aten.unsqueeze %618, %int0_759 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_760 = torch.constant.int 2
    %620 = torch.aten.unsqueeze %619, %int2_760 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_761 = torch.constant.int 3
    %621 = torch.aten.unsqueeze %620, %int3_761 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %622 = torch.aten.mul.Tensor %613, %621 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_762 = torch.constant.int 1
    %623 = torch.aten.add.Tensor %622, %617, %int1_762 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_763 = torch.constant.int 5
    %624 = torch.prims.convert_element_type %623, %int5_763 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %625 = torch.aten.silu %624 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_764 = torch.constant.none
    %626 = torch.aten.clone %625, %none_764 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %627 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16>
    %628 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_765 = torch.constant.int 1
    %int1_766 = torch.constant.int 1
    %629 = torch.prim.ListConstruct %int1_765, %int1_766 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_767 = torch.constant.int 1
    %int1_768 = torch.constant.int 1
    %630 = torch.prim.ListConstruct %int1_767, %int1_768 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_769 = torch.constant.int 1
    %int1_770 = torch.constant.int 1
    %631 = torch.prim.ListConstruct %int1_769, %int1_770 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_771 = torch.constant.bool false
    %int0_772 = torch.constant.int 0
    %int0_773 = torch.constant.int 0
    %632 = torch.prim.ListConstruct %int0_772, %int0_773 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_774 = torch.constant.int 1
    %633 = torch.aten.convolution %626, %627, %628, %629, %630, %631, %false_771, %632, %int1_774 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_775 = torch.constant.int 1
    %634 = torch.aten.add.Tensor %574, %633, %int1_775 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_776 = torch.constant.float 1.000000e+00
    %635 = torch.aten.div.Scalar %634, %float1.000000e00_776 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int6_777 = torch.constant.int 6
    %636 = torch.prims.convert_element_type %635, %int6_777 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int512_778 = torch.constant.int 512
    %int6_779 = torch.constant.int 6
    %none_780 = torch.constant.none
    %cpu_781 = torch.constant.device "cpu"
    %false_782 = torch.constant.bool false
    %637 = torch.aten.arange %int512_778, %int6_779, %none_780, %cpu_781, %false_782 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_783 = torch.constant.float 0.000000e+00
    %int1_784 = torch.constant.int 1
    %638 = torch.aten.add.Scalar %637, %float0.000000e00_783, %int1_784 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_785 = torch.constant.float 5.000000e-01
    %639 = torch.aten.mul.Scalar %638, %float5.000000e-01_785 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_786 = torch.constant.int 4
    %640 = torch.prims.convert_element_type %639, %int4_786 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %int-1_787 = torch.constant.int -1
    %641 = torch.aten.unsqueeze %640, %int-1_787 : !torch.vtensor<[512],si64>, !torch.int -> !torch.vtensor<[512,1],si64>
    %int512_788 = torch.constant.int 512
    %int6_789 = torch.constant.int 6
    %none_790 = torch.constant.none
    %cpu_791 = torch.constant.device "cpu"
    %false_792 = torch.constant.bool false
    %642 = torch.aten.arange %int512_788, %int6_789, %none_790, %cpu_791, %false_792 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_793 = torch.constant.float 0.000000e+00
    %int1_794 = torch.constant.int 1
    %643 = torch.aten.add.Scalar %642, %float0.000000e00_793, %int1_794 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_795 = torch.constant.float 5.000000e-01
    %644 = torch.aten.mul.Scalar %643, %float5.000000e-01_795 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_796 = torch.constant.int 4
    %645 = torch.prims.convert_element_type %644, %int4_796 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %none_797 = torch.constant.none
    %none_798 = torch.constant.none
    %646 = torch.prim.ListConstruct %none_797, %none_798, %641, %645 : (!torch.none, !torch.none, !torch.vtensor<[512,1],si64>, !torch.vtensor<[512],si64>) -> !torch.list<optional<vtensor>>
    %647 = torch.aten.index.Tensor %636, %646 : !torch.vtensor<[1,512,256,256],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,512,512,512],f32>
    %int2_799 = torch.constant.int 2
    %648 = torch.aten.clone %647, %int2_799 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f32>
    %int5_800 = torch.constant.int 5
    %649 = torch.prims.convert_element_type %648, %int5_800 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %__auto.decoder.up_blocks.1.upsamplers.0.conv.weight = util.global.load @__auto.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %650 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.upsamplers.0.conv.bias = util.global.load @__auto.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16>
    %651 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_801 = torch.constant.int 1
    %int1_802 = torch.constant.int 1
    %652 = torch.prim.ListConstruct %int1_801, %int1_802 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_803 = torch.constant.int 1
    %int1_804 = torch.constant.int 1
    %653 = torch.prim.ListConstruct %int1_803, %int1_804 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_805 = torch.constant.int 1
    %int1_806 = torch.constant.int 1
    %654 = torch.prim.ListConstruct %int1_805, %int1_806 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_807 = torch.constant.bool false
    %int0_808 = torch.constant.int 0
    %int0_809 = torch.constant.int 0
    %655 = torch.prim.ListConstruct %int0_808, %int0_809 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_810 = torch.constant.int 1
    %656 = torch.aten.convolution %649, %650, %651, %652, %653, %654, %false_807, %655, %int1_810 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %int1_811 = torch.constant.int 1
    %int32_812 = torch.constant.int 32
    %int16_813 = torch.constant.int 16
    %int262144 = torch.constant.int 262144
    %657 = torch.prim.ListConstruct %int1_811, %int32_812, %int16_813, %int262144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %658 = torch.aten.view %656, %657 : !torch.vtensor<[1,512,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,262144],f16>
    %int6_814 = torch.constant.int 6
    %659 = torch.prims.convert_element_type %658, %int6_814 : !torch.vtensor<[1,32,16,262144],f16>, !torch.int -> !torch.vtensor<[1,32,16,262144],f32>
    %int2_815 = torch.constant.int 2
    %int3_816 = torch.constant.int 3
    %660 = torch.prim.ListConstruct %int2_815, %int3_816 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_817 = torch.constant.int 0
    %true_818 = torch.constant.bool true
    %result0_819, %result1_820 = torch.aten.var_mean.correction %659, %660, %int0_817, %true_818 : !torch.vtensor<[1,32,16,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_821 = torch.constant.float 9.9999999999999995E-7
    %int1_822 = torch.constant.int 1
    %661 = torch.aten.add.Scalar %result0_819, %float9.999990e-07_821, %int1_822 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %662 = torch.aten.rsqrt %661 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_823 = torch.constant.int 1
    %663 = torch.aten.sub.Tensor %658, %result1_820, %int1_823 : !torch.vtensor<[1,32,16,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,262144],f32>
    %664 = torch.aten.mul.Tensor %663, %662 : !torch.vtensor<[1,32,16,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,262144],f32>
    %int1_824 = torch.constant.int 1
    %int512_825 = torch.constant.int 512
    %int512_826 = torch.constant.int 512
    %int512_827 = torch.constant.int 512
    %665 = torch.prim.ListConstruct %int1_824, %int512_825, %int512_826, %int512_827 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %666 = torch.aten.view %664, %665 : !torch.vtensor<[1,32,16,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,512,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16>
    %667 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_828 = torch.constant.int 0
    %668 = torch.aten.unsqueeze %667, %int0_828 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_829 = torch.constant.int 2
    %669 = torch.aten.unsqueeze %668, %int2_829 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_830 = torch.constant.int 3
    %670 = torch.aten.unsqueeze %669, %int3_830 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16>
    %671 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_831 = torch.constant.int 0
    %672 = torch.aten.unsqueeze %671, %int0_831 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_832 = torch.constant.int 2
    %673 = torch.aten.unsqueeze %672, %int2_832 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_833 = torch.constant.int 3
    %674 = torch.aten.unsqueeze %673, %int3_833 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %675 = torch.aten.mul.Tensor %666, %674 : !torch.vtensor<[1,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,512,512],f32>
    %int1_834 = torch.constant.int 1
    %676 = torch.aten.add.Tensor %675, %670, %int1_834 : !torch.vtensor<[1,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,512,512],f32>
    %int5_835 = torch.constant.int 5
    %677 = torch.prims.convert_element_type %676, %int5_835 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %678 = torch.aten.silu %677 : !torch.vtensor<[1,512,512,512],f16> -> !torch.vtensor<[1,512,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16>
    %679 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16> -> !torch.vtensor<[256,512,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16>
    %680 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_836 = torch.constant.int 1
    %int1_837 = torch.constant.int 1
    %681 = torch.prim.ListConstruct %int1_836, %int1_837 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_838 = torch.constant.int 1
    %int1_839 = torch.constant.int 1
    %682 = torch.prim.ListConstruct %int1_838, %int1_839 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_840 = torch.constant.int 1
    %int1_841 = torch.constant.int 1
    %683 = torch.prim.ListConstruct %int1_840, %int1_841 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_842 = torch.constant.bool false
    %int0_843 = torch.constant.int 0
    %int0_844 = torch.constant.int 0
    %684 = torch.prim.ListConstruct %int0_843, %int0_844 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_845 = torch.constant.int 1
    %685 = torch.aten.convolution %678, %679, %680, %681, %682, %683, %false_842, %684, %int1_845 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[256,512,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_846 = torch.constant.int 1
    %int32_847 = torch.constant.int 32
    %int8 = torch.constant.int 8
    %int262144_848 = torch.constant.int 262144
    %686 = torch.prim.ListConstruct %int1_846, %int32_847, %int8, %int262144_848 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %687 = torch.aten.view %685, %686 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_849 = torch.constant.int 6
    %688 = torch.prims.convert_element_type %687, %int6_849 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_850 = torch.constant.int 2
    %int3_851 = torch.constant.int 3
    %689 = torch.prim.ListConstruct %int2_850, %int3_851 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_852 = torch.constant.int 0
    %true_853 = torch.constant.bool true
    %result0_854, %result1_855 = torch.aten.var_mean.correction %688, %689, %int0_852, %true_853 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_856 = torch.constant.float 9.9999999999999995E-7
    %int1_857 = torch.constant.int 1
    %690 = torch.aten.add.Scalar %result0_854, %float9.999990e-07_856, %int1_857 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %691 = torch.aten.rsqrt %690 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_858 = torch.constant.int 1
    %692 = torch.aten.sub.Tensor %687, %result1_855, %int1_858 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %693 = torch.aten.mul.Tensor %692, %691 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_859 = torch.constant.int 1
    %int256_860 = torch.constant.int 256
    %int512_861 = torch.constant.int 512
    %int512_862 = torch.constant.int 512
    %694 = torch.prim.ListConstruct %int1_859, %int256_860, %int512_861, %int512_862 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %695 = torch.aten.view %693, %694 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16>
    %696 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_863 = torch.constant.int 0
    %697 = torch.aten.unsqueeze %696, %int0_863 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_864 = torch.constant.int 2
    %698 = torch.aten.unsqueeze %697, %int2_864 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_865 = torch.constant.int 3
    %699 = torch.aten.unsqueeze %698, %int3_865 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16>
    %700 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_866 = torch.constant.int 0
    %701 = torch.aten.unsqueeze %700, %int0_866 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_867 = torch.constant.int 2
    %702 = torch.aten.unsqueeze %701, %int2_867 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_868 = torch.constant.int 3
    %703 = torch.aten.unsqueeze %702, %int3_868 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %704 = torch.aten.mul.Tensor %695, %703 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_869 = torch.constant.int 1
    %705 = torch.aten.add.Tensor %704, %699, %int1_869 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_870 = torch.constant.int 5
    %706 = torch.prims.convert_element_type %705, %int5_870 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %707 = torch.aten.silu %706 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_871 = torch.constant.none
    %708 = torch.aten.clone %707, %none_871 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16>
    %709 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16>
    %710 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_872 = torch.constant.int 1
    %int1_873 = torch.constant.int 1
    %711 = torch.prim.ListConstruct %int1_872, %int1_873 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_874 = torch.constant.int 1
    %int1_875 = torch.constant.int 1
    %712 = torch.prim.ListConstruct %int1_874, %int1_875 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_876 = torch.constant.int 1
    %int1_877 = torch.constant.int 1
    %713 = torch.prim.ListConstruct %int1_876, %int1_877 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_878 = torch.constant.bool false
    %int0_879 = torch.constant.int 0
    %int0_880 = torch.constant.int 0
    %714 = torch.prim.ListConstruct %int0_879, %int0_880 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_881 = torch.constant.int 1
    %715 = torch.aten.convolution %708, %709, %710, %711, %712, %713, %false_878, %714, %int1_881 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16>
    %716 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16> -> !torch.vtensor<[256,512,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16>
    %717 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_882 = torch.constant.int 1
    %int1_883 = torch.constant.int 1
    %718 = torch.prim.ListConstruct %int1_882, %int1_883 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_884 = torch.constant.int 0
    %int0_885 = torch.constant.int 0
    %719 = torch.prim.ListConstruct %int0_884, %int0_885 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_886 = torch.constant.int 1
    %int1_887 = torch.constant.int 1
    %720 = torch.prim.ListConstruct %int1_886, %int1_887 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_888 = torch.constant.bool false
    %int0_889 = torch.constant.int 0
    %int0_890 = torch.constant.int 0
    %721 = torch.prim.ListConstruct %int0_889, %int0_890 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_891 = torch.constant.int 1
    %722 = torch.aten.convolution %656, %716, %717, %718, %719, %720, %false_888, %721, %int1_891 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[256,512,1,1],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_892 = torch.constant.int 1
    %723 = torch.aten.add.Tensor %722, %715, %int1_892 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_893 = torch.constant.float 1.000000e+00
    %724 = torch.aten.div.Scalar %723, %float1.000000e00_893 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int1_894 = torch.constant.int 1
    %int32_895 = torch.constant.int 32
    %int8_896 = torch.constant.int 8
    %int262144_897 = torch.constant.int 262144
    %725 = torch.prim.ListConstruct %int1_894, %int32_895, %int8_896, %int262144_897 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %726 = torch.aten.view %724, %725 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_898 = torch.constant.int 6
    %727 = torch.prims.convert_element_type %726, %int6_898 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_899 = torch.constant.int 2
    %int3_900 = torch.constant.int 3
    %728 = torch.prim.ListConstruct %int2_899, %int3_900 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_901 = torch.constant.int 0
    %true_902 = torch.constant.bool true
    %result0_903, %result1_904 = torch.aten.var_mean.correction %727, %728, %int0_901, %true_902 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_905 = torch.constant.float 9.9999999999999995E-7
    %int1_906 = torch.constant.int 1
    %729 = torch.aten.add.Scalar %result0_903, %float9.999990e-07_905, %int1_906 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %730 = torch.aten.rsqrt %729 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_907 = torch.constant.int 1
    %731 = torch.aten.sub.Tensor %726, %result1_904, %int1_907 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %732 = torch.aten.mul.Tensor %731, %730 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_908 = torch.constant.int 1
    %int256_909 = torch.constant.int 256
    %int512_910 = torch.constant.int 512
    %int512_911 = torch.constant.int 512
    %733 = torch.prim.ListConstruct %int1_908, %int256_909, %int512_910, %int512_911 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %734 = torch.aten.view %732, %733 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16>
    %735 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_912 = torch.constant.int 0
    %736 = torch.aten.unsqueeze %735, %int0_912 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_913 = torch.constant.int 2
    %737 = torch.aten.unsqueeze %736, %int2_913 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_914 = torch.constant.int 3
    %738 = torch.aten.unsqueeze %737, %int3_914 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16>
    %739 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_915 = torch.constant.int 0
    %740 = torch.aten.unsqueeze %739, %int0_915 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_916 = torch.constant.int 2
    %741 = torch.aten.unsqueeze %740, %int2_916 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_917 = torch.constant.int 3
    %742 = torch.aten.unsqueeze %741, %int3_917 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %743 = torch.aten.mul.Tensor %734, %742 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_918 = torch.constant.int 1
    %744 = torch.aten.add.Tensor %743, %738, %int1_918 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_919 = torch.constant.int 5
    %745 = torch.prims.convert_element_type %744, %int5_919 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %746 = torch.aten.silu %745 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16>
    %747 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16>
    %748 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_920 = torch.constant.int 1
    %int1_921 = torch.constant.int 1
    %749 = torch.prim.ListConstruct %int1_920, %int1_921 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_922 = torch.constant.int 1
    %int1_923 = torch.constant.int 1
    %750 = torch.prim.ListConstruct %int1_922, %int1_923 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_924 = torch.constant.int 1
    %int1_925 = torch.constant.int 1
    %751 = torch.prim.ListConstruct %int1_924, %int1_925 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_926 = torch.constant.bool false
    %int0_927 = torch.constant.int 0
    %int0_928 = torch.constant.int 0
    %752 = torch.prim.ListConstruct %int0_927, %int0_928 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_929 = torch.constant.int 1
    %753 = torch.aten.convolution %746, %747, %748, %749, %750, %751, %false_926, %752, %int1_929 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_930 = torch.constant.int 1
    %int32_931 = torch.constant.int 32
    %int8_932 = torch.constant.int 8
    %int262144_933 = torch.constant.int 262144
    %754 = torch.prim.ListConstruct %int1_930, %int32_931, %int8_932, %int262144_933 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %755 = torch.aten.view %753, %754 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_934 = torch.constant.int 6
    %756 = torch.prims.convert_element_type %755, %int6_934 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_935 = torch.constant.int 2
    %int3_936 = torch.constant.int 3
    %757 = torch.prim.ListConstruct %int2_935, %int3_936 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_937 = torch.constant.int 0
    %true_938 = torch.constant.bool true
    %result0_939, %result1_940 = torch.aten.var_mean.correction %756, %757, %int0_937, %true_938 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_941 = torch.constant.float 9.9999999999999995E-7
    %int1_942 = torch.constant.int 1
    %758 = torch.aten.add.Scalar %result0_939, %float9.999990e-07_941, %int1_942 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %759 = torch.aten.rsqrt %758 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_943 = torch.constant.int 1
    %760 = torch.aten.sub.Tensor %755, %result1_940, %int1_943 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %761 = torch.aten.mul.Tensor %760, %759 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_944 = torch.constant.int 1
    %int256_945 = torch.constant.int 256
    %int512_946 = torch.constant.int 512
    %int512_947 = torch.constant.int 512
    %762 = torch.prim.ListConstruct %int1_944, %int256_945, %int512_946, %int512_947 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %763 = torch.aten.view %761, %762 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16>
    %764 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_948 = torch.constant.int 0
    %765 = torch.aten.unsqueeze %764, %int0_948 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_949 = torch.constant.int 2
    %766 = torch.aten.unsqueeze %765, %int2_949 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_950 = torch.constant.int 3
    %767 = torch.aten.unsqueeze %766, %int3_950 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16>
    %768 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_951 = torch.constant.int 0
    %769 = torch.aten.unsqueeze %768, %int0_951 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_952 = torch.constant.int 2
    %770 = torch.aten.unsqueeze %769, %int2_952 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_953 = torch.constant.int 3
    %771 = torch.aten.unsqueeze %770, %int3_953 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %772 = torch.aten.mul.Tensor %763, %771 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_954 = torch.constant.int 1
    %773 = torch.aten.add.Tensor %772, %767, %int1_954 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_955 = torch.constant.int 5
    %774 = torch.prims.convert_element_type %773, %int5_955 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %775 = torch.aten.silu %774 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_956 = torch.constant.none
    %776 = torch.aten.clone %775, %none_956 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16>
    %777 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16>
    %778 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_957 = torch.constant.int 1
    %int1_958 = torch.constant.int 1
    %779 = torch.prim.ListConstruct %int1_957, %int1_958 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_959 = torch.constant.int 1
    %int1_960 = torch.constant.int 1
    %780 = torch.prim.ListConstruct %int1_959, %int1_960 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_961 = torch.constant.int 1
    %int1_962 = torch.constant.int 1
    %781 = torch.prim.ListConstruct %int1_961, %int1_962 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_963 = torch.constant.bool false
    %int0_964 = torch.constant.int 0
    %int0_965 = torch.constant.int 0
    %782 = torch.prim.ListConstruct %int0_964, %int0_965 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_966 = torch.constant.int 1
    %783 = torch.aten.convolution %776, %777, %778, %779, %780, %781, %false_963, %782, %int1_966 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_967 = torch.constant.int 1
    %784 = torch.aten.add.Tensor %724, %783, %int1_967 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_968 = torch.constant.float 1.000000e+00
    %785 = torch.aten.div.Scalar %784, %float1.000000e00_968 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int1_969 = torch.constant.int 1
    %int32_970 = torch.constant.int 32
    %int8_971 = torch.constant.int 8
    %int262144_972 = torch.constant.int 262144
    %786 = torch.prim.ListConstruct %int1_969, %int32_970, %int8_971, %int262144_972 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %787 = torch.aten.view %785, %786 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_973 = torch.constant.int 6
    %788 = torch.prims.convert_element_type %787, %int6_973 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_974 = torch.constant.int 2
    %int3_975 = torch.constant.int 3
    %789 = torch.prim.ListConstruct %int2_974, %int3_975 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_976 = torch.constant.int 0
    %true_977 = torch.constant.bool true
    %result0_978, %result1_979 = torch.aten.var_mean.correction %788, %789, %int0_976, %true_977 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_980 = torch.constant.float 9.9999999999999995E-7
    %int1_981 = torch.constant.int 1
    %790 = torch.aten.add.Scalar %result0_978, %float9.999990e-07_980, %int1_981 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %791 = torch.aten.rsqrt %790 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_982 = torch.constant.int 1
    %792 = torch.aten.sub.Tensor %787, %result1_979, %int1_982 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %793 = torch.aten.mul.Tensor %792, %791 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_983 = torch.constant.int 1
    %int256_984 = torch.constant.int 256
    %int512_985 = torch.constant.int 512
    %int512_986 = torch.constant.int 512
    %794 = torch.prim.ListConstruct %int1_983, %int256_984, %int512_985, %int512_986 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %795 = torch.aten.view %793, %794 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16>
    %796 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_987 = torch.constant.int 0
    %797 = torch.aten.unsqueeze %796, %int0_987 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_988 = torch.constant.int 2
    %798 = torch.aten.unsqueeze %797, %int2_988 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_989 = torch.constant.int 3
    %799 = torch.aten.unsqueeze %798, %int3_989 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16>
    %800 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_990 = torch.constant.int 0
    %801 = torch.aten.unsqueeze %800, %int0_990 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_991 = torch.constant.int 2
    %802 = torch.aten.unsqueeze %801, %int2_991 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_992 = torch.constant.int 3
    %803 = torch.aten.unsqueeze %802, %int3_992 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %804 = torch.aten.mul.Tensor %795, %803 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_993 = torch.constant.int 1
    %805 = torch.aten.add.Tensor %804, %799, %int1_993 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_994 = torch.constant.int 5
    %806 = torch.prims.convert_element_type %805, %int5_994 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %807 = torch.aten.silu %806 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16>
    %808 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16>
    %809 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_995 = torch.constant.int 1
    %int1_996 = torch.constant.int 1
    %810 = torch.prim.ListConstruct %int1_995, %int1_996 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_997 = torch.constant.int 1
    %int1_998 = torch.constant.int 1
    %811 = torch.prim.ListConstruct %int1_997, %int1_998 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_999 = torch.constant.int 1
    %int1_1000 = torch.constant.int 1
    %812 = torch.prim.ListConstruct %int1_999, %int1_1000 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1001 = torch.constant.bool false
    %int0_1002 = torch.constant.int 0
    %int0_1003 = torch.constant.int 0
    %813 = torch.prim.ListConstruct %int0_1002, %int0_1003 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1004 = torch.constant.int 1
    %814 = torch.aten.convolution %807, %808, %809, %810, %811, %812, %false_1001, %813, %int1_1004 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1005 = torch.constant.int 1
    %int32_1006 = torch.constant.int 32
    %int8_1007 = torch.constant.int 8
    %int262144_1008 = torch.constant.int 262144
    %815 = torch.prim.ListConstruct %int1_1005, %int32_1006, %int8_1007, %int262144_1008 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %816 = torch.aten.view %814, %815 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_1009 = torch.constant.int 6
    %817 = torch.prims.convert_element_type %816, %int6_1009 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_1010 = torch.constant.int 2
    %int3_1011 = torch.constant.int 3
    %818 = torch.prim.ListConstruct %int2_1010, %int3_1011 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1012 = torch.constant.int 0
    %true_1013 = torch.constant.bool true
    %result0_1014, %result1_1015 = torch.aten.var_mean.correction %817, %818, %int0_1012, %true_1013 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1016 = torch.constant.float 9.9999999999999995E-7
    %int1_1017 = torch.constant.int 1
    %819 = torch.aten.add.Scalar %result0_1014, %float9.999990e-07_1016, %int1_1017 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %820 = torch.aten.rsqrt %819 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1018 = torch.constant.int 1
    %821 = torch.aten.sub.Tensor %816, %result1_1015, %int1_1018 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %822 = torch.aten.mul.Tensor %821, %820 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_1019 = torch.constant.int 1
    %int256_1020 = torch.constant.int 256
    %int512_1021 = torch.constant.int 512
    %int512_1022 = torch.constant.int 512
    %823 = torch.prim.ListConstruct %int1_1019, %int256_1020, %int512_1021, %int512_1022 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %824 = torch.aten.view %822, %823 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16>
    %825 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1023 = torch.constant.int 0
    %826 = torch.aten.unsqueeze %825, %int0_1023 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1024 = torch.constant.int 2
    %827 = torch.aten.unsqueeze %826, %int2_1024 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1025 = torch.constant.int 3
    %828 = torch.aten.unsqueeze %827, %int3_1025 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16>
    %829 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1026 = torch.constant.int 0
    %830 = torch.aten.unsqueeze %829, %int0_1026 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1027 = torch.constant.int 2
    %831 = torch.aten.unsqueeze %830, %int2_1027 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1028 = torch.constant.int 3
    %832 = torch.aten.unsqueeze %831, %int3_1028 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %833 = torch.aten.mul.Tensor %824, %832 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_1029 = torch.constant.int 1
    %834 = torch.aten.add.Tensor %833, %828, %int1_1029 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_1030 = torch.constant.int 5
    %835 = torch.prims.convert_element_type %834, %int5_1030 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %836 = torch.aten.silu %835 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_1031 = torch.constant.none
    %837 = torch.aten.clone %836, %none_1031 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16>
    %838 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16>
    %839 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1032 = torch.constant.int 1
    %int1_1033 = torch.constant.int 1
    %840 = torch.prim.ListConstruct %int1_1032, %int1_1033 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1034 = torch.constant.int 1
    %int1_1035 = torch.constant.int 1
    %841 = torch.prim.ListConstruct %int1_1034, %int1_1035 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1036 = torch.constant.int 1
    %int1_1037 = torch.constant.int 1
    %842 = torch.prim.ListConstruct %int1_1036, %int1_1037 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1038 = torch.constant.bool false
    %int0_1039 = torch.constant.int 0
    %int0_1040 = torch.constant.int 0
    %843 = torch.prim.ListConstruct %int0_1039, %int0_1040 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1041 = torch.constant.int 1
    %844 = torch.aten.convolution %837, %838, %839, %840, %841, %842, %false_1038, %843, %int1_1041 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1042 = torch.constant.int 1
    %845 = torch.aten.add.Tensor %785, %844, %int1_1042 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_1043 = torch.constant.float 1.000000e+00
    %846 = torch.aten.div.Scalar %845, %float1.000000e00_1043 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int6_1044 = torch.constant.int 6
    %847 = torch.prims.convert_element_type %846, %int6_1044 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int1024 = torch.constant.int 1024
    %int6_1045 = torch.constant.int 6
    %none_1046 = torch.constant.none
    %cpu_1047 = torch.constant.device "cpu"
    %false_1048 = torch.constant.bool false
    %848 = torch.aten.arange %int1024, %int6_1045, %none_1046, %cpu_1047, %false_1048 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1049 = torch.constant.float 0.000000e+00
    %int1_1050 = torch.constant.int 1
    %849 = torch.aten.add.Scalar %848, %float0.000000e00_1049, %int1_1050 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1051 = torch.constant.float 5.000000e-01
    %850 = torch.aten.mul.Scalar %849, %float5.000000e-01_1051 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1052 = torch.constant.int 4
    %851 = torch.prims.convert_element_type %850, %int4_1052 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %int-1_1053 = torch.constant.int -1
    %852 = torch.aten.unsqueeze %851, %int-1_1053 : !torch.vtensor<[1024],si64>, !torch.int -> !torch.vtensor<[1024,1],si64>
    %int1024_1054 = torch.constant.int 1024
    %int6_1055 = torch.constant.int 6
    %none_1056 = torch.constant.none
    %cpu_1057 = torch.constant.device "cpu"
    %false_1058 = torch.constant.bool false
    %853 = torch.aten.arange %int1024_1054, %int6_1055, %none_1056, %cpu_1057, %false_1058 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1059 = torch.constant.float 0.000000e+00
    %int1_1060 = torch.constant.int 1
    %854 = torch.aten.add.Scalar %853, %float0.000000e00_1059, %int1_1060 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1061 = torch.constant.float 5.000000e-01
    %855 = torch.aten.mul.Scalar %854, %float5.000000e-01_1061 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1062 = torch.constant.int 4
    %856 = torch.prims.convert_element_type %855, %int4_1062 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %none_1063 = torch.constant.none
    %none_1064 = torch.constant.none
    %857 = torch.prim.ListConstruct %none_1063, %none_1064, %852, %856 : (!torch.none, !torch.none, !torch.vtensor<[1024,1],si64>, !torch.vtensor<[1024],si64>) -> !torch.list<optional<vtensor>>
    %858 = torch.aten.index.Tensor %847, %857 : !torch.vtensor<[1,256,512,512],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,256,1024,1024],f32>
    %int2_1065 = torch.constant.int 2
    %859 = torch.aten.clone %858, %int2_1065 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f32>
    %int5_1066 = torch.constant.int 5
    %860 = torch.prims.convert_element_type %859, %int5_1066 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %__auto.decoder.up_blocks.2.upsamplers.0.conv.weight = util.global.load @__auto.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16>
    %861 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.upsamplers.0.conv.bias = util.global.load @__auto.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16>
    %862 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1067 = torch.constant.int 1
    %int1_1068 = torch.constant.int 1
    %863 = torch.prim.ListConstruct %int1_1067, %int1_1068 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1069 = torch.constant.int 1
    %int1_1070 = torch.constant.int 1
    %864 = torch.prim.ListConstruct %int1_1069, %int1_1070 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1071 = torch.constant.int 1
    %int1_1072 = torch.constant.int 1
    %865 = torch.prim.ListConstruct %int1_1071, %int1_1072 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1073 = torch.constant.bool false
    %int0_1074 = torch.constant.int 0
    %int0_1075 = torch.constant.int 0
    %866 = torch.prim.ListConstruct %int0_1074, %int0_1075 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1076 = torch.constant.int 1
    %867 = torch.aten.convolution %860, %861, %862, %863, %864, %865, %false_1073, %866, %int1_1076 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %int1_1077 = torch.constant.int 1
    %int32_1078 = torch.constant.int 32
    %int8_1079 = torch.constant.int 8
    %int1048576 = torch.constant.int 1048576
    %868 = torch.prim.ListConstruct %int1_1077, %int32_1078, %int8_1079, %int1048576 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %869 = torch.aten.view %867, %868 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,1048576],f16>
    %int6_1080 = torch.constant.int 6
    %870 = torch.prims.convert_element_type %869, %int6_1080 : !torch.vtensor<[1,32,8,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,8,1048576],f32>
    %int2_1081 = torch.constant.int 2
    %int3_1082 = torch.constant.int 3
    %871 = torch.prim.ListConstruct %int2_1081, %int3_1082 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1083 = torch.constant.int 0
    %true_1084 = torch.constant.bool true
    %result0_1085, %result1_1086 = torch.aten.var_mean.correction %870, %871, %int0_1083, %true_1084 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1087 = torch.constant.float 9.9999999999999995E-7
    %int1_1088 = torch.constant.int 1
    %872 = torch.aten.add.Scalar %result0_1085, %float9.999990e-07_1087, %int1_1088 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %873 = torch.aten.rsqrt %872 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1089 = torch.constant.int 1
    %874 = torch.aten.sub.Tensor %869, %result1_1086, %int1_1089 : !torch.vtensor<[1,32,8,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,1048576],f32>
    %875 = torch.aten.mul.Tensor %874, %873 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,1048576],f32>
    %int1_1090 = torch.constant.int 1
    %int256_1091 = torch.constant.int 256
    %int1024_1092 = torch.constant.int 1024
    %int1024_1093 = torch.constant.int 1024
    %876 = torch.prim.ListConstruct %int1_1090, %int256_1091, %int1024_1092, %int1024_1093 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %877 = torch.aten.view %875, %876 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,256,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16>
    %878 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1094 = torch.constant.int 0
    %879 = torch.aten.unsqueeze %878, %int0_1094 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1095 = torch.constant.int 2
    %880 = torch.aten.unsqueeze %879, %int2_1095 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1096 = torch.constant.int 3
    %881 = torch.aten.unsqueeze %880, %int3_1096 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16>
    %882 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1097 = torch.constant.int 0
    %883 = torch.aten.unsqueeze %882, %int0_1097 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1098 = torch.constant.int 2
    %884 = torch.aten.unsqueeze %883, %int2_1098 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1099 = torch.constant.int 3
    %885 = torch.aten.unsqueeze %884, %int3_1099 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %886 = torch.aten.mul.Tensor %877, %885 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,1024,1024],f32>
    %int1_1100 = torch.constant.int 1
    %887 = torch.aten.add.Tensor %886, %881, %int1_1100 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f32>
    %int5_1101 = torch.constant.int 5
    %888 = torch.prims.convert_element_type %887, %int5_1101 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %889 = torch.aten.silu %888 : !torch.vtensor<[1,256,1024,1024],f16> -> !torch.vtensor<[1,256,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16>
    %890 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16> -> !torch.vtensor<[128,256,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16>
    %891 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1102 = torch.constant.int 1
    %int1_1103 = torch.constant.int 1
    %892 = torch.prim.ListConstruct %int1_1102, %int1_1103 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1104 = torch.constant.int 1
    %int1_1105 = torch.constant.int 1
    %893 = torch.prim.ListConstruct %int1_1104, %int1_1105 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1106 = torch.constant.int 1
    %int1_1107 = torch.constant.int 1
    %894 = torch.prim.ListConstruct %int1_1106, %int1_1107 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1108 = torch.constant.bool false
    %int0_1109 = torch.constant.int 0
    %int0_1110 = torch.constant.int 0
    %895 = torch.prim.ListConstruct %int0_1109, %int0_1110 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1111 = torch.constant.int 1
    %896 = torch.aten.convolution %889, %890, %891, %892, %893, %894, %false_1108, %895, %int1_1111 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[128,256,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1112 = torch.constant.int 1
    %int32_1113 = torch.constant.int 32
    %int4_1114 = torch.constant.int 4
    %int1048576_1115 = torch.constant.int 1048576
    %897 = torch.prim.ListConstruct %int1_1112, %int32_1113, %int4_1114, %int1048576_1115 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %898 = torch.aten.view %896, %897 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1116 = torch.constant.int 6
    %899 = torch.prims.convert_element_type %898, %int6_1116 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1117 = torch.constant.int 2
    %int3_1118 = torch.constant.int 3
    %900 = torch.prim.ListConstruct %int2_1117, %int3_1118 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1119 = torch.constant.int 0
    %true_1120 = torch.constant.bool true
    %result0_1121, %result1_1122 = torch.aten.var_mean.correction %899, %900, %int0_1119, %true_1120 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1123 = torch.constant.float 9.9999999999999995E-7
    %int1_1124 = torch.constant.int 1
    %901 = torch.aten.add.Scalar %result0_1121, %float9.999990e-07_1123, %int1_1124 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %902 = torch.aten.rsqrt %901 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1125 = torch.constant.int 1
    %903 = torch.aten.sub.Tensor %898, %result1_1122, %int1_1125 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %904 = torch.aten.mul.Tensor %903, %902 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1126 = torch.constant.int 1
    %int128_1127 = torch.constant.int 128
    %int1024_1128 = torch.constant.int 1024
    %int1024_1129 = torch.constant.int 1024
    %905 = torch.prim.ListConstruct %int1_1126, %int128_1127, %int1024_1128, %int1024_1129 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %906 = torch.aten.view %904, %905 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16>
    %907 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1130 = torch.constant.int 0
    %908 = torch.aten.unsqueeze %907, %int0_1130 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1131 = torch.constant.int 2
    %909 = torch.aten.unsqueeze %908, %int2_1131 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1132 = torch.constant.int 3
    %910 = torch.aten.unsqueeze %909, %int3_1132 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16>
    %911 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1133 = torch.constant.int 0
    %912 = torch.aten.unsqueeze %911, %int0_1133 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1134 = torch.constant.int 2
    %913 = torch.aten.unsqueeze %912, %int2_1134 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1135 = torch.constant.int 3
    %914 = torch.aten.unsqueeze %913, %int3_1135 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %915 = torch.aten.mul.Tensor %906, %914 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1136 = torch.constant.int 1
    %916 = torch.aten.add.Tensor %915, %910, %int1_1136 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1137 = torch.constant.int 5
    %917 = torch.prims.convert_element_type %916, %int5_1137 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %918 = torch.aten.silu %917 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1138 = torch.constant.none
    %919 = torch.aten.clone %918, %none_1138 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16>
    %920 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16>
    %921 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1139 = torch.constant.int 1
    %int1_1140 = torch.constant.int 1
    %922 = torch.prim.ListConstruct %int1_1139, %int1_1140 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1141 = torch.constant.int 1
    %int1_1142 = torch.constant.int 1
    %923 = torch.prim.ListConstruct %int1_1141, %int1_1142 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1143 = torch.constant.int 1
    %int1_1144 = torch.constant.int 1
    %924 = torch.prim.ListConstruct %int1_1143, %int1_1144 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1145 = torch.constant.bool false
    %int0_1146 = torch.constant.int 0
    %int0_1147 = torch.constant.int 0
    %925 = torch.prim.ListConstruct %int0_1146, %int0_1147 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1148 = torch.constant.int 1
    %926 = torch.aten.convolution %919, %920, %921, %922, %923, %924, %false_1145, %925, %int1_1148 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16>
    %927 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16> -> !torch.vtensor<[128,256,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16>
    %928 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1149 = torch.constant.int 1
    %int1_1150 = torch.constant.int 1
    %929 = torch.prim.ListConstruct %int1_1149, %int1_1150 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1151 = torch.constant.int 0
    %int0_1152 = torch.constant.int 0
    %930 = torch.prim.ListConstruct %int0_1151, %int0_1152 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1153 = torch.constant.int 1
    %int1_1154 = torch.constant.int 1
    %931 = torch.prim.ListConstruct %int1_1153, %int1_1154 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1155 = torch.constant.bool false
    %int0_1156 = torch.constant.int 0
    %int0_1157 = torch.constant.int 0
    %932 = torch.prim.ListConstruct %int0_1156, %int0_1157 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1158 = torch.constant.int 1
    %933 = torch.aten.convolution %867, %927, %928, %929, %930, %931, %false_1155, %932, %int1_1158 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[128,256,1,1],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1159 = torch.constant.int 1
    %934 = torch.aten.add.Tensor %933, %926, %int1_1159 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1160 = torch.constant.float 1.000000e+00
    %935 = torch.aten.div.Scalar %934, %float1.000000e00_1160 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1161 = torch.constant.int 1
    %int32_1162 = torch.constant.int 32
    %int4_1163 = torch.constant.int 4
    %int1048576_1164 = torch.constant.int 1048576
    %936 = torch.prim.ListConstruct %int1_1161, %int32_1162, %int4_1163, %int1048576_1164 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %937 = torch.aten.view %935, %936 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1165 = torch.constant.int 6
    %938 = torch.prims.convert_element_type %937, %int6_1165 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1166 = torch.constant.int 2
    %int3_1167 = torch.constant.int 3
    %939 = torch.prim.ListConstruct %int2_1166, %int3_1167 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1168 = torch.constant.int 0
    %true_1169 = torch.constant.bool true
    %result0_1170, %result1_1171 = torch.aten.var_mean.correction %938, %939, %int0_1168, %true_1169 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1172 = torch.constant.float 9.9999999999999995E-7
    %int1_1173 = torch.constant.int 1
    %940 = torch.aten.add.Scalar %result0_1170, %float9.999990e-07_1172, %int1_1173 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %941 = torch.aten.rsqrt %940 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1174 = torch.constant.int 1
    %942 = torch.aten.sub.Tensor %937, %result1_1171, %int1_1174 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %943 = torch.aten.mul.Tensor %942, %941 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1175 = torch.constant.int 1
    %int128_1176 = torch.constant.int 128
    %int1024_1177 = torch.constant.int 1024
    %int1024_1178 = torch.constant.int 1024
    %944 = torch.prim.ListConstruct %int1_1175, %int128_1176, %int1024_1177, %int1024_1178 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %945 = torch.aten.view %943, %944 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16>
    %946 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1179 = torch.constant.int 0
    %947 = torch.aten.unsqueeze %946, %int0_1179 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1180 = torch.constant.int 2
    %948 = torch.aten.unsqueeze %947, %int2_1180 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1181 = torch.constant.int 3
    %949 = torch.aten.unsqueeze %948, %int3_1181 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16>
    %950 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1182 = torch.constant.int 0
    %951 = torch.aten.unsqueeze %950, %int0_1182 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1183 = torch.constant.int 2
    %952 = torch.aten.unsqueeze %951, %int2_1183 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1184 = torch.constant.int 3
    %953 = torch.aten.unsqueeze %952, %int3_1184 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %954 = torch.aten.mul.Tensor %945, %953 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1185 = torch.constant.int 1
    %955 = torch.aten.add.Tensor %954, %949, %int1_1185 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1186 = torch.constant.int 5
    %956 = torch.prims.convert_element_type %955, %int5_1186 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %957 = torch.aten.silu %956 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16>
    %958 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16>
    %959 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1187 = torch.constant.int 1
    %int1_1188 = torch.constant.int 1
    %960 = torch.prim.ListConstruct %int1_1187, %int1_1188 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1189 = torch.constant.int 1
    %int1_1190 = torch.constant.int 1
    %961 = torch.prim.ListConstruct %int1_1189, %int1_1190 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1191 = torch.constant.int 1
    %int1_1192 = torch.constant.int 1
    %962 = torch.prim.ListConstruct %int1_1191, %int1_1192 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1193 = torch.constant.bool false
    %int0_1194 = torch.constant.int 0
    %int0_1195 = torch.constant.int 0
    %963 = torch.prim.ListConstruct %int0_1194, %int0_1195 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1196 = torch.constant.int 1
    %964 = torch.aten.convolution %957, %958, %959, %960, %961, %962, %false_1193, %963, %int1_1196 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1197 = torch.constant.int 1
    %int32_1198 = torch.constant.int 32
    %int4_1199 = torch.constant.int 4
    %int1048576_1200 = torch.constant.int 1048576
    %965 = torch.prim.ListConstruct %int1_1197, %int32_1198, %int4_1199, %int1048576_1200 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %966 = torch.aten.view %964, %965 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1201 = torch.constant.int 6
    %967 = torch.prims.convert_element_type %966, %int6_1201 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1202 = torch.constant.int 2
    %int3_1203 = torch.constant.int 3
    %968 = torch.prim.ListConstruct %int2_1202, %int3_1203 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1204 = torch.constant.int 0
    %true_1205 = torch.constant.bool true
    %result0_1206, %result1_1207 = torch.aten.var_mean.correction %967, %968, %int0_1204, %true_1205 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1208 = torch.constant.float 9.9999999999999995E-7
    %int1_1209 = torch.constant.int 1
    %969 = torch.aten.add.Scalar %result0_1206, %float9.999990e-07_1208, %int1_1209 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %970 = torch.aten.rsqrt %969 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1210 = torch.constant.int 1
    %971 = torch.aten.sub.Tensor %966, %result1_1207, %int1_1210 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %972 = torch.aten.mul.Tensor %971, %970 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1211 = torch.constant.int 1
    %int128_1212 = torch.constant.int 128
    %int1024_1213 = torch.constant.int 1024
    %int1024_1214 = torch.constant.int 1024
    %973 = torch.prim.ListConstruct %int1_1211, %int128_1212, %int1024_1213, %int1024_1214 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %974 = torch.aten.view %972, %973 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16>
    %975 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1215 = torch.constant.int 0
    %976 = torch.aten.unsqueeze %975, %int0_1215 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1216 = torch.constant.int 2
    %977 = torch.aten.unsqueeze %976, %int2_1216 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1217 = torch.constant.int 3
    %978 = torch.aten.unsqueeze %977, %int3_1217 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16>
    %979 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1218 = torch.constant.int 0
    %980 = torch.aten.unsqueeze %979, %int0_1218 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1219 = torch.constant.int 2
    %981 = torch.aten.unsqueeze %980, %int2_1219 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1220 = torch.constant.int 3
    %982 = torch.aten.unsqueeze %981, %int3_1220 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %983 = torch.aten.mul.Tensor %974, %982 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1221 = torch.constant.int 1
    %984 = torch.aten.add.Tensor %983, %978, %int1_1221 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1222 = torch.constant.int 5
    %985 = torch.prims.convert_element_type %984, %int5_1222 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %986 = torch.aten.silu %985 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1223 = torch.constant.none
    %987 = torch.aten.clone %986, %none_1223 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16>
    %988 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16>
    %989 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1224 = torch.constant.int 1
    %int1_1225 = torch.constant.int 1
    %990 = torch.prim.ListConstruct %int1_1224, %int1_1225 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1226 = torch.constant.int 1
    %int1_1227 = torch.constant.int 1
    %991 = torch.prim.ListConstruct %int1_1226, %int1_1227 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1228 = torch.constant.int 1
    %int1_1229 = torch.constant.int 1
    %992 = torch.prim.ListConstruct %int1_1228, %int1_1229 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1230 = torch.constant.bool false
    %int0_1231 = torch.constant.int 0
    %int0_1232 = torch.constant.int 0
    %993 = torch.prim.ListConstruct %int0_1231, %int0_1232 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1233 = torch.constant.int 1
    %994 = torch.aten.convolution %987, %988, %989, %990, %991, %992, %false_1230, %993, %int1_1233 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1234 = torch.constant.int 1
    %995 = torch.aten.add.Tensor %935, %994, %int1_1234 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1235 = torch.constant.float 1.000000e+00
    %996 = torch.aten.div.Scalar %995, %float1.000000e00_1235 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1236 = torch.constant.int 1
    %int32_1237 = torch.constant.int 32
    %int4_1238 = torch.constant.int 4
    %int1048576_1239 = torch.constant.int 1048576
    %997 = torch.prim.ListConstruct %int1_1236, %int32_1237, %int4_1238, %int1048576_1239 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %998 = torch.aten.view %996, %997 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1240 = torch.constant.int 6
    %999 = torch.prims.convert_element_type %998, %int6_1240 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1241 = torch.constant.int 2
    %int3_1242 = torch.constant.int 3
    %1000 = torch.prim.ListConstruct %int2_1241, %int3_1242 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1243 = torch.constant.int 0
    %true_1244 = torch.constant.bool true
    %result0_1245, %result1_1246 = torch.aten.var_mean.correction %999, %1000, %int0_1243, %true_1244 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1247 = torch.constant.float 9.9999999999999995E-7
    %int1_1248 = torch.constant.int 1
    %1001 = torch.aten.add.Scalar %result0_1245, %float9.999990e-07_1247, %int1_1248 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1002 = torch.aten.rsqrt %1001 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1249 = torch.constant.int 1
    %1003 = torch.aten.sub.Tensor %998, %result1_1246, %int1_1249 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1004 = torch.aten.mul.Tensor %1003, %1002 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1250 = torch.constant.int 1
    %int128_1251 = torch.constant.int 128
    %int1024_1252 = torch.constant.int 1024
    %int1024_1253 = torch.constant.int 1024
    %1005 = torch.prim.ListConstruct %int1_1250, %int128_1251, %int1024_1252, %int1024_1253 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1006 = torch.aten.view %1004, %1005 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16>
    %1007 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1254 = torch.constant.int 0
    %1008 = torch.aten.unsqueeze %1007, %int0_1254 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1255 = torch.constant.int 2
    %1009 = torch.aten.unsqueeze %1008, %int2_1255 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1256 = torch.constant.int 3
    %1010 = torch.aten.unsqueeze %1009, %int3_1256 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16>
    %1011 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1257 = torch.constant.int 0
    %1012 = torch.aten.unsqueeze %1011, %int0_1257 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1258 = torch.constant.int 2
    %1013 = torch.aten.unsqueeze %1012, %int2_1258 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1259 = torch.constant.int 3
    %1014 = torch.aten.unsqueeze %1013, %int3_1259 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1015 = torch.aten.mul.Tensor %1006, %1014 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1260 = torch.constant.int 1
    %1016 = torch.aten.add.Tensor %1015, %1010, %int1_1260 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1261 = torch.constant.int 5
    %1017 = torch.prims.convert_element_type %1016, %int5_1261 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %1018 = torch.aten.silu %1017 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16>
    %1019 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16>
    %1020 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1262 = torch.constant.int 1
    %int1_1263 = torch.constant.int 1
    %1021 = torch.prim.ListConstruct %int1_1262, %int1_1263 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1264 = torch.constant.int 1
    %int1_1265 = torch.constant.int 1
    %1022 = torch.prim.ListConstruct %int1_1264, %int1_1265 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1266 = torch.constant.int 1
    %int1_1267 = torch.constant.int 1
    %1023 = torch.prim.ListConstruct %int1_1266, %int1_1267 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1268 = torch.constant.bool false
    %int0_1269 = torch.constant.int 0
    %int0_1270 = torch.constant.int 0
    %1024 = torch.prim.ListConstruct %int0_1269, %int0_1270 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1271 = torch.constant.int 1
    %1025 = torch.aten.convolution %1018, %1019, %1020, %1021, %1022, %1023, %false_1268, %1024, %int1_1271 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1272 = torch.constant.int 1
    %int32_1273 = torch.constant.int 32
    %int4_1274 = torch.constant.int 4
    %int1048576_1275 = torch.constant.int 1048576
    %1026 = torch.prim.ListConstruct %int1_1272, %int32_1273, %int4_1274, %int1048576_1275 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1027 = torch.aten.view %1025, %1026 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1276 = torch.constant.int 6
    %1028 = torch.prims.convert_element_type %1027, %int6_1276 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1277 = torch.constant.int 2
    %int3_1278 = torch.constant.int 3
    %1029 = torch.prim.ListConstruct %int2_1277, %int3_1278 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1279 = torch.constant.int 0
    %true_1280 = torch.constant.bool true
    %result0_1281, %result1_1282 = torch.aten.var_mean.correction %1028, %1029, %int0_1279, %true_1280 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1283 = torch.constant.float 9.9999999999999995E-7
    %int1_1284 = torch.constant.int 1
    %1030 = torch.aten.add.Scalar %result0_1281, %float9.999990e-07_1283, %int1_1284 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1031 = torch.aten.rsqrt %1030 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1285 = torch.constant.int 1
    %1032 = torch.aten.sub.Tensor %1027, %result1_1282, %int1_1285 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1033 = torch.aten.mul.Tensor %1032, %1031 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1286 = torch.constant.int 1
    %int128_1287 = torch.constant.int 128
    %int1024_1288 = torch.constant.int 1024
    %int1024_1289 = torch.constant.int 1024
    %1034 = torch.prim.ListConstruct %int1_1286, %int128_1287, %int1024_1288, %int1024_1289 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1035 = torch.aten.view %1033, %1034 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16>
    %1036 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1290 = torch.constant.int 0
    %1037 = torch.aten.unsqueeze %1036, %int0_1290 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1291 = torch.constant.int 2
    %1038 = torch.aten.unsqueeze %1037, %int2_1291 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1292 = torch.constant.int 3
    %1039 = torch.aten.unsqueeze %1038, %int3_1292 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16>
    %1040 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1293 = torch.constant.int 0
    %1041 = torch.aten.unsqueeze %1040, %int0_1293 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1294 = torch.constant.int 2
    %1042 = torch.aten.unsqueeze %1041, %int2_1294 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1295 = torch.constant.int 3
    %1043 = torch.aten.unsqueeze %1042, %int3_1295 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1044 = torch.aten.mul.Tensor %1035, %1043 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1296 = torch.constant.int 1
    %1045 = torch.aten.add.Tensor %1044, %1039, %int1_1296 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1297 = torch.constant.int 5
    %1046 = torch.prims.convert_element_type %1045, %int5_1297 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %1047 = torch.aten.silu %1046 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1298 = torch.constant.none
    %1048 = torch.aten.clone %1047, %none_1298 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16>
    %1049 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16>
    %1050 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1299 = torch.constant.int 1
    %int1_1300 = torch.constant.int 1
    %1051 = torch.prim.ListConstruct %int1_1299, %int1_1300 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1301 = torch.constant.int 1
    %int1_1302 = torch.constant.int 1
    %1052 = torch.prim.ListConstruct %int1_1301, %int1_1302 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1303 = torch.constant.int 1
    %int1_1304 = torch.constant.int 1
    %1053 = torch.prim.ListConstruct %int1_1303, %int1_1304 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1305 = torch.constant.bool false
    %int0_1306 = torch.constant.int 0
    %int0_1307 = torch.constant.int 0
    %1054 = torch.prim.ListConstruct %int0_1306, %int0_1307 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1308 = torch.constant.int 1
    %1055 = torch.aten.convolution %1048, %1049, %1050, %1051, %1052, %1053, %false_1305, %1054, %int1_1308 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1309 = torch.constant.int 1
    %1056 = torch.aten.add.Tensor %996, %1055, %int1_1309 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1310 = torch.constant.float 1.000000e+00
    %1057 = torch.aten.div.Scalar %1056, %float1.000000e00_1310 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1311 = torch.constant.int 1
    %int32_1312 = torch.constant.int 32
    %int4_1313 = torch.constant.int 4
    %int1048576_1314 = torch.constant.int 1048576
    %1058 = torch.prim.ListConstruct %int1_1311, %int32_1312, %int4_1313, %int1048576_1314 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1059 = torch.aten.view %1057, %1058 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1315 = torch.constant.int 6
    %1060 = torch.prims.convert_element_type %1059, %int6_1315 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1316 = torch.constant.int 2
    %int3_1317 = torch.constant.int 3
    %1061 = torch.prim.ListConstruct %int2_1316, %int3_1317 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1318 = torch.constant.int 0
    %true_1319 = torch.constant.bool true
    %result0_1320, %result1_1321 = torch.aten.var_mean.correction %1060, %1061, %int0_1318, %true_1319 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1322 = torch.constant.float 9.9999999999999995E-7
    %int1_1323 = torch.constant.int 1
    %1062 = torch.aten.add.Scalar %result0_1320, %float9.999990e-07_1322, %int1_1323 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1063 = torch.aten.rsqrt %1062 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1324 = torch.constant.int 1
    %1064 = torch.aten.sub.Tensor %1059, %result1_1321, %int1_1324 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1065 = torch.aten.mul.Tensor %1064, %1063 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1325 = torch.constant.int 1
    %int128_1326 = torch.constant.int 128
    %int1024_1327 = torch.constant.int 1024
    %int1024_1328 = torch.constant.int 1024
    %1066 = torch.prim.ListConstruct %int1_1325, %int128_1326, %int1024_1327, %int1024_1328 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1067 = torch.aten.view %1065, %1066 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.decoder.conv_norm_out.bias = util.global.load @__auto.decoder.conv_norm_out.bias : tensor<128xf16>
    %1068 = torch_c.from_builtin_tensor %__auto.decoder.conv_norm_out.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1329 = torch.constant.int 0
    %1069 = torch.aten.unsqueeze %1068, %int0_1329 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1330 = torch.constant.int 2
    %1070 = torch.aten.unsqueeze %1069, %int2_1330 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1331 = torch.constant.int 3
    %1071 = torch.aten.unsqueeze %1070, %int3_1331 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.conv_norm_out.weight = util.global.load @__auto.decoder.conv_norm_out.weight : tensor<128xf16>
    %1072 = torch_c.from_builtin_tensor %__auto.decoder.conv_norm_out.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1332 = torch.constant.int 0
    %1073 = torch.aten.unsqueeze %1072, %int0_1332 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1333 = torch.constant.int 2
    %1074 = torch.aten.unsqueeze %1073, %int2_1333 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1334 = torch.constant.int 3
    %1075 = torch.aten.unsqueeze %1074, %int3_1334 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1076 = torch.aten.mul.Tensor %1067, %1075 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1335 = torch.constant.int 1
    %1077 = torch.aten.add.Tensor %1076, %1071, %int1_1335 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1336 = torch.constant.int 5
    %1078 = torch.prims.convert_element_type %1077, %int5_1336 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %1079 = torch.aten.silu %1078 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.decoder.conv_out.weight = util.global.load @__auto.decoder.conv_out.weight : tensor<3x128x3x3xf16>
    %1080 = torch_c.from_builtin_tensor %__auto.decoder.conv_out.weight : tensor<3x128x3x3xf16> -> !torch.vtensor<[3,128,3,3],f16>
    %__auto.decoder.conv_out.bias = util.global.load @__auto.decoder.conv_out.bias : tensor<3xf16>
    %1081 = torch_c.from_builtin_tensor %__auto.decoder.conv_out.bias : tensor<3xf16> -> !torch.vtensor<[3],f16>
    %int1_1337 = torch.constant.int 1
    %int1_1338 = torch.constant.int 1
    %1082 = torch.prim.ListConstruct %int1_1337, %int1_1338 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1339 = torch.constant.int 1
    %int1_1340 = torch.constant.int 1
    %1083 = torch.prim.ListConstruct %int1_1339, %int1_1340 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1341 = torch.constant.int 1
    %int1_1342 = torch.constant.int 1
    %1084 = torch.prim.ListConstruct %int1_1341, %int1_1342 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1343 = torch.constant.bool false
    %int0_1344 = torch.constant.int 0
    %int0_1345 = torch.constant.int 0
    %1085 = torch.prim.ListConstruct %int0_1344, %int0_1345 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1346 = torch.constant.int 1
    %1086 = torch.aten.convolution %1079, %1080, %1081, %1082, %1083, %1084, %false_1343, %1085, %int1_1346 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[3,128,3,3],f16>, !torch.vtensor<[3],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %int2_1347 = torch.constant.int 2
    %1087 = torch.aten.div.Scalar %1086, %int2_1347 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %float5.000000e-01_1348 = torch.constant.float 5.000000e-01
    %int1_1349 = torch.constant.int 1
    %1088 = torch.aten.add.Scalar %1087, %float5.000000e-01_1348, %int1_1349 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.float, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %int0_1350 = torch.constant.int 0
    %int1_1351 = torch.constant.int 1
    %1089 = torch.aten.clamp %1088, %int0_1350, %int1_1351 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    return %1089 : !torch.vtensor<[1,3,1024,1024],f16>
  }
}
