module @compiled_vae {
  util.global private @__auto.post_quant_conv.weight = #stream.parameter.named<"model"::"post_quant_conv.weight"> : tensor<4x4x1x1xf16>
  util.global private @__auto.post_quant_conv.bias = #stream.parameter.named<"model"::"post_quant_conv.bias"> : tensor<4xf16>
  util.global private @__auto.decoder.conv_in.weight = #stream.parameter.named<"model"::"decoder.conv_in.weight"> : tensor<512x4x3x3xf16>
  util.global private @__auto.decoder.conv_in.bias = #stream.parameter.named<"model"::"decoder.conv_in.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.group_norm.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.group_norm.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_q.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_q.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_k.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_k.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_v.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_v.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_out.0.weight = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @__auto.decoder.mid_block.attentions.0.to_out.0.bias = #stream.parameter.named<"model"::"decoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.mid_block.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.0.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"decoder.up_blocks.0.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.0.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"decoder.up_blocks.0.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.1.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"decoder.up_blocks.1.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.1.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"decoder.up_blocks.1.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv1.weight"> : tensor<256x512x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<256x512x1x1xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.resnets.2.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.2.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"decoder.up_blocks.2.upsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.2.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"decoder.up_blocks.2.upsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv1.weight"> : tensor<128x256x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv_shortcut.weight"> : tensor<128x256x1x1xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.0.conv_shortcut.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.1.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv1.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv1.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.norm2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv2.weight = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.decoder.up_blocks.3.resnets.2.conv2.bias = #stream.parameter.named<"model"::"decoder.up_blocks.3.resnets.2.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.conv_norm_out.bias = #stream.parameter.named<"model"::"decoder.conv_norm_out.bias"> : tensor<128xf16>
  util.global private @__auto.decoder.conv_norm_out.weight = #stream.parameter.named<"model"::"decoder.conv_norm_out.weight"> : tensor<128xf16>
  util.global private @__auto.decoder.conv_out.weight = #stream.parameter.named<"model"::"decoder.conv_out.weight"> : tensor<3x128x3x3xf16>
  util.global private @__auto.decoder.conv_out.bias = #stream.parameter.named<"model"::"decoder.conv_out.bias"> : tensor<3xf16>
  func.func @decode(%arg0: !torch.vtensor<[14,4,128,128],f16>) -> !torch.vtensor<[14,3,1024,1024],f16> attributes {iree.reflection = {input_dtypes = "['float16']", input_shapes = "[(14, 4, 128, 128)]", model_name = "vae_decode", output_dtypes = "['float32']", output_shapes = "[(3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024, 3, 1024, 1024)]"}, torch.assume_strict_symbolic_shapes} {
    %float7.677540e00 = torch.constant.float 7.6775431861804221
    %0 = torch.aten.mul.Scalar %arg0, %float7.677540e00 : !torch.vtensor<[14,4,128,128],f16>, !torch.float -> !torch.vtensor<[14,4,128,128],f16>
    %__auto.post_quant_conv.weight = util.global.load @__auto.post_quant_conv.weight : tensor<4x4x1x1xf16>
    %1 = torch_c.from_builtin_tensor %__auto.post_quant_conv.weight : tensor<4x4x1x1xf16> -> !torch.vtensor<[4,4,1,1],f16>
    %__auto.post_quant_conv.bias = util.global.load @__auto.post_quant_conv.bias : tensor<4xf16>
    %2 = torch_c.from_builtin_tensor %__auto.post_quant_conv.bias : tensor<4xf16> -> !torch.vtensor<[4],f16>
    %int1 = torch.constant.int 1
    %int1_0 = torch.constant.int 1
    %3 = torch.prim.ListConstruct %int1, %int1_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0 = torch.constant.int 0
    %int0_1 = torch.constant.int 0
    %4 = torch.prim.ListConstruct %int0, %int0_1 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_2 = torch.constant.int 1
    %int1_3 = torch.constant.int 1
    %5 = torch.prim.ListConstruct %int1_2, %int1_3 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0_4 = torch.constant.int 0
    %int0_5 = torch.constant.int 0
    %6 = torch.prim.ListConstruct %int0_4, %int0_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_6 = torch.constant.int 1
    %7 = torch.aten.convolution %0, %1, %2, %3, %4, %5, %false, %6, %int1_6 : !torch.vtensor<[14,4,128,128],f16>, !torch.vtensor<[4,4,1,1],f16>, !torch.vtensor<[4],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,4,128,128],f16>
    %__auto.decoder.conv_in.weight = util.global.load @__auto.decoder.conv_in.weight : tensor<512x4x3x3xf16>
    %8 = torch_c.from_builtin_tensor %__auto.decoder.conv_in.weight : tensor<512x4x3x3xf16> -> !torch.vtensor<[512,4,3,3],f16>
    %__auto.decoder.conv_in.bias = util.global.load @__auto.decoder.conv_in.bias : tensor<512xf16>
    %9 = torch_c.from_builtin_tensor %__auto.decoder.conv_in.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_7 = torch.constant.int 1
    %int1_8 = torch.constant.int 1
    %10 = torch.prim.ListConstruct %int1_7, %int1_8 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_9 = torch.constant.int 1
    %int1_10 = torch.constant.int 1
    %11 = torch.prim.ListConstruct %int1_9, %int1_10 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_11 = torch.constant.int 1
    %int1_12 = torch.constant.int 1
    %12 = torch.prim.ListConstruct %int1_11, %int1_12 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_13 = torch.constant.bool false
    %int0_14 = torch.constant.int 0
    %int0_15 = torch.constant.int 0
    %13 = torch.prim.ListConstruct %int0_14, %int0_15 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_16 = torch.constant.int 1
    %14 = torch.aten.convolution %7, %8, %9, %10, %11, %12, %false_13, %13, %int1_16 : !torch.vtensor<[14,4,128,128],f16>, !torch.vtensor<[512,4,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14 = torch.constant.int 14
    %int32 = torch.constant.int 32
    %int16 = torch.constant.int 16
    %int16384 = torch.constant.int 16384
    %15 = torch.prim.ListConstruct %int14, %int32, %int16, %int16384 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6 = torch.constant.int 6
    %17 = torch.prims.convert_element_type %16, %int6 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2 = torch.constant.int 2
    %int3 = torch.constant.int 3
    %18 = torch.prim.ListConstruct %int2, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_17 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %17, %18, %int0_17, %true : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07 = torch.constant.float 9.9999999999999995E-7
    %int1_18 = torch.constant.int 1
    %19 = torch.aten.add.Scalar %result0, %float9.999990e-07, %int1_18 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %20 = torch.aten.rsqrt %19 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_19 = torch.constant.int 1
    %21 = torch.aten.sub.Tensor %16, %result1, %int1_19 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %22 = torch.aten.mul.Tensor %21, %20 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_20 = torch.constant.int 14
    %int512 = torch.constant.int 512
    %int128 = torch.constant.int 128
    %int128_21 = torch.constant.int 128
    %23 = torch.prim.ListConstruct %int14_20, %int512, %int128, %int128_21 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %24 = torch.aten.view %22, %23 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.0.norm1.bias = util.global.load @__auto.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16>
    %25 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_22 = torch.constant.int 0
    %26 = torch.aten.unsqueeze %25, %int0_22 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_23 = torch.constant.int 2
    %27 = torch.aten.unsqueeze %26, %int2_23 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_24 = torch.constant.int 3
    %28 = torch.aten.unsqueeze %27, %int3_24 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.0.norm1.weight = util.global.load @__auto.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16>
    %29 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_25 = torch.constant.int 0
    %30 = torch.aten.unsqueeze %29, %int0_25 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_26 = torch.constant.int 2
    %31 = torch.aten.unsqueeze %30, %int2_26 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_27 = torch.constant.int 3
    %32 = torch.aten.unsqueeze %31, %int3_27 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %33 = torch.aten.mul.Tensor %24, %32 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_28 = torch.constant.int 1
    %34 = torch.aten.add.Tensor %33, %28, %int1_28 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5 = torch.constant.int 5
    %35 = torch.prims.convert_element_type %34, %int5 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %36 = torch.aten.silu %35 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.0.conv1.weight = util.global.load @__auto.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %37 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.0.conv1.bias = util.global.load @__auto.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16>
    %38 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_29 = torch.constant.int 1
    %int1_30 = torch.constant.int 1
    %39 = torch.prim.ListConstruct %int1_29, %int1_30 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_31 = torch.constant.int 1
    %int1_32 = torch.constant.int 1
    %40 = torch.prim.ListConstruct %int1_31, %int1_32 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_33 = torch.constant.int 1
    %int1_34 = torch.constant.int 1
    %41 = torch.prim.ListConstruct %int1_33, %int1_34 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_35 = torch.constant.bool false
    %int0_36 = torch.constant.int 0
    %int0_37 = torch.constant.int 0
    %42 = torch.prim.ListConstruct %int0_36, %int0_37 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_38 = torch.constant.int 1
    %43 = torch.aten.convolution %36, %37, %38, %39, %40, %41, %false_35, %42, %int1_38 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_39 = torch.constant.int 14
    %int32_40 = torch.constant.int 32
    %int16_41 = torch.constant.int 16
    %int16384_42 = torch.constant.int 16384
    %44 = torch.prim.ListConstruct %int14_39, %int32_40, %int16_41, %int16384_42 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %45 = torch.aten.view %43, %44 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_43 = torch.constant.int 6
    %46 = torch.prims.convert_element_type %45, %int6_43 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_44 = torch.constant.int 2
    %int3_45 = torch.constant.int 3
    %47 = torch.prim.ListConstruct %int2_44, %int3_45 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_46 = torch.constant.int 0
    %true_47 = torch.constant.bool true
    %result0_48, %result1_49 = torch.aten.var_mean.correction %46, %47, %int0_46, %true_47 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_50 = torch.constant.float 9.9999999999999995E-7
    %int1_51 = torch.constant.int 1
    %48 = torch.aten.add.Scalar %result0_48, %float9.999990e-07_50, %int1_51 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %49 = torch.aten.rsqrt %48 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_52 = torch.constant.int 1
    %50 = torch.aten.sub.Tensor %45, %result1_49, %int1_52 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %51 = torch.aten.mul.Tensor %50, %49 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_53 = torch.constant.int 14
    %int512_54 = torch.constant.int 512
    %int128_55 = torch.constant.int 128
    %int128_56 = torch.constant.int 128
    %52 = torch.prim.ListConstruct %int14_53, %int512_54, %int128_55, %int128_56 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %53 = torch.aten.view %51, %52 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.0.norm2.bias = util.global.load @__auto.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16>
    %54 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_57 = torch.constant.int 0
    %55 = torch.aten.unsqueeze %54, %int0_57 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_58 = torch.constant.int 2
    %56 = torch.aten.unsqueeze %55, %int2_58 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_59 = torch.constant.int 3
    %57 = torch.aten.unsqueeze %56, %int3_59 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.0.norm2.weight = util.global.load @__auto.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16>
    %58 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_60 = torch.constant.int 0
    %59 = torch.aten.unsqueeze %58, %int0_60 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_61 = torch.constant.int 2
    %60 = torch.aten.unsqueeze %59, %int2_61 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_62 = torch.constant.int 3
    %61 = torch.aten.unsqueeze %60, %int3_62 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %62 = torch.aten.mul.Tensor %53, %61 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_63 = torch.constant.int 1
    %63 = torch.aten.add.Tensor %62, %57, %int1_63 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_64 = torch.constant.int 5
    %64 = torch.prims.convert_element_type %63, %int5_64 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %65 = torch.aten.silu %64 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %none = torch.constant.none
    %66 = torch.aten.clone %65, %none : !torch.vtensor<[14,512,128,128],f16>, !torch.none -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.0.conv2.weight = util.global.load @__auto.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %67 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.0.conv2.bias = util.global.load @__auto.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16>
    %68 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_65 = torch.constant.int 1
    %int1_66 = torch.constant.int 1
    %69 = torch.prim.ListConstruct %int1_65, %int1_66 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_67 = torch.constant.int 1
    %int1_68 = torch.constant.int 1
    %70 = torch.prim.ListConstruct %int1_67, %int1_68 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_69 = torch.constant.int 1
    %int1_70 = torch.constant.int 1
    %71 = torch.prim.ListConstruct %int1_69, %int1_70 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_71 = torch.constant.bool false
    %int0_72 = torch.constant.int 0
    %int0_73 = torch.constant.int 0
    %72 = torch.prim.ListConstruct %int0_72, %int0_73 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_74 = torch.constant.int 1
    %73 = torch.aten.convolution %66, %67, %68, %69, %70, %71, %false_71, %72, %int1_74 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_75 = torch.constant.int 1
    %74 = torch.aten.add.Tensor %14, %73, %int1_75 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_76 = torch.constant.int 1
    %75 = torch.aten.div.Scalar %74, %int1_76 : !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_77 = torch.constant.int 14
    %int512_78 = torch.constant.int 512
    %int16384_79 = torch.constant.int 16384
    %76 = torch.prim.ListConstruct %int14_77, %int512_78, %int16384_79 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %77 = torch.aten.view %75, %76 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,512,16384],f16>
    %int1_80 = torch.constant.int 1
    %int2_81 = torch.constant.int 2
    %78 = torch.aten.transpose.int %77, %int1_80, %int2_81 : !torch.vtensor<[14,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %int1_82 = torch.constant.int 1
    %int2_83 = torch.constant.int 2
    %79 = torch.aten.transpose.int %78, %int1_82, %int2_83 : !torch.vtensor<[14,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,512,16384],f16>
    %int14_84 = torch.constant.int 14
    %int32_85 = torch.constant.int 32
    %int16_86 = torch.constant.int 16
    %int16384_87 = torch.constant.int 16384
    %80 = torch.prim.ListConstruct %int14_84, %int32_85, %int16_86, %int16384_87 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %81 = torch.aten.view %79, %80 : !torch.vtensor<[14,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_88 = torch.constant.int 6
    %82 = torch.prims.convert_element_type %81, %int6_88 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_89 = torch.constant.int 2
    %int3_90 = torch.constant.int 3
    %83 = torch.prim.ListConstruct %int2_89, %int3_90 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_91 = torch.constant.int 0
    %true_92 = torch.constant.bool true
    %result0_93, %result1_94 = torch.aten.var_mean.correction %82, %83, %int0_91, %true_92 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_95 = torch.constant.float 9.9999999999999995E-7
    %int1_96 = torch.constant.int 1
    %84 = torch.aten.add.Scalar %result0_93, %float9.999990e-07_95, %int1_96 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %85 = torch.aten.rsqrt %84 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_97 = torch.constant.int 1
    %86 = torch.aten.sub.Tensor %81, %result1_94, %int1_97 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %87 = torch.aten.mul.Tensor %86, %85 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_98 = torch.constant.int 14
    %int512_99 = torch.constant.int 512
    %int16384_100 = torch.constant.int 16384
    %88 = torch.prim.ListConstruct %int14_98, %int512_99, %int16384_100 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %89 = torch.aten.view %87, %88 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,16384],f32>
    %__auto.decoder.mid_block.attentions.0.group_norm.bias = util.global.load @__auto.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16>
    %90 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_101 = torch.constant.int 0
    %91 = torch.aten.unsqueeze %90, %int0_101 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_102 = torch.constant.int 2
    %92 = torch.aten.unsqueeze %91, %int2_102 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %__auto.decoder.mid_block.attentions.0.group_norm.weight = util.global.load @__auto.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16>
    %93 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_103 = torch.constant.int 0
    %94 = torch.aten.unsqueeze %93, %int0_103 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_104 = torch.constant.int 2
    %95 = torch.aten.unsqueeze %94, %int2_104 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %96 = torch.aten.mul.Tensor %89, %95 : !torch.vtensor<[14,512,16384],f32>, !torch.vtensor<[1,512,1],f16> -> !torch.vtensor<[14,512,16384],f32>
    %int1_105 = torch.constant.int 1
    %97 = torch.aten.add.Tensor %96, %92, %int1_105 : !torch.vtensor<[14,512,16384],f32>, !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[14,512,16384],f32>
    %int5_106 = torch.constant.int 5
    %98 = torch.prims.convert_element_type %97, %int5_106 : !torch.vtensor<[14,512,16384],f32>, !torch.int -> !torch.vtensor<[14,512,16384],f16>
    %int1_107 = torch.constant.int 1
    %int2_108 = torch.constant.int 2
    %99 = torch.aten.transpose.int %98, %int1_107, %int2_108 : !torch.vtensor<[14,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_q.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16>
    %100 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_109 = torch.constant.int 0
    %int1_110 = torch.constant.int 1
    %101 = torch.aten.transpose.int %100, %int0_109, %int1_110 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_111 = torch.constant.int 0
    %102 = torch.aten.clone %99, %int0_111 : !torch.vtensor<[14,16384,512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %int229376 = torch.constant.int 229376
    %int512_112 = torch.constant.int 512
    %103 = torch.prim.ListConstruct %int229376, %int512_112 : (!torch.int, !torch.int) -> !torch.list<int>
    %104 = torch.aten._unsafe_view %102, %103 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[229376,512],f16>
    %105 = torch.aten.mm %104, %101 : !torch.vtensor<[229376,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[229376,512],f16>
    %int14_113 = torch.constant.int 14
    %int16384_114 = torch.constant.int 16384
    %int512_115 = torch.constant.int 512
    %106 = torch.prim.ListConstruct %int14_113, %int16384_114, %int512_115 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %107 = torch.aten.view %105, %106 : !torch.vtensor<[229376,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_q.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16>
    %108 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_116 = torch.constant.int 1
    %109 = torch.aten.add.Tensor %107, %108, %int1_116 : !torch.vtensor<[14,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_k.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16>
    %110 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_117 = torch.constant.int 0
    %int1_118 = torch.constant.int 1
    %111 = torch.aten.transpose.int %110, %int0_117, %int1_118 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_119 = torch.constant.int 0
    %112 = torch.aten.clone %99, %int0_119 : !torch.vtensor<[14,16384,512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %int229376_120 = torch.constant.int 229376
    %int512_121 = torch.constant.int 512
    %113 = torch.prim.ListConstruct %int229376_120, %int512_121 : (!torch.int, !torch.int) -> !torch.list<int>
    %114 = torch.aten._unsafe_view %112, %113 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[229376,512],f16>
    %115 = torch.aten.mm %114, %111 : !torch.vtensor<[229376,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[229376,512],f16>
    %int14_122 = torch.constant.int 14
    %int16384_123 = torch.constant.int 16384
    %int512_124 = torch.constant.int 512
    %116 = torch.prim.ListConstruct %int14_122, %int16384_123, %int512_124 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %117 = torch.aten.view %115, %116 : !torch.vtensor<[229376,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_k.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16>
    %118 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_125 = torch.constant.int 1
    %119 = torch.aten.add.Tensor %117, %118, %int1_125 : !torch.vtensor<[14,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_v.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16>
    %120 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_126 = torch.constant.int 0
    %int1_127 = torch.constant.int 1
    %121 = torch.aten.transpose.int %120, %int0_126, %int1_127 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int0_128 = torch.constant.int 0
    %122 = torch.aten.clone %99, %int0_128 : !torch.vtensor<[14,16384,512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %int229376_129 = torch.constant.int 229376
    %int512_130 = torch.constant.int 512
    %123 = torch.prim.ListConstruct %int229376_129, %int512_130 : (!torch.int, !torch.int) -> !torch.list<int>
    %124 = torch.aten._unsafe_view %122, %123 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[229376,512],f16>
    %125 = torch.aten.mm %124, %121 : !torch.vtensor<[229376,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[229376,512],f16>
    %int14_131 = torch.constant.int 14
    %int16384_132 = torch.constant.int 16384
    %int512_133 = torch.constant.int 512
    %126 = torch.prim.ListConstruct %int14_131, %int16384_132, %int512_133 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %127 = torch.aten.view %125, %126 : !torch.vtensor<[229376,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_v.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16>
    %128 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_134 = torch.constant.int 1
    %129 = torch.aten.add.Tensor %127, %128, %int1_134 : !torch.vtensor<[14,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %int14_135 = torch.constant.int 14
    %int-1 = torch.constant.int -1
    %int1_136 = torch.constant.int 1
    %int512_137 = torch.constant.int 512
    %130 = torch.prim.ListConstruct %int14_135, %int-1, %int1_136, %int512_137 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %131 = torch.aten.view %109, %130 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,1,512],f16>
    %int1_138 = torch.constant.int 1
    %int2_139 = torch.constant.int 2
    %132 = torch.aten.transpose.int %131, %int1_138, %int2_139 : !torch.vtensor<[14,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,1,16384,512],f16>
    %int14_140 = torch.constant.int 14
    %int-1_141 = torch.constant.int -1
    %int1_142 = torch.constant.int 1
    %int512_143 = torch.constant.int 512
    %133 = torch.prim.ListConstruct %int14_140, %int-1_141, %int1_142, %int512_143 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %134 = torch.aten.view %119, %133 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,1,512],f16>
    %int1_144 = torch.constant.int 1
    %int2_145 = torch.constant.int 2
    %135 = torch.aten.transpose.int %134, %int1_144, %int2_145 : !torch.vtensor<[14,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,1,16384,512],f16>
    %int14_146 = torch.constant.int 14
    %int-1_147 = torch.constant.int -1
    %int1_148 = torch.constant.int 1
    %int512_149 = torch.constant.int 512
    %136 = torch.prim.ListConstruct %int14_146, %int-1_147, %int1_148, %int512_149 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %137 = torch.aten.view %129, %136 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,1,512],f16>
    %int1_150 = torch.constant.int 1
    %int2_151 = torch.constant.int 2
    %138 = torch.aten.transpose.int %137, %int1_150, %int2_151 : !torch.vtensor<[14,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,1,16384,512],f16>
    %float2.102240e-01 = torch.constant.float 0.21022410381342863
    %139 = torch.aten.mul.Scalar %132, %float2.102240e-01 : !torch.vtensor<[14,1,16384,512],f16>, !torch.float -> !torch.vtensor<[14,1,16384,512],f16>
    %int-2 = torch.constant.int -2
    %int-1_152 = torch.constant.int -1
    %140 = torch.aten.transpose.int %135, %int-2, %int-1_152 : !torch.vtensor<[14,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,1,512,16384],f16>
    %float2.102240e-01_153 = torch.constant.float 0.21022410381342863
    %141 = torch.aten.mul.Scalar %140, %float2.102240e-01_153 : !torch.vtensor<[14,1,512,16384],f16>, !torch.float -> !torch.vtensor<[14,1,512,16384],f16>
    %int14_154 = torch.constant.int 14
    %int1_155 = torch.constant.int 1
    %int16384_156 = torch.constant.int 16384
    %int512_157 = torch.constant.int 512
    %142 = torch.prim.ListConstruct %int14_154, %int1_155, %int16384_156, %int512_157 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_158 = torch.constant.bool false
    %143 = torch.aten.expand %139, %142, %false_158 : !torch.vtensor<[14,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[14,1,16384,512],f16>
    %int14_159 = torch.constant.int 14
    %int16384_160 = torch.constant.int 16384
    %int512_161 = torch.constant.int 512
    %144 = torch.prim.ListConstruct %int14_159, %int16384_160, %int512_161 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %145 = torch.aten.view %143, %144 : !torch.vtensor<[14,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %int14_162 = torch.constant.int 14
    %int1_163 = torch.constant.int 1
    %int512_164 = torch.constant.int 512
    %int16384_165 = torch.constant.int 16384
    %146 = torch.prim.ListConstruct %int14_162, %int1_163, %int512_164, %int16384_165 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_166 = torch.constant.bool false
    %147 = torch.aten.expand %141, %146, %false_166 : !torch.vtensor<[14,1,512,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[14,1,512,16384],f16>
    %int14_167 = torch.constant.int 14
    %int512_168 = torch.constant.int 512
    %int16384_169 = torch.constant.int 16384
    %148 = torch.prim.ListConstruct %int14_167, %int512_168, %int16384_169 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %149 = torch.aten.view %147, %148 : !torch.vtensor<[14,1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[14,512,16384],f16>
    %150 = torch.aten.bmm %145, %149 : !torch.vtensor<[14,16384,512],f16>, !torch.vtensor<[14,512,16384],f16> -> !torch.vtensor<[14,16384,16384],f16>
    %int14_170 = torch.constant.int 14
    %int1_171 = torch.constant.int 1
    %int16384_172 = torch.constant.int 16384
    %int16384_173 = torch.constant.int 16384
    %151 = torch.prim.ListConstruct %int14_170, %int1_171, %int16384_172, %int16384_173 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %152 = torch.aten.view %150, %151 : !torch.vtensor<[14,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[14,1,16384,16384],f16>
    %int-1_174 = torch.constant.int -1
    %false_175 = torch.constant.bool false
    %153 = torch.aten._softmax %152, %int-1_174, %false_175 : !torch.vtensor<[14,1,16384,16384],f16>, !torch.int, !torch.bool -> !torch.vtensor<[14,1,16384,16384],f16>
    %int14_176 = torch.constant.int 14
    %int1_177 = torch.constant.int 1
    %int16384_178 = torch.constant.int 16384
    %int16384_179 = torch.constant.int 16384
    %154 = torch.prim.ListConstruct %int14_176, %int1_177, %int16384_178, %int16384_179 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_180 = torch.constant.bool false
    %155 = torch.aten.expand %153, %154, %false_180 : !torch.vtensor<[14,1,16384,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[14,1,16384,16384],f16>
    %int14_181 = torch.constant.int 14
    %int16384_182 = torch.constant.int 16384
    %int16384_183 = torch.constant.int 16384
    %156 = torch.prim.ListConstruct %int14_181, %int16384_182, %int16384_183 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %157 = torch.aten.view %155, %156 : !torch.vtensor<[14,1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,16384],f16>
    %int14_184 = torch.constant.int 14
    %int1_185 = torch.constant.int 1
    %int16384_186 = torch.constant.int 16384
    %int512_187 = torch.constant.int 512
    %158 = torch.prim.ListConstruct %int14_184, %int1_185, %int16384_186, %int512_187 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_188 = torch.constant.bool false
    %159 = torch.aten.expand %138, %158, %false_188 : !torch.vtensor<[14,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[14,1,16384,512],f16>
    %int14_189 = torch.constant.int 14
    %int16384_190 = torch.constant.int 16384
    %int512_191 = torch.constant.int 512
    %160 = torch.prim.ListConstruct %int14_189, %int16384_190, %int512_191 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %161 = torch.aten.view %159, %160 : !torch.vtensor<[14,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %162 = torch.aten.bmm %157, %161 : !torch.vtensor<[14,16384,16384],f16>, !torch.vtensor<[14,16384,512],f16> -> !torch.vtensor<[14,16384,512],f16>
    %int14_192 = torch.constant.int 14
    %int1_193 = torch.constant.int 1
    %int16384_194 = torch.constant.int 16384
    %int512_195 = torch.constant.int 512
    %163 = torch.prim.ListConstruct %int14_192, %int1_193, %int16384_194, %int512_195 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %164 = torch.aten.view %162, %163 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[14,1,16384,512],f16>
    %int1_196 = torch.constant.int 1
    %int2_197 = torch.constant.int 2
    %165 = torch.aten.transpose.int %164, %int1_196, %int2_197 : !torch.vtensor<[14,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,16384,1,512],f16>
    %int14_198 = torch.constant.int 14
    %int-1_199 = torch.constant.int -1
    %int512_200 = torch.constant.int 512
    %166 = torch.prim.ListConstruct %int14_198, %int-1_199, %int512_200 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %167 = torch.aten.view %165, %166 : !torch.vtensor<[14,16384,1,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %int5_201 = torch.constant.int 5
    %168 = torch.prims.convert_element_type %167, %int5_201 : !torch.vtensor<[14,16384,512],f16>, !torch.int -> !torch.vtensor<[14,16384,512],f16>
    %int229376_202 = torch.constant.int 229376
    %int512_203 = torch.constant.int 512
    %169 = torch.prim.ListConstruct %int229376_202, %int512_203 : (!torch.int, !torch.int) -> !torch.list<int>
    %170 = torch.aten.view %168, %169 : !torch.vtensor<[14,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[229376,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_out.0.weight = util.global.load @__auto.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16>
    %171 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_204 = torch.constant.int 0
    %int1_205 = torch.constant.int 1
    %172 = torch.aten.transpose.int %171, %int0_204, %int1_205 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %__auto.decoder.mid_block.attentions.0.to_out.0.bias = util.global.load @__auto.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16>
    %173 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int6_206 = torch.constant.int 6
    %174 = torch.prims.convert_element_type %173, %int6_206 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[512],f32>
    %int6_207 = torch.constant.int 6
    %175 = torch.prims.convert_element_type %170, %int6_207 : !torch.vtensor<[229376,512],f16>, !torch.int -> !torch.vtensor<[229376,512],f32>
    %int6_208 = torch.constant.int 6
    %176 = torch.prims.convert_element_type %172, %int6_208 : !torch.vtensor<[512,512],f16>, !torch.int -> !torch.vtensor<[512,512],f32>
    %177 = torch.aten.mm %175, %176 : !torch.vtensor<[229376,512],f32>, !torch.vtensor<[512,512],f32> -> !torch.vtensor<[229376,512],f32>
    %int1_209 = torch.constant.int 1
    %178 = torch.aten.mul.Scalar %177, %int1_209 : !torch.vtensor<[229376,512],f32>, !torch.int -> !torch.vtensor<[229376,512],f32>
    %int1_210 = torch.constant.int 1
    %179 = torch.aten.mul.Scalar %174, %int1_210 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],f32>
    %int1_211 = torch.constant.int 1
    %180 = torch.aten.add.Tensor %178, %179, %int1_211 : !torch.vtensor<[229376,512],f32>, !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[229376,512],f32>
    %int5_212 = torch.constant.int 5
    %181 = torch.prims.convert_element_type %180, %int5_212 : !torch.vtensor<[229376,512],f32>, !torch.int -> !torch.vtensor<[229376,512],f16>
    %int14_213 = torch.constant.int 14
    %int16384_214 = torch.constant.int 16384
    %int512_215 = torch.constant.int 512
    %182 = torch.prim.ListConstruct %int14_213, %int16384_214, %int512_215 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %183 = torch.aten.view %181, %182 : !torch.vtensor<[229376,512],f16>, !torch.list<int> -> !torch.vtensor<[14,16384,512],f16>
    %none_216 = torch.constant.none
    %184 = torch.aten.clone %183, %none_216 : !torch.vtensor<[14,16384,512],f16>, !torch.none -> !torch.vtensor<[14,16384,512],f16>
    %int-1_217 = torch.constant.int -1
    %int-2_218 = torch.constant.int -2
    %185 = torch.aten.transpose.int %184, %int-1_217, %int-2_218 : !torch.vtensor<[14,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,512,16384],f16>
    %int14_219 = torch.constant.int 14
    %int512_220 = torch.constant.int 512
    %int128_221 = torch.constant.int 128
    %int128_222 = torch.constant.int 128
    %186 = torch.prim.ListConstruct %int14_219, %int512_220, %int128_221, %int128_222 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %187 = torch.aten.view %185, %186 : !torch.vtensor<[14,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f16>
    %int1_223 = torch.constant.int 1
    %188 = torch.aten.add.Tensor %187, %75, %int1_223 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_224 = torch.constant.int 1
    %189 = torch.aten.div.Scalar %188, %int1_224 : !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_225 = torch.constant.int 14
    %int32_226 = torch.constant.int 32
    %int16_227 = torch.constant.int 16
    %int16384_228 = torch.constant.int 16384
    %190 = torch.prim.ListConstruct %int14_225, %int32_226, %int16_227, %int16384_228 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %191 = torch.aten.view %189, %190 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_229 = torch.constant.int 6
    %192 = torch.prims.convert_element_type %191, %int6_229 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_230 = torch.constant.int 2
    %int3_231 = torch.constant.int 3
    %193 = torch.prim.ListConstruct %int2_230, %int3_231 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_232 = torch.constant.int 0
    %true_233 = torch.constant.bool true
    %result0_234, %result1_235 = torch.aten.var_mean.correction %192, %193, %int0_232, %true_233 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_236 = torch.constant.float 9.9999999999999995E-7
    %int1_237 = torch.constant.int 1
    %194 = torch.aten.add.Scalar %result0_234, %float9.999990e-07_236, %int1_237 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %195 = torch.aten.rsqrt %194 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_238 = torch.constant.int 1
    %196 = torch.aten.sub.Tensor %191, %result1_235, %int1_238 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %197 = torch.aten.mul.Tensor %196, %195 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_239 = torch.constant.int 14
    %int512_240 = torch.constant.int 512
    %int128_241 = torch.constant.int 128
    %int128_242 = torch.constant.int 128
    %198 = torch.prim.ListConstruct %int14_239, %int512_240, %int128_241, %int128_242 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %199 = torch.aten.view %197, %198 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.1.norm1.bias = util.global.load @__auto.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16>
    %200 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_243 = torch.constant.int 0
    %201 = torch.aten.unsqueeze %200, %int0_243 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_244 = torch.constant.int 2
    %202 = torch.aten.unsqueeze %201, %int2_244 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_245 = torch.constant.int 3
    %203 = torch.aten.unsqueeze %202, %int3_245 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.1.norm1.weight = util.global.load @__auto.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16>
    %204 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_246 = torch.constant.int 0
    %205 = torch.aten.unsqueeze %204, %int0_246 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_247 = torch.constant.int 2
    %206 = torch.aten.unsqueeze %205, %int2_247 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_248 = torch.constant.int 3
    %207 = torch.aten.unsqueeze %206, %int3_248 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %208 = torch.aten.mul.Tensor %199, %207 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_249 = torch.constant.int 1
    %209 = torch.aten.add.Tensor %208, %203, %int1_249 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_250 = torch.constant.int 5
    %210 = torch.prims.convert_element_type %209, %int5_250 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %211 = torch.aten.silu %210 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.1.conv1.weight = util.global.load @__auto.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %212 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.1.conv1.bias = util.global.load @__auto.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16>
    %213 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_251 = torch.constant.int 1
    %int1_252 = torch.constant.int 1
    %214 = torch.prim.ListConstruct %int1_251, %int1_252 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_253 = torch.constant.int 1
    %int1_254 = torch.constant.int 1
    %215 = torch.prim.ListConstruct %int1_253, %int1_254 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_255 = torch.constant.int 1
    %int1_256 = torch.constant.int 1
    %216 = torch.prim.ListConstruct %int1_255, %int1_256 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_257 = torch.constant.bool false
    %int0_258 = torch.constant.int 0
    %int0_259 = torch.constant.int 0
    %217 = torch.prim.ListConstruct %int0_258, %int0_259 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_260 = torch.constant.int 1
    %218 = torch.aten.convolution %211, %212, %213, %214, %215, %216, %false_257, %217, %int1_260 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_261 = torch.constant.int 14
    %int32_262 = torch.constant.int 32
    %int16_263 = torch.constant.int 16
    %int16384_264 = torch.constant.int 16384
    %219 = torch.prim.ListConstruct %int14_261, %int32_262, %int16_263, %int16384_264 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %220 = torch.aten.view %218, %219 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_265 = torch.constant.int 6
    %221 = torch.prims.convert_element_type %220, %int6_265 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_266 = torch.constant.int 2
    %int3_267 = torch.constant.int 3
    %222 = torch.prim.ListConstruct %int2_266, %int3_267 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_268 = torch.constant.int 0
    %true_269 = torch.constant.bool true
    %result0_270, %result1_271 = torch.aten.var_mean.correction %221, %222, %int0_268, %true_269 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_272 = torch.constant.float 9.9999999999999995E-7
    %int1_273 = torch.constant.int 1
    %223 = torch.aten.add.Scalar %result0_270, %float9.999990e-07_272, %int1_273 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %224 = torch.aten.rsqrt %223 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_274 = torch.constant.int 1
    %225 = torch.aten.sub.Tensor %220, %result1_271, %int1_274 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %226 = torch.aten.mul.Tensor %225, %224 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_275 = torch.constant.int 14
    %int512_276 = torch.constant.int 512
    %int128_277 = torch.constant.int 128
    %int128_278 = torch.constant.int 128
    %227 = torch.prim.ListConstruct %int14_275, %int512_276, %int128_277, %int128_278 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %228 = torch.aten.view %226, %227 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.mid_block.resnets.1.norm2.bias = util.global.load @__auto.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16>
    %229 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_279 = torch.constant.int 0
    %230 = torch.aten.unsqueeze %229, %int0_279 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_280 = torch.constant.int 2
    %231 = torch.aten.unsqueeze %230, %int2_280 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_281 = torch.constant.int 3
    %232 = torch.aten.unsqueeze %231, %int3_281 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.mid_block.resnets.1.norm2.weight = util.global.load @__auto.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16>
    %233 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_282 = torch.constant.int 0
    %234 = torch.aten.unsqueeze %233, %int0_282 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_283 = torch.constant.int 2
    %235 = torch.aten.unsqueeze %234, %int2_283 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_284 = torch.constant.int 3
    %236 = torch.aten.unsqueeze %235, %int3_284 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %237 = torch.aten.mul.Tensor %228, %236 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_285 = torch.constant.int 1
    %238 = torch.aten.add.Tensor %237, %232, %int1_285 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_286 = torch.constant.int 5
    %239 = torch.prims.convert_element_type %238, %int5_286 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %240 = torch.aten.silu %239 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %none_287 = torch.constant.none
    %241 = torch.aten.clone %240, %none_287 : !torch.vtensor<[14,512,128,128],f16>, !torch.none -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.mid_block.resnets.1.conv2.weight = util.global.load @__auto.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %242 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.mid_block.resnets.1.conv2.bias = util.global.load @__auto.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16>
    %243 = torch_c.from_builtin_tensor %__auto.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_288 = torch.constant.int 1
    %int1_289 = torch.constant.int 1
    %244 = torch.prim.ListConstruct %int1_288, %int1_289 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_290 = torch.constant.int 1
    %int1_291 = torch.constant.int 1
    %245 = torch.prim.ListConstruct %int1_290, %int1_291 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_292 = torch.constant.int 1
    %int1_293 = torch.constant.int 1
    %246 = torch.prim.ListConstruct %int1_292, %int1_293 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_294 = torch.constant.bool false
    %int0_295 = torch.constant.int 0
    %int0_296 = torch.constant.int 0
    %247 = torch.prim.ListConstruct %int0_295, %int0_296 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_297 = torch.constant.int 1
    %248 = torch.aten.convolution %241, %242, %243, %244, %245, %246, %false_294, %247, %int1_297 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_298 = torch.constant.int 1
    %249 = torch.aten.add.Tensor %189, %248, %int1_298 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_299 = torch.constant.int 1
    %250 = torch.aten.div.Scalar %249, %int1_299 : !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int5_300 = torch.constant.int 5
    %251 = torch.prims.convert_element_type %250, %int5_300 : !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_301 = torch.constant.int 14
    %int32_302 = torch.constant.int 32
    %int16_303 = torch.constant.int 16
    %int16384_304 = torch.constant.int 16384
    %252 = torch.prim.ListConstruct %int14_301, %int32_302, %int16_303, %int16384_304 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %253 = torch.aten.view %251, %252 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_305 = torch.constant.int 6
    %254 = torch.prims.convert_element_type %253, %int6_305 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_306 = torch.constant.int 2
    %int3_307 = torch.constant.int 3
    %255 = torch.prim.ListConstruct %int2_306, %int3_307 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_308 = torch.constant.int 0
    %true_309 = torch.constant.bool true
    %result0_310, %result1_311 = torch.aten.var_mean.correction %254, %255, %int0_308, %true_309 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_312 = torch.constant.float 9.9999999999999995E-7
    %int1_313 = torch.constant.int 1
    %256 = torch.aten.add.Scalar %result0_310, %float9.999990e-07_312, %int1_313 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %257 = torch.aten.rsqrt %256 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_314 = torch.constant.int 1
    %258 = torch.aten.sub.Tensor %253, %result1_311, %int1_314 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %259 = torch.aten.mul.Tensor %258, %257 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_315 = torch.constant.int 14
    %int512_316 = torch.constant.int 512
    %int128_317 = torch.constant.int 128
    %int128_318 = torch.constant.int 128
    %260 = torch.prim.ListConstruct %int14_315, %int512_316, %int128_317, %int128_318 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %261 = torch.aten.view %259, %260 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16>
    %262 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_319 = torch.constant.int 0
    %263 = torch.aten.unsqueeze %262, %int0_319 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_320 = torch.constant.int 2
    %264 = torch.aten.unsqueeze %263, %int2_320 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_321 = torch.constant.int 3
    %265 = torch.aten.unsqueeze %264, %int3_321 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16>
    %266 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_322 = torch.constant.int 0
    %267 = torch.aten.unsqueeze %266, %int0_322 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_323 = torch.constant.int 2
    %268 = torch.aten.unsqueeze %267, %int2_323 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_324 = torch.constant.int 3
    %269 = torch.aten.unsqueeze %268, %int3_324 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %270 = torch.aten.mul.Tensor %261, %269 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_325 = torch.constant.int 1
    %271 = torch.aten.add.Tensor %270, %265, %int1_325 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_326 = torch.constant.int 5
    %272 = torch.prims.convert_element_type %271, %int5_326 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %273 = torch.aten.silu %272 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %274 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16>
    %275 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_327 = torch.constant.int 1
    %int1_328 = torch.constant.int 1
    %276 = torch.prim.ListConstruct %int1_327, %int1_328 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_329 = torch.constant.int 1
    %int1_330 = torch.constant.int 1
    %277 = torch.prim.ListConstruct %int1_329, %int1_330 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_331 = torch.constant.int 1
    %int1_332 = torch.constant.int 1
    %278 = torch.prim.ListConstruct %int1_331, %int1_332 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_333 = torch.constant.bool false
    %int0_334 = torch.constant.int 0
    %int0_335 = torch.constant.int 0
    %279 = torch.prim.ListConstruct %int0_334, %int0_335 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_336 = torch.constant.int 1
    %280 = torch.aten.convolution %273, %274, %275, %276, %277, %278, %false_333, %279, %int1_336 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_337 = torch.constant.int 14
    %int32_338 = torch.constant.int 32
    %int16_339 = torch.constant.int 16
    %int16384_340 = torch.constant.int 16384
    %281 = torch.prim.ListConstruct %int14_337, %int32_338, %int16_339, %int16384_340 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %282 = torch.aten.view %280, %281 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_341 = torch.constant.int 6
    %283 = torch.prims.convert_element_type %282, %int6_341 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_342 = torch.constant.int 2
    %int3_343 = torch.constant.int 3
    %284 = torch.prim.ListConstruct %int2_342, %int3_343 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_344 = torch.constant.int 0
    %true_345 = torch.constant.bool true
    %result0_346, %result1_347 = torch.aten.var_mean.correction %283, %284, %int0_344, %true_345 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_348 = torch.constant.float 9.9999999999999995E-7
    %int1_349 = torch.constant.int 1
    %285 = torch.aten.add.Scalar %result0_346, %float9.999990e-07_348, %int1_349 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %286 = torch.aten.rsqrt %285 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_350 = torch.constant.int 1
    %287 = torch.aten.sub.Tensor %282, %result1_347, %int1_350 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %288 = torch.aten.mul.Tensor %287, %286 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_351 = torch.constant.int 14
    %int512_352 = torch.constant.int 512
    %int128_353 = torch.constant.int 128
    %int128_354 = torch.constant.int 128
    %289 = torch.prim.ListConstruct %int14_351, %int512_352, %int128_353, %int128_354 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %290 = torch.aten.view %288, %289 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16>
    %291 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_355 = torch.constant.int 0
    %292 = torch.aten.unsqueeze %291, %int0_355 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_356 = torch.constant.int 2
    %293 = torch.aten.unsqueeze %292, %int2_356 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_357 = torch.constant.int 3
    %294 = torch.aten.unsqueeze %293, %int3_357 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16>
    %295 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_358 = torch.constant.int 0
    %296 = torch.aten.unsqueeze %295, %int0_358 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_359 = torch.constant.int 2
    %297 = torch.aten.unsqueeze %296, %int2_359 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_360 = torch.constant.int 3
    %298 = torch.aten.unsqueeze %297, %int3_360 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %299 = torch.aten.mul.Tensor %290, %298 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_361 = torch.constant.int 1
    %300 = torch.aten.add.Tensor %299, %294, %int1_361 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_362 = torch.constant.int 5
    %301 = torch.prims.convert_element_type %300, %int5_362 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %302 = torch.aten.silu %301 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %none_363 = torch.constant.none
    %303 = torch.aten.clone %302, %none_363 : !torch.vtensor<[14,512,128,128],f16>, !torch.none -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %304 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16>
    %305 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_364 = torch.constant.int 1
    %int1_365 = torch.constant.int 1
    %306 = torch.prim.ListConstruct %int1_364, %int1_365 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_366 = torch.constant.int 1
    %int1_367 = torch.constant.int 1
    %307 = torch.prim.ListConstruct %int1_366, %int1_367 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_368 = torch.constant.int 1
    %int1_369 = torch.constant.int 1
    %308 = torch.prim.ListConstruct %int1_368, %int1_369 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_370 = torch.constant.bool false
    %int0_371 = torch.constant.int 0
    %int0_372 = torch.constant.int 0
    %309 = torch.prim.ListConstruct %int0_371, %int0_372 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_373 = torch.constant.int 1
    %310 = torch.aten.convolution %303, %304, %305, %306, %307, %308, %false_370, %309, %int1_373 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_374 = torch.constant.int 1
    %311 = torch.aten.add.Tensor %251, %310, %int1_374 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %float1.000000e00 = torch.constant.float 1.000000e+00
    %312 = torch.aten.div.Scalar %311, %float1.000000e00 : !torch.vtensor<[14,512,128,128],f16>, !torch.float -> !torch.vtensor<[14,512,128,128],f16>
    %int14_375 = torch.constant.int 14
    %int32_376 = torch.constant.int 32
    %int16_377 = torch.constant.int 16
    %int16384_378 = torch.constant.int 16384
    %313 = torch.prim.ListConstruct %int14_375, %int32_376, %int16_377, %int16384_378 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %314 = torch.aten.view %312, %313 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_379 = torch.constant.int 6
    %315 = torch.prims.convert_element_type %314, %int6_379 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_380 = torch.constant.int 2
    %int3_381 = torch.constant.int 3
    %316 = torch.prim.ListConstruct %int2_380, %int3_381 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_382 = torch.constant.int 0
    %true_383 = torch.constant.bool true
    %result0_384, %result1_385 = torch.aten.var_mean.correction %315, %316, %int0_382, %true_383 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_386 = torch.constant.float 9.9999999999999995E-7
    %int1_387 = torch.constant.int 1
    %317 = torch.aten.add.Scalar %result0_384, %float9.999990e-07_386, %int1_387 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %318 = torch.aten.rsqrt %317 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_388 = torch.constant.int 1
    %319 = torch.aten.sub.Tensor %314, %result1_385, %int1_388 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %320 = torch.aten.mul.Tensor %319, %318 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_389 = torch.constant.int 14
    %int512_390 = torch.constant.int 512
    %int128_391 = torch.constant.int 128
    %int128_392 = torch.constant.int 128
    %321 = torch.prim.ListConstruct %int14_389, %int512_390, %int128_391, %int128_392 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %322 = torch.aten.view %320, %321 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16>
    %323 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_393 = torch.constant.int 0
    %324 = torch.aten.unsqueeze %323, %int0_393 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_394 = torch.constant.int 2
    %325 = torch.aten.unsqueeze %324, %int2_394 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_395 = torch.constant.int 3
    %326 = torch.aten.unsqueeze %325, %int3_395 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16>
    %327 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_396 = torch.constant.int 0
    %328 = torch.aten.unsqueeze %327, %int0_396 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_397 = torch.constant.int 2
    %329 = torch.aten.unsqueeze %328, %int2_397 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_398 = torch.constant.int 3
    %330 = torch.aten.unsqueeze %329, %int3_398 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %331 = torch.aten.mul.Tensor %322, %330 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_399 = torch.constant.int 1
    %332 = torch.aten.add.Tensor %331, %326, %int1_399 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_400 = torch.constant.int 5
    %333 = torch.prims.convert_element_type %332, %int5_400 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %334 = torch.aten.silu %333 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %335 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16>
    %336 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_401 = torch.constant.int 1
    %int1_402 = torch.constant.int 1
    %337 = torch.prim.ListConstruct %int1_401, %int1_402 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_403 = torch.constant.int 1
    %int1_404 = torch.constant.int 1
    %338 = torch.prim.ListConstruct %int1_403, %int1_404 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_405 = torch.constant.int 1
    %int1_406 = torch.constant.int 1
    %339 = torch.prim.ListConstruct %int1_405, %int1_406 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_407 = torch.constant.bool false
    %int0_408 = torch.constant.int 0
    %int0_409 = torch.constant.int 0
    %340 = torch.prim.ListConstruct %int0_408, %int0_409 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_410 = torch.constant.int 1
    %341 = torch.aten.convolution %334, %335, %336, %337, %338, %339, %false_407, %340, %int1_410 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_411 = torch.constant.int 14
    %int32_412 = torch.constant.int 32
    %int16_413 = torch.constant.int 16
    %int16384_414 = torch.constant.int 16384
    %342 = torch.prim.ListConstruct %int14_411, %int32_412, %int16_413, %int16384_414 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %343 = torch.aten.view %341, %342 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_415 = torch.constant.int 6
    %344 = torch.prims.convert_element_type %343, %int6_415 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_416 = torch.constant.int 2
    %int3_417 = torch.constant.int 3
    %345 = torch.prim.ListConstruct %int2_416, %int3_417 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_418 = torch.constant.int 0
    %true_419 = torch.constant.bool true
    %result0_420, %result1_421 = torch.aten.var_mean.correction %344, %345, %int0_418, %true_419 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_422 = torch.constant.float 9.9999999999999995E-7
    %int1_423 = torch.constant.int 1
    %346 = torch.aten.add.Scalar %result0_420, %float9.999990e-07_422, %int1_423 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %347 = torch.aten.rsqrt %346 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_424 = torch.constant.int 1
    %348 = torch.aten.sub.Tensor %343, %result1_421, %int1_424 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %349 = torch.aten.mul.Tensor %348, %347 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_425 = torch.constant.int 14
    %int512_426 = torch.constant.int 512
    %int128_427 = torch.constant.int 128
    %int128_428 = torch.constant.int 128
    %350 = torch.prim.ListConstruct %int14_425, %int512_426, %int128_427, %int128_428 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %351 = torch.aten.view %349, %350 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16>
    %352 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_429 = torch.constant.int 0
    %353 = torch.aten.unsqueeze %352, %int0_429 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_430 = torch.constant.int 2
    %354 = torch.aten.unsqueeze %353, %int2_430 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_431 = torch.constant.int 3
    %355 = torch.aten.unsqueeze %354, %int3_431 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16>
    %356 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_432 = torch.constant.int 0
    %357 = torch.aten.unsqueeze %356, %int0_432 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_433 = torch.constant.int 2
    %358 = torch.aten.unsqueeze %357, %int2_433 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_434 = torch.constant.int 3
    %359 = torch.aten.unsqueeze %358, %int3_434 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %360 = torch.aten.mul.Tensor %351, %359 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_435 = torch.constant.int 1
    %361 = torch.aten.add.Tensor %360, %355, %int1_435 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_436 = torch.constant.int 5
    %362 = torch.prims.convert_element_type %361, %int5_436 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %363 = torch.aten.silu %362 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %none_437 = torch.constant.none
    %364 = torch.aten.clone %363, %none_437 : !torch.vtensor<[14,512,128,128],f16>, !torch.none -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %365 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16>
    %366 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_438 = torch.constant.int 1
    %int1_439 = torch.constant.int 1
    %367 = torch.prim.ListConstruct %int1_438, %int1_439 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_440 = torch.constant.int 1
    %int1_441 = torch.constant.int 1
    %368 = torch.prim.ListConstruct %int1_440, %int1_441 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_442 = torch.constant.int 1
    %int1_443 = torch.constant.int 1
    %369 = torch.prim.ListConstruct %int1_442, %int1_443 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_444 = torch.constant.bool false
    %int0_445 = torch.constant.int 0
    %int0_446 = torch.constant.int 0
    %370 = torch.prim.ListConstruct %int0_445, %int0_446 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_447 = torch.constant.int 1
    %371 = torch.aten.convolution %364, %365, %366, %367, %368, %369, %false_444, %370, %int1_447 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_448 = torch.constant.int 1
    %372 = torch.aten.add.Tensor %312, %371, %int1_448 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %float1.000000e00_449 = torch.constant.float 1.000000e+00
    %373 = torch.aten.div.Scalar %372, %float1.000000e00_449 : !torch.vtensor<[14,512,128,128],f16>, !torch.float -> !torch.vtensor<[14,512,128,128],f16>
    %int14_450 = torch.constant.int 14
    %int32_451 = torch.constant.int 32
    %int16_452 = torch.constant.int 16
    %int16384_453 = torch.constant.int 16384
    %374 = torch.prim.ListConstruct %int14_450, %int32_451, %int16_452, %int16384_453 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %375 = torch.aten.view %373, %374 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_454 = torch.constant.int 6
    %376 = torch.prims.convert_element_type %375, %int6_454 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_455 = torch.constant.int 2
    %int3_456 = torch.constant.int 3
    %377 = torch.prim.ListConstruct %int2_455, %int3_456 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_457 = torch.constant.int 0
    %true_458 = torch.constant.bool true
    %result0_459, %result1_460 = torch.aten.var_mean.correction %376, %377, %int0_457, %true_458 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_461 = torch.constant.float 9.9999999999999995E-7
    %int1_462 = torch.constant.int 1
    %378 = torch.aten.add.Scalar %result0_459, %float9.999990e-07_461, %int1_462 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %379 = torch.aten.rsqrt %378 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_463 = torch.constant.int 1
    %380 = torch.aten.sub.Tensor %375, %result1_460, %int1_463 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %381 = torch.aten.mul.Tensor %380, %379 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_464 = torch.constant.int 14
    %int512_465 = torch.constant.int 512
    %int128_466 = torch.constant.int 128
    %int128_467 = torch.constant.int 128
    %382 = torch.prim.ListConstruct %int14_464, %int512_465, %int128_466, %int128_467 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %383 = torch.aten.view %381, %382 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16>
    %384 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_468 = torch.constant.int 0
    %385 = torch.aten.unsqueeze %384, %int0_468 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_469 = torch.constant.int 2
    %386 = torch.aten.unsqueeze %385, %int2_469 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_470 = torch.constant.int 3
    %387 = torch.aten.unsqueeze %386, %int3_470 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16>
    %388 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_471 = torch.constant.int 0
    %389 = torch.aten.unsqueeze %388, %int0_471 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_472 = torch.constant.int 2
    %390 = torch.aten.unsqueeze %389, %int2_472 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_473 = torch.constant.int 3
    %391 = torch.aten.unsqueeze %390, %int3_473 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %392 = torch.aten.mul.Tensor %383, %391 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_474 = torch.constant.int 1
    %393 = torch.aten.add.Tensor %392, %387, %int1_474 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_475 = torch.constant.int 5
    %394 = torch.prims.convert_element_type %393, %int5_475 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %395 = torch.aten.silu %394 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %396 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16>
    %397 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_476 = torch.constant.int 1
    %int1_477 = torch.constant.int 1
    %398 = torch.prim.ListConstruct %int1_476, %int1_477 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_478 = torch.constant.int 1
    %int1_479 = torch.constant.int 1
    %399 = torch.prim.ListConstruct %int1_478, %int1_479 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_480 = torch.constant.int 1
    %int1_481 = torch.constant.int 1
    %400 = torch.prim.ListConstruct %int1_480, %int1_481 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_482 = torch.constant.bool false
    %int0_483 = torch.constant.int 0
    %int0_484 = torch.constant.int 0
    %401 = torch.prim.ListConstruct %int0_483, %int0_484 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_485 = torch.constant.int 1
    %402 = torch.aten.convolution %395, %396, %397, %398, %399, %400, %false_482, %401, %int1_485 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int14_486 = torch.constant.int 14
    %int32_487 = torch.constant.int 32
    %int16_488 = torch.constant.int 16
    %int16384_489 = torch.constant.int 16384
    %403 = torch.prim.ListConstruct %int14_486, %int32_487, %int16_488, %int16384_489 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %404 = torch.aten.view %402, %403 : !torch.vtensor<[14,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,16384],f16>
    %int6_490 = torch.constant.int 6
    %405 = torch.prims.convert_element_type %404, %int6_490 : !torch.vtensor<[14,32,16,16384],f16>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %int2_491 = torch.constant.int 2
    %int3_492 = torch.constant.int 3
    %406 = torch.prim.ListConstruct %int2_491, %int3_492 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_493 = torch.constant.int 0
    %true_494 = torch.constant.bool true
    %result0_495, %result1_496 = torch.aten.var_mean.correction %405, %406, %int0_493, %true_494 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_497 = torch.constant.float 9.9999999999999995E-7
    %int1_498 = torch.constant.int 1
    %407 = torch.aten.add.Scalar %result0_495, %float9.999990e-07_497, %int1_498 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %408 = torch.aten.rsqrt %407 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_499 = torch.constant.int 1
    %409 = torch.aten.sub.Tensor %404, %result1_496, %int1_499 : !torch.vtensor<[14,32,16,16384],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,16384],f32>
    %410 = torch.aten.mul.Tensor %409, %408 : !torch.vtensor<[14,32,16,16384],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,16384],f32>
    %int14_500 = torch.constant.int 14
    %int512_501 = torch.constant.int 512
    %int128_502 = torch.constant.int 128
    %int128_503 = torch.constant.int 128
    %411 = torch.prim.ListConstruct %int14_500, %int512_501, %int128_502, %int128_503 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %412 = torch.aten.view %410, %411 : !torch.vtensor<[14,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[14,512,128,128],f32>
    %__auto.decoder.up_blocks.0.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16>
    %413 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_504 = torch.constant.int 0
    %414 = torch.aten.unsqueeze %413, %int0_504 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_505 = torch.constant.int 2
    %415 = torch.aten.unsqueeze %414, %int2_505 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_506 = torch.constant.int 3
    %416 = torch.aten.unsqueeze %415, %int3_506 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.0.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16>
    %417 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_507 = torch.constant.int 0
    %418 = torch.aten.unsqueeze %417, %int0_507 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_508 = torch.constant.int 2
    %419 = torch.aten.unsqueeze %418, %int2_508 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_509 = torch.constant.int 3
    %420 = torch.aten.unsqueeze %419, %int3_509 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %421 = torch.aten.mul.Tensor %412, %420 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,128,128],f32>
    %int1_510 = torch.constant.int 1
    %422 = torch.aten.add.Tensor %421, %416, %int1_510 : !torch.vtensor<[14,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int5_511 = torch.constant.int 5
    %423 = torch.prims.convert_element_type %422, %int5_511 : !torch.vtensor<[14,512,128,128],f32>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %424 = torch.aten.silu %423 : !torch.vtensor<[14,512,128,128],f16> -> !torch.vtensor<[14,512,128,128],f16>
    %none_512 = torch.constant.none
    %425 = torch.aten.clone %424, %none_512 : !torch.vtensor<[14,512,128,128],f16>, !torch.none -> !torch.vtensor<[14,512,128,128],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %426 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16>
    %427 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_513 = torch.constant.int 1
    %int1_514 = torch.constant.int 1
    %428 = torch.prim.ListConstruct %int1_513, %int1_514 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_515 = torch.constant.int 1
    %int1_516 = torch.constant.int 1
    %429 = torch.prim.ListConstruct %int1_515, %int1_516 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_517 = torch.constant.int 1
    %int1_518 = torch.constant.int 1
    %430 = torch.prim.ListConstruct %int1_517, %int1_518 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_519 = torch.constant.bool false
    %int0_520 = torch.constant.int 0
    %int0_521 = torch.constant.int 0
    %431 = torch.prim.ListConstruct %int0_520, %int0_521 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_522 = torch.constant.int 1
    %432 = torch.aten.convolution %425, %426, %427, %428, %429, %430, %false_519, %431, %int1_522 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %int1_523 = torch.constant.int 1
    %433 = torch.aten.add.Tensor %373, %432, %int1_523 : !torch.vtensor<[14,512,128,128],f16>, !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f16>
    %float1.000000e00_524 = torch.constant.float 1.000000e+00
    %434 = torch.aten.div.Scalar %433, %float1.000000e00_524 : !torch.vtensor<[14,512,128,128],f16>, !torch.float -> !torch.vtensor<[14,512,128,128],f16>
    %int6_525 = torch.constant.int 6
    %435 = torch.prims.convert_element_type %434, %int6_525 : !torch.vtensor<[14,512,128,128],f16>, !torch.int -> !torch.vtensor<[14,512,128,128],f32>
    %int256 = torch.constant.int 256
    %int6_526 = torch.constant.int 6
    %none_527 = torch.constant.none
    %cpu = torch.constant.device "cpu"
    %false_528 = torch.constant.bool false
    %436 = torch.aten.arange %int256, %int6_526, %none_527, %cpu, %false_528 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %int1_529 = torch.constant.int 1
    %437 = torch.aten.add.Scalar %436, %float0.000000e00, %int1_529 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %438 = torch.aten.mul.Scalar %437, %float5.000000e-01 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4 = torch.constant.int 4
    %439 = torch.prims.convert_element_type %438, %int4 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %int-1_530 = torch.constant.int -1
    %440 = torch.aten.unsqueeze %439, %int-1_530 : !torch.vtensor<[256],si64>, !torch.int -> !torch.vtensor<[256,1],si64>
    %int256_531 = torch.constant.int 256
    %int6_532 = torch.constant.int 6
    %none_533 = torch.constant.none
    %cpu_534 = torch.constant.device "cpu"
    %false_535 = torch.constant.bool false
    %441 = torch.aten.arange %int256_531, %int6_532, %none_533, %cpu_534, %false_535 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00_536 = torch.constant.float 0.000000e+00
    %int1_537 = torch.constant.int 1
    %442 = torch.aten.add.Scalar %441, %float0.000000e00_536, %int1_537 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01_538 = torch.constant.float 5.000000e-01
    %443 = torch.aten.mul.Scalar %442, %float5.000000e-01_538 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4_539 = torch.constant.int 4
    %444 = torch.prims.convert_element_type %443, %int4_539 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %none_540 = torch.constant.none
    %none_541 = torch.constant.none
    %445 = torch.prim.ListConstruct %none_540, %none_541, %440, %444 : (!torch.none, !torch.none, !torch.vtensor<[256,1],si64>, !torch.vtensor<[256],si64>) -> !torch.list<optional<vtensor>>
    %446 = torch.aten.index.Tensor %435, %445 : !torch.vtensor<[14,512,128,128],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[14,512,256,256],f32>
    %int2_542 = torch.constant.int 2
    %447 = torch.aten.clone %446, %int2_542 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_543 = torch.constant.int 5
    %448 = torch.prims.convert_element_type %447, %int5_543 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.0.upsamplers.0.conv.weight = util.global.load @__auto.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %449 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.0.upsamplers.0.conv.bias = util.global.load @__auto.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16>
    %450 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_544 = torch.constant.int 1
    %int1_545 = torch.constant.int 1
    %451 = torch.prim.ListConstruct %int1_544, %int1_545 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_546 = torch.constant.int 1
    %int1_547 = torch.constant.int 1
    %452 = torch.prim.ListConstruct %int1_546, %int1_547 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_548 = torch.constant.int 1
    %int1_549 = torch.constant.int 1
    %453 = torch.prim.ListConstruct %int1_548, %int1_549 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_550 = torch.constant.bool false
    %int0_551 = torch.constant.int 0
    %int0_552 = torch.constant.int 0
    %454 = torch.prim.ListConstruct %int0_551, %int0_552 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_553 = torch.constant.int 1
    %455 = torch.aten.convolution %448, %449, %450, %451, %452, %453, %false_550, %454, %int1_553 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int14_554 = torch.constant.int 14
    %int32_555 = torch.constant.int 32
    %int16_556 = torch.constant.int 16
    %int65536 = torch.constant.int 65536
    %456 = torch.prim.ListConstruct %int14_554, %int32_555, %int16_556, %int65536 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %457 = torch.aten.view %455, %456 : !torch.vtensor<[14,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,65536],f16>
    %int6_557 = torch.constant.int 6
    %458 = torch.prims.convert_element_type %457, %int6_557 : !torch.vtensor<[14,32,16,65536],f16>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %int2_558 = torch.constant.int 2
    %int3_559 = torch.constant.int 3
    %459 = torch.prim.ListConstruct %int2_558, %int3_559 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_560 = torch.constant.int 0
    %true_561 = torch.constant.bool true
    %result0_562, %result1_563 = torch.aten.var_mean.correction %458, %459, %int0_560, %true_561 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_564 = torch.constant.float 9.9999999999999995E-7
    %int1_565 = torch.constant.int 1
    %460 = torch.aten.add.Scalar %result0_562, %float9.999990e-07_564, %int1_565 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %461 = torch.aten.rsqrt %460 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_566 = torch.constant.int 1
    %462 = torch.aten.sub.Tensor %457, %result1_563, %int1_566 : !torch.vtensor<[14,32,16,65536],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %463 = torch.aten.mul.Tensor %462, %461 : !torch.vtensor<[14,32,16,65536],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,65536],f32>
    %int14_567 = torch.constant.int 14
    %int512_568 = torch.constant.int 512
    %int256_569 = torch.constant.int 256
    %int256_570 = torch.constant.int 256
    %464 = torch.prim.ListConstruct %int14_567, %int512_568, %int256_569, %int256_570 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %465 = torch.aten.view %463, %464 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[14,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16>
    %466 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_571 = torch.constant.int 0
    %467 = torch.aten.unsqueeze %466, %int0_571 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_572 = torch.constant.int 2
    %468 = torch.aten.unsqueeze %467, %int2_572 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_573 = torch.constant.int 3
    %469 = torch.aten.unsqueeze %468, %int3_573 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16>
    %470 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_574 = torch.constant.int 0
    %471 = torch.aten.unsqueeze %470, %int0_574 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_575 = torch.constant.int 2
    %472 = torch.aten.unsqueeze %471, %int2_575 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_576 = torch.constant.int 3
    %473 = torch.aten.unsqueeze %472, %int3_576 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %474 = torch.aten.mul.Tensor %465, %473 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,256,256],f32>
    %int1_577 = torch.constant.int 1
    %475 = torch.aten.add.Tensor %474, %469, %int1_577 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_578 = torch.constant.int 5
    %476 = torch.prims.convert_element_type %475, %int5_578 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %477 = torch.aten.silu %476 : !torch.vtensor<[14,512,256,256],f16> -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %478 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16>
    %479 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_579 = torch.constant.int 1
    %int1_580 = torch.constant.int 1
    %480 = torch.prim.ListConstruct %int1_579, %int1_580 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_581 = torch.constant.int 1
    %int1_582 = torch.constant.int 1
    %481 = torch.prim.ListConstruct %int1_581, %int1_582 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_583 = torch.constant.int 1
    %int1_584 = torch.constant.int 1
    %482 = torch.prim.ListConstruct %int1_583, %int1_584 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_585 = torch.constant.bool false
    %int0_586 = torch.constant.int 0
    %int0_587 = torch.constant.int 0
    %483 = torch.prim.ListConstruct %int0_586, %int0_587 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_588 = torch.constant.int 1
    %484 = torch.aten.convolution %477, %478, %479, %480, %481, %482, %false_585, %483, %int1_588 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int14_589 = torch.constant.int 14
    %int32_590 = torch.constant.int 32
    %int16_591 = torch.constant.int 16
    %int65536_592 = torch.constant.int 65536
    %485 = torch.prim.ListConstruct %int14_589, %int32_590, %int16_591, %int65536_592 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %486 = torch.aten.view %484, %485 : !torch.vtensor<[14,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,65536],f16>
    %int6_593 = torch.constant.int 6
    %487 = torch.prims.convert_element_type %486, %int6_593 : !torch.vtensor<[14,32,16,65536],f16>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %int2_594 = torch.constant.int 2
    %int3_595 = torch.constant.int 3
    %488 = torch.prim.ListConstruct %int2_594, %int3_595 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_596 = torch.constant.int 0
    %true_597 = torch.constant.bool true
    %result0_598, %result1_599 = torch.aten.var_mean.correction %487, %488, %int0_596, %true_597 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_600 = torch.constant.float 9.9999999999999995E-7
    %int1_601 = torch.constant.int 1
    %489 = torch.aten.add.Scalar %result0_598, %float9.999990e-07_600, %int1_601 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %490 = torch.aten.rsqrt %489 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_602 = torch.constant.int 1
    %491 = torch.aten.sub.Tensor %486, %result1_599, %int1_602 : !torch.vtensor<[14,32,16,65536],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %492 = torch.aten.mul.Tensor %491, %490 : !torch.vtensor<[14,32,16,65536],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,65536],f32>
    %int14_603 = torch.constant.int 14
    %int512_604 = torch.constant.int 512
    %int256_605 = torch.constant.int 256
    %int256_606 = torch.constant.int 256
    %493 = torch.prim.ListConstruct %int14_603, %int512_604, %int256_605, %int256_606 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %494 = torch.aten.view %492, %493 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[14,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16>
    %495 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_607 = torch.constant.int 0
    %496 = torch.aten.unsqueeze %495, %int0_607 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_608 = torch.constant.int 2
    %497 = torch.aten.unsqueeze %496, %int2_608 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_609 = torch.constant.int 3
    %498 = torch.aten.unsqueeze %497, %int3_609 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16>
    %499 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_610 = torch.constant.int 0
    %500 = torch.aten.unsqueeze %499, %int0_610 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_611 = torch.constant.int 2
    %501 = torch.aten.unsqueeze %500, %int2_611 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_612 = torch.constant.int 3
    %502 = torch.aten.unsqueeze %501, %int3_612 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %503 = torch.aten.mul.Tensor %494, %502 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,256,256],f32>
    %int1_613 = torch.constant.int 1
    %504 = torch.aten.add.Tensor %503, %498, %int1_613 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_614 = torch.constant.int 5
    %505 = torch.prims.convert_element_type %504, %int5_614 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %506 = torch.aten.silu %505 : !torch.vtensor<[14,512,256,256],f16> -> !torch.vtensor<[14,512,256,256],f16>
    %none_615 = torch.constant.none
    %507 = torch.aten.clone %506, %none_615 : !torch.vtensor<[14,512,256,256],f16>, !torch.none -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %508 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16>
    %509 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_616 = torch.constant.int 1
    %int1_617 = torch.constant.int 1
    %510 = torch.prim.ListConstruct %int1_616, %int1_617 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_618 = torch.constant.int 1
    %int1_619 = torch.constant.int 1
    %511 = torch.prim.ListConstruct %int1_618, %int1_619 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_620 = torch.constant.int 1
    %int1_621 = torch.constant.int 1
    %512 = torch.prim.ListConstruct %int1_620, %int1_621 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_622 = torch.constant.bool false
    %int0_623 = torch.constant.int 0
    %int0_624 = torch.constant.int 0
    %513 = torch.prim.ListConstruct %int0_623, %int0_624 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_625 = torch.constant.int 1
    %514 = torch.aten.convolution %507, %508, %509, %510, %511, %512, %false_622, %513, %int1_625 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int1_626 = torch.constant.int 1
    %515 = torch.aten.add.Tensor %455, %514, %int1_626 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[14,512,256,256],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %float1.000000e00_627 = torch.constant.float 1.000000e+00
    %516 = torch.aten.div.Scalar %515, %float1.000000e00_627 : !torch.vtensor<[14,512,256,256],f16>, !torch.float -> !torch.vtensor<[14,512,256,256],f16>
    %int14_628 = torch.constant.int 14
    %int32_629 = torch.constant.int 32
    %int16_630 = torch.constant.int 16
    %int65536_631 = torch.constant.int 65536
    %517 = torch.prim.ListConstruct %int14_628, %int32_629, %int16_630, %int65536_631 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %518 = torch.aten.view %516, %517 : !torch.vtensor<[14,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,65536],f16>
    %int6_632 = torch.constant.int 6
    %519 = torch.prims.convert_element_type %518, %int6_632 : !torch.vtensor<[14,32,16,65536],f16>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %int2_633 = torch.constant.int 2
    %int3_634 = torch.constant.int 3
    %520 = torch.prim.ListConstruct %int2_633, %int3_634 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_635 = torch.constant.int 0
    %true_636 = torch.constant.bool true
    %result0_637, %result1_638 = torch.aten.var_mean.correction %519, %520, %int0_635, %true_636 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_639 = torch.constant.float 9.9999999999999995E-7
    %int1_640 = torch.constant.int 1
    %521 = torch.aten.add.Scalar %result0_637, %float9.999990e-07_639, %int1_640 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %522 = torch.aten.rsqrt %521 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_641 = torch.constant.int 1
    %523 = torch.aten.sub.Tensor %518, %result1_638, %int1_641 : !torch.vtensor<[14,32,16,65536],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %524 = torch.aten.mul.Tensor %523, %522 : !torch.vtensor<[14,32,16,65536],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,65536],f32>
    %int14_642 = torch.constant.int 14
    %int512_643 = torch.constant.int 512
    %int256_644 = torch.constant.int 256
    %int256_645 = torch.constant.int 256
    %525 = torch.prim.ListConstruct %int14_642, %int512_643, %int256_644, %int256_645 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %526 = torch.aten.view %524, %525 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[14,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16>
    %527 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_646 = torch.constant.int 0
    %528 = torch.aten.unsqueeze %527, %int0_646 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_647 = torch.constant.int 2
    %529 = torch.aten.unsqueeze %528, %int2_647 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_648 = torch.constant.int 3
    %530 = torch.aten.unsqueeze %529, %int3_648 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16>
    %531 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_649 = torch.constant.int 0
    %532 = torch.aten.unsqueeze %531, %int0_649 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_650 = torch.constant.int 2
    %533 = torch.aten.unsqueeze %532, %int2_650 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_651 = torch.constant.int 3
    %534 = torch.aten.unsqueeze %533, %int3_651 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %535 = torch.aten.mul.Tensor %526, %534 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,256,256],f32>
    %int1_652 = torch.constant.int 1
    %536 = torch.aten.add.Tensor %535, %530, %int1_652 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_653 = torch.constant.int 5
    %537 = torch.prims.convert_element_type %536, %int5_653 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %538 = torch.aten.silu %537 : !torch.vtensor<[14,512,256,256],f16> -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %539 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16>
    %540 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_654 = torch.constant.int 1
    %int1_655 = torch.constant.int 1
    %541 = torch.prim.ListConstruct %int1_654, %int1_655 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_656 = torch.constant.int 1
    %int1_657 = torch.constant.int 1
    %542 = torch.prim.ListConstruct %int1_656, %int1_657 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_658 = torch.constant.int 1
    %int1_659 = torch.constant.int 1
    %543 = torch.prim.ListConstruct %int1_658, %int1_659 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_660 = torch.constant.bool false
    %int0_661 = torch.constant.int 0
    %int0_662 = torch.constant.int 0
    %544 = torch.prim.ListConstruct %int0_661, %int0_662 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_663 = torch.constant.int 1
    %545 = torch.aten.convolution %538, %539, %540, %541, %542, %543, %false_660, %544, %int1_663 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int14_664 = torch.constant.int 14
    %int32_665 = torch.constant.int 32
    %int16_666 = torch.constant.int 16
    %int65536_667 = torch.constant.int 65536
    %546 = torch.prim.ListConstruct %int14_664, %int32_665, %int16_666, %int65536_667 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %547 = torch.aten.view %545, %546 : !torch.vtensor<[14,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,65536],f16>
    %int6_668 = torch.constant.int 6
    %548 = torch.prims.convert_element_type %547, %int6_668 : !torch.vtensor<[14,32,16,65536],f16>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %int2_669 = torch.constant.int 2
    %int3_670 = torch.constant.int 3
    %549 = torch.prim.ListConstruct %int2_669, %int3_670 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_671 = torch.constant.int 0
    %true_672 = torch.constant.bool true
    %result0_673, %result1_674 = torch.aten.var_mean.correction %548, %549, %int0_671, %true_672 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_675 = torch.constant.float 9.9999999999999995E-7
    %int1_676 = torch.constant.int 1
    %550 = torch.aten.add.Scalar %result0_673, %float9.999990e-07_675, %int1_676 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %551 = torch.aten.rsqrt %550 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_677 = torch.constant.int 1
    %552 = torch.aten.sub.Tensor %547, %result1_674, %int1_677 : !torch.vtensor<[14,32,16,65536],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %553 = torch.aten.mul.Tensor %552, %551 : !torch.vtensor<[14,32,16,65536],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,65536],f32>
    %int14_678 = torch.constant.int 14
    %int512_679 = torch.constant.int 512
    %int256_680 = torch.constant.int 256
    %int256_681 = torch.constant.int 256
    %554 = torch.prim.ListConstruct %int14_678, %int512_679, %int256_680, %int256_681 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %555 = torch.aten.view %553, %554 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[14,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16>
    %556 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_682 = torch.constant.int 0
    %557 = torch.aten.unsqueeze %556, %int0_682 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_683 = torch.constant.int 2
    %558 = torch.aten.unsqueeze %557, %int2_683 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_684 = torch.constant.int 3
    %559 = torch.aten.unsqueeze %558, %int3_684 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16>
    %560 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_685 = torch.constant.int 0
    %561 = torch.aten.unsqueeze %560, %int0_685 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_686 = torch.constant.int 2
    %562 = torch.aten.unsqueeze %561, %int2_686 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_687 = torch.constant.int 3
    %563 = torch.aten.unsqueeze %562, %int3_687 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %564 = torch.aten.mul.Tensor %555, %563 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,256,256],f32>
    %int1_688 = torch.constant.int 1
    %565 = torch.aten.add.Tensor %564, %559, %int1_688 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_689 = torch.constant.int 5
    %566 = torch.prims.convert_element_type %565, %int5_689 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %567 = torch.aten.silu %566 : !torch.vtensor<[14,512,256,256],f16> -> !torch.vtensor<[14,512,256,256],f16>
    %none_690 = torch.constant.none
    %568 = torch.aten.clone %567, %none_690 : !torch.vtensor<[14,512,256,256],f16>, !torch.none -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %569 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16>
    %570 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_691 = torch.constant.int 1
    %int1_692 = torch.constant.int 1
    %571 = torch.prim.ListConstruct %int1_691, %int1_692 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_693 = torch.constant.int 1
    %int1_694 = torch.constant.int 1
    %572 = torch.prim.ListConstruct %int1_693, %int1_694 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_695 = torch.constant.int 1
    %int1_696 = torch.constant.int 1
    %573 = torch.prim.ListConstruct %int1_695, %int1_696 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_697 = torch.constant.bool false
    %int0_698 = torch.constant.int 0
    %int0_699 = torch.constant.int 0
    %574 = torch.prim.ListConstruct %int0_698, %int0_699 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_700 = torch.constant.int 1
    %575 = torch.aten.convolution %568, %569, %570, %571, %572, %573, %false_697, %574, %int1_700 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int1_701 = torch.constant.int 1
    %576 = torch.aten.add.Tensor %516, %575, %int1_701 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[14,512,256,256],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %float1.000000e00_702 = torch.constant.float 1.000000e+00
    %577 = torch.aten.div.Scalar %576, %float1.000000e00_702 : !torch.vtensor<[14,512,256,256],f16>, !torch.float -> !torch.vtensor<[14,512,256,256],f16>
    %int14_703 = torch.constant.int 14
    %int32_704 = torch.constant.int 32
    %int16_705 = torch.constant.int 16
    %int65536_706 = torch.constant.int 65536
    %578 = torch.prim.ListConstruct %int14_703, %int32_704, %int16_705, %int65536_706 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %579 = torch.aten.view %577, %578 : !torch.vtensor<[14,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,65536],f16>
    %int6_707 = torch.constant.int 6
    %580 = torch.prims.convert_element_type %579, %int6_707 : !torch.vtensor<[14,32,16,65536],f16>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %int2_708 = torch.constant.int 2
    %int3_709 = torch.constant.int 3
    %581 = torch.prim.ListConstruct %int2_708, %int3_709 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_710 = torch.constant.int 0
    %true_711 = torch.constant.bool true
    %result0_712, %result1_713 = torch.aten.var_mean.correction %580, %581, %int0_710, %true_711 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_714 = torch.constant.float 9.9999999999999995E-7
    %int1_715 = torch.constant.int 1
    %582 = torch.aten.add.Scalar %result0_712, %float9.999990e-07_714, %int1_715 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %583 = torch.aten.rsqrt %582 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_716 = torch.constant.int 1
    %584 = torch.aten.sub.Tensor %579, %result1_713, %int1_716 : !torch.vtensor<[14,32,16,65536],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %585 = torch.aten.mul.Tensor %584, %583 : !torch.vtensor<[14,32,16,65536],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,65536],f32>
    %int14_717 = torch.constant.int 14
    %int512_718 = torch.constant.int 512
    %int256_719 = torch.constant.int 256
    %int256_720 = torch.constant.int 256
    %586 = torch.prim.ListConstruct %int14_717, %int512_718, %int256_719, %int256_720 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %587 = torch.aten.view %585, %586 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[14,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16>
    %588 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_721 = torch.constant.int 0
    %589 = torch.aten.unsqueeze %588, %int0_721 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_722 = torch.constant.int 2
    %590 = torch.aten.unsqueeze %589, %int2_722 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_723 = torch.constant.int 3
    %591 = torch.aten.unsqueeze %590, %int3_723 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16>
    %592 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_724 = torch.constant.int 0
    %593 = torch.aten.unsqueeze %592, %int0_724 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_725 = torch.constant.int 2
    %594 = torch.aten.unsqueeze %593, %int2_725 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_726 = torch.constant.int 3
    %595 = torch.aten.unsqueeze %594, %int3_726 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %596 = torch.aten.mul.Tensor %587, %595 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,256,256],f32>
    %int1_727 = torch.constant.int 1
    %597 = torch.aten.add.Tensor %596, %591, %int1_727 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_728 = torch.constant.int 5
    %598 = torch.prims.convert_element_type %597, %int5_728 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %599 = torch.aten.silu %598 : !torch.vtensor<[14,512,256,256],f16> -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %600 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16>
    %601 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_729 = torch.constant.int 1
    %int1_730 = torch.constant.int 1
    %602 = torch.prim.ListConstruct %int1_729, %int1_730 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_731 = torch.constant.int 1
    %int1_732 = torch.constant.int 1
    %603 = torch.prim.ListConstruct %int1_731, %int1_732 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_733 = torch.constant.int 1
    %int1_734 = torch.constant.int 1
    %604 = torch.prim.ListConstruct %int1_733, %int1_734 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_735 = torch.constant.bool false
    %int0_736 = torch.constant.int 0
    %int0_737 = torch.constant.int 0
    %605 = torch.prim.ListConstruct %int0_736, %int0_737 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_738 = torch.constant.int 1
    %606 = torch.aten.convolution %599, %600, %601, %602, %603, %604, %false_735, %605, %int1_738 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int14_739 = torch.constant.int 14
    %int32_740 = torch.constant.int 32
    %int16_741 = torch.constant.int 16
    %int65536_742 = torch.constant.int 65536
    %607 = torch.prim.ListConstruct %int14_739, %int32_740, %int16_741, %int65536_742 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %608 = torch.aten.view %606, %607 : !torch.vtensor<[14,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,65536],f16>
    %int6_743 = torch.constant.int 6
    %609 = torch.prims.convert_element_type %608, %int6_743 : !torch.vtensor<[14,32,16,65536],f16>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %int2_744 = torch.constant.int 2
    %int3_745 = torch.constant.int 3
    %610 = torch.prim.ListConstruct %int2_744, %int3_745 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_746 = torch.constant.int 0
    %true_747 = torch.constant.bool true
    %result0_748, %result1_749 = torch.aten.var_mean.correction %609, %610, %int0_746, %true_747 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_750 = torch.constant.float 9.9999999999999995E-7
    %int1_751 = torch.constant.int 1
    %611 = torch.aten.add.Scalar %result0_748, %float9.999990e-07_750, %int1_751 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %612 = torch.aten.rsqrt %611 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_752 = torch.constant.int 1
    %613 = torch.aten.sub.Tensor %608, %result1_749, %int1_752 : !torch.vtensor<[14,32,16,65536],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,65536],f32>
    %614 = torch.aten.mul.Tensor %613, %612 : !torch.vtensor<[14,32,16,65536],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,65536],f32>
    %int14_753 = torch.constant.int 14
    %int512_754 = torch.constant.int 512
    %int256_755 = torch.constant.int 256
    %int256_756 = torch.constant.int 256
    %615 = torch.prim.ListConstruct %int14_753, %int512_754, %int256_755, %int256_756 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %616 = torch.aten.view %614, %615 : !torch.vtensor<[14,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[14,512,256,256],f32>
    %__auto.decoder.up_blocks.1.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16>
    %617 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_757 = torch.constant.int 0
    %618 = torch.aten.unsqueeze %617, %int0_757 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_758 = torch.constant.int 2
    %619 = torch.aten.unsqueeze %618, %int2_758 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_759 = torch.constant.int 3
    %620 = torch.aten.unsqueeze %619, %int3_759 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.1.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16>
    %621 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_760 = torch.constant.int 0
    %622 = torch.aten.unsqueeze %621, %int0_760 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_761 = torch.constant.int 2
    %623 = torch.aten.unsqueeze %622, %int2_761 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_762 = torch.constant.int 3
    %624 = torch.aten.unsqueeze %623, %int3_762 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %625 = torch.aten.mul.Tensor %616, %624 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,256,256],f32>
    %int1_763 = torch.constant.int 1
    %626 = torch.aten.add.Tensor %625, %620, %int1_763 : !torch.vtensor<[14,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int5_764 = torch.constant.int 5
    %627 = torch.prims.convert_element_type %626, %int5_764 : !torch.vtensor<[14,512,256,256],f32>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %628 = torch.aten.silu %627 : !torch.vtensor<[14,512,256,256],f16> -> !torch.vtensor<[14,512,256,256],f16>
    %none_765 = torch.constant.none
    %629 = torch.aten.clone %628, %none_765 : !torch.vtensor<[14,512,256,256],f16>, !torch.none -> !torch.vtensor<[14,512,256,256],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %630 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16>
    %631 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_766 = torch.constant.int 1
    %int1_767 = torch.constant.int 1
    %632 = torch.prim.ListConstruct %int1_766, %int1_767 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_768 = torch.constant.int 1
    %int1_769 = torch.constant.int 1
    %633 = torch.prim.ListConstruct %int1_768, %int1_769 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_770 = torch.constant.int 1
    %int1_771 = torch.constant.int 1
    %634 = torch.prim.ListConstruct %int1_770, %int1_771 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_772 = torch.constant.bool false
    %int0_773 = torch.constant.int 0
    %int0_774 = torch.constant.int 0
    %635 = torch.prim.ListConstruct %int0_773, %int0_774 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_775 = torch.constant.int 1
    %636 = torch.aten.convolution %629, %630, %631, %632, %633, %634, %false_772, %635, %int1_775 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %int1_776 = torch.constant.int 1
    %637 = torch.aten.add.Tensor %577, %636, %int1_776 : !torch.vtensor<[14,512,256,256],f16>, !torch.vtensor<[14,512,256,256],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f16>
    %float1.000000e00_777 = torch.constant.float 1.000000e+00
    %638 = torch.aten.div.Scalar %637, %float1.000000e00_777 : !torch.vtensor<[14,512,256,256],f16>, !torch.float -> !torch.vtensor<[14,512,256,256],f16>
    %int6_778 = torch.constant.int 6
    %639 = torch.prims.convert_element_type %638, %int6_778 : !torch.vtensor<[14,512,256,256],f16>, !torch.int -> !torch.vtensor<[14,512,256,256],f32>
    %int512_779 = torch.constant.int 512
    %int6_780 = torch.constant.int 6
    %none_781 = torch.constant.none
    %cpu_782 = torch.constant.device "cpu"
    %false_783 = torch.constant.bool false
    %640 = torch.aten.arange %int512_779, %int6_780, %none_781, %cpu_782, %false_783 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_784 = torch.constant.float 0.000000e+00
    %int1_785 = torch.constant.int 1
    %641 = torch.aten.add.Scalar %640, %float0.000000e00_784, %int1_785 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_786 = torch.constant.float 5.000000e-01
    %642 = torch.aten.mul.Scalar %641, %float5.000000e-01_786 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_787 = torch.constant.int 4
    %643 = torch.prims.convert_element_type %642, %int4_787 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %int-1_788 = torch.constant.int -1
    %644 = torch.aten.unsqueeze %643, %int-1_788 : !torch.vtensor<[512],si64>, !torch.int -> !torch.vtensor<[512,1],si64>
    %int512_789 = torch.constant.int 512
    %int6_790 = torch.constant.int 6
    %none_791 = torch.constant.none
    %cpu_792 = torch.constant.device "cpu"
    %false_793 = torch.constant.bool false
    %645 = torch.aten.arange %int512_789, %int6_790, %none_791, %cpu_792, %false_793 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_794 = torch.constant.float 0.000000e+00
    %int1_795 = torch.constant.int 1
    %646 = torch.aten.add.Scalar %645, %float0.000000e00_794, %int1_795 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_796 = torch.constant.float 5.000000e-01
    %647 = torch.aten.mul.Scalar %646, %float5.000000e-01_796 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_797 = torch.constant.int 4
    %648 = torch.prims.convert_element_type %647, %int4_797 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %none_798 = torch.constant.none
    %none_799 = torch.constant.none
    %649 = torch.prim.ListConstruct %none_798, %none_799, %644, %648 : (!torch.none, !torch.none, !torch.vtensor<[512,1],si64>, !torch.vtensor<[512],si64>) -> !torch.list<optional<vtensor>>
    %650 = torch.aten.index.Tensor %639, %649 : !torch.vtensor<[14,512,256,256],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[14,512,512,512],f32>
    %int2_800 = torch.constant.int 2
    %651 = torch.aten.clone %650, %int2_800 : !torch.vtensor<[14,512,512,512],f32>, !torch.int -> !torch.vtensor<[14,512,512,512],f32>
    %int5_801 = torch.constant.int 5
    %652 = torch.prims.convert_element_type %651, %int5_801 : !torch.vtensor<[14,512,512,512],f32>, !torch.int -> !torch.vtensor<[14,512,512,512],f16>
    %__auto.decoder.up_blocks.1.upsamplers.0.conv.weight = util.global.load @__auto.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %653 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.decoder.up_blocks.1.upsamplers.0.conv.bias = util.global.load @__auto.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16>
    %654 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_802 = torch.constant.int 1
    %int1_803 = torch.constant.int 1
    %655 = torch.prim.ListConstruct %int1_802, %int1_803 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_804 = torch.constant.int 1
    %int1_805 = torch.constant.int 1
    %656 = torch.prim.ListConstruct %int1_804, %int1_805 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_806 = torch.constant.int 1
    %int1_807 = torch.constant.int 1
    %657 = torch.prim.ListConstruct %int1_806, %int1_807 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_808 = torch.constant.bool false
    %int0_809 = torch.constant.int 0
    %int0_810 = torch.constant.int 0
    %658 = torch.prim.ListConstruct %int0_809, %int0_810 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_811 = torch.constant.int 1
    %659 = torch.aten.convolution %652, %653, %654, %655, %656, %657, %false_808, %658, %int1_811 : !torch.vtensor<[14,512,512,512],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,512,512,512],f16>
    %int14_812 = torch.constant.int 14
    %int32_813 = torch.constant.int 32
    %int16_814 = torch.constant.int 16
    %int262144 = torch.constant.int 262144
    %660 = torch.prim.ListConstruct %int14_812, %int32_813, %int16_814, %int262144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %661 = torch.aten.view %659, %660 : !torch.vtensor<[14,512,512,512],f16>, !torch.list<int> -> !torch.vtensor<[14,32,16,262144],f16>
    %int6_815 = torch.constant.int 6
    %662 = torch.prims.convert_element_type %661, %int6_815 : !torch.vtensor<[14,32,16,262144],f16>, !torch.int -> !torch.vtensor<[14,32,16,262144],f32>
    %int2_816 = torch.constant.int 2
    %int3_817 = torch.constant.int 3
    %663 = torch.prim.ListConstruct %int2_816, %int3_817 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_818 = torch.constant.int 0
    %true_819 = torch.constant.bool true
    %result0_820, %result1_821 = torch.aten.var_mean.correction %662, %663, %int0_818, %true_819 : !torch.vtensor<[14,32,16,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_822 = torch.constant.float 9.9999999999999995E-7
    %int1_823 = torch.constant.int 1
    %664 = torch.aten.add.Scalar %result0_820, %float9.999990e-07_822, %int1_823 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %665 = torch.aten.rsqrt %664 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_824 = torch.constant.int 1
    %666 = torch.aten.sub.Tensor %661, %result1_821, %int1_824 : !torch.vtensor<[14,32,16,262144],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,16,262144],f32>
    %667 = torch.aten.mul.Tensor %666, %665 : !torch.vtensor<[14,32,16,262144],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,16,262144],f32>
    %int14_825 = torch.constant.int 14
    %int512_826 = torch.constant.int 512
    %int512_827 = torch.constant.int 512
    %int512_828 = torch.constant.int 512
    %668 = torch.prim.ListConstruct %int14_825, %int512_826, %int512_827, %int512_828 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %669 = torch.aten.view %667, %668 : !torch.vtensor<[14,32,16,262144],f32>, !torch.list<int> -> !torch.vtensor<[14,512,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16>
    %670 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_829 = torch.constant.int 0
    %671 = torch.aten.unsqueeze %670, %int0_829 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_830 = torch.constant.int 2
    %672 = torch.aten.unsqueeze %671, %int2_830 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_831 = torch.constant.int 3
    %673 = torch.aten.unsqueeze %672, %int3_831 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16>
    %674 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_832 = torch.constant.int 0
    %675 = torch.aten.unsqueeze %674, %int0_832 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_833 = torch.constant.int 2
    %676 = torch.aten.unsqueeze %675, %int2_833 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_834 = torch.constant.int 3
    %677 = torch.aten.unsqueeze %676, %int3_834 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %678 = torch.aten.mul.Tensor %669, %677 : !torch.vtensor<[14,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[14,512,512,512],f32>
    %int1_835 = torch.constant.int 1
    %679 = torch.aten.add.Tensor %678, %673, %int1_835 : !torch.vtensor<[14,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[14,512,512,512],f32>
    %int5_836 = torch.constant.int 5
    %680 = torch.prims.convert_element_type %679, %int5_836 : !torch.vtensor<[14,512,512,512],f32>, !torch.int -> !torch.vtensor<[14,512,512,512],f16>
    %681 = torch.aten.silu %680 : !torch.vtensor<[14,512,512,512],f16> -> !torch.vtensor<[14,512,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16>
    %682 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16> -> !torch.vtensor<[256,512,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16>
    %683 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_837 = torch.constant.int 1
    %int1_838 = torch.constant.int 1
    %684 = torch.prim.ListConstruct %int1_837, %int1_838 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_839 = torch.constant.int 1
    %int1_840 = torch.constant.int 1
    %685 = torch.prim.ListConstruct %int1_839, %int1_840 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_841 = torch.constant.int 1
    %int1_842 = torch.constant.int 1
    %686 = torch.prim.ListConstruct %int1_841, %int1_842 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_843 = torch.constant.bool false
    %int0_844 = torch.constant.int 0
    %int0_845 = torch.constant.int 0
    %687 = torch.prim.ListConstruct %int0_844, %int0_845 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_846 = torch.constant.int 1
    %688 = torch.aten.convolution %681, %682, %683, %684, %685, %686, %false_843, %687, %int1_846 : !torch.vtensor<[14,512,512,512],f16>, !torch.vtensor<[256,512,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %int14_847 = torch.constant.int 14
    %int32_848 = torch.constant.int 32
    %int8 = torch.constant.int 8
    %int262144_849 = torch.constant.int 262144
    %689 = torch.prim.ListConstruct %int14_847, %int32_848, %int8, %int262144_849 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %690 = torch.aten.view %688, %689 : !torch.vtensor<[14,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[14,32,8,262144],f16>
    %int6_850 = torch.constant.int 6
    %691 = torch.prims.convert_element_type %690, %int6_850 : !torch.vtensor<[14,32,8,262144],f16>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %int2_851 = torch.constant.int 2
    %int3_852 = torch.constant.int 3
    %692 = torch.prim.ListConstruct %int2_851, %int3_852 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_853 = torch.constant.int 0
    %true_854 = torch.constant.bool true
    %result0_855, %result1_856 = torch.aten.var_mean.correction %691, %692, %int0_853, %true_854 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_857 = torch.constant.float 9.9999999999999995E-7
    %int1_858 = torch.constant.int 1
    %693 = torch.aten.add.Scalar %result0_855, %float9.999990e-07_857, %int1_858 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %694 = torch.aten.rsqrt %693 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_859 = torch.constant.int 1
    %695 = torch.aten.sub.Tensor %690, %result1_856, %int1_859 : !torch.vtensor<[14,32,8,262144],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %696 = torch.aten.mul.Tensor %695, %694 : !torch.vtensor<[14,32,8,262144],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,8,262144],f32>
    %int14_860 = torch.constant.int 14
    %int256_861 = torch.constant.int 256
    %int512_862 = torch.constant.int 512
    %int512_863 = torch.constant.int 512
    %697 = torch.prim.ListConstruct %int14_860, %int256_861, %int512_862, %int512_863 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %698 = torch.aten.view %696, %697 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[14,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16>
    %699 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_864 = torch.constant.int 0
    %700 = torch.aten.unsqueeze %699, %int0_864 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_865 = torch.constant.int 2
    %701 = torch.aten.unsqueeze %700, %int2_865 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_866 = torch.constant.int 3
    %702 = torch.aten.unsqueeze %701, %int3_866 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16>
    %703 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_867 = torch.constant.int 0
    %704 = torch.aten.unsqueeze %703, %int0_867 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_868 = torch.constant.int 2
    %705 = torch.aten.unsqueeze %704, %int2_868 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_869 = torch.constant.int 3
    %706 = torch.aten.unsqueeze %705, %int3_869 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %707 = torch.aten.mul.Tensor %698, %706 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[14,256,512,512],f32>
    %int1_870 = torch.constant.int 1
    %708 = torch.aten.add.Tensor %707, %702, %int1_870 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f32>
    %int5_871 = torch.constant.int 5
    %709 = torch.prims.convert_element_type %708, %int5_871 : !torch.vtensor<[14,256,512,512],f32>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %710 = torch.aten.silu %709 : !torch.vtensor<[14,256,512,512],f16> -> !torch.vtensor<[14,256,512,512],f16>
    %none_872 = torch.constant.none
    %711 = torch.aten.clone %710, %none_872 : !torch.vtensor<[14,256,512,512],f16>, !torch.none -> !torch.vtensor<[14,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16>
    %712 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16>
    %713 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_873 = torch.constant.int 1
    %int1_874 = torch.constant.int 1
    %714 = torch.prim.ListConstruct %int1_873, %int1_874 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_875 = torch.constant.int 1
    %int1_876 = torch.constant.int 1
    %715 = torch.prim.ListConstruct %int1_875, %int1_876 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_877 = torch.constant.int 1
    %int1_878 = torch.constant.int 1
    %716 = torch.prim.ListConstruct %int1_877, %int1_878 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_879 = torch.constant.bool false
    %int0_880 = torch.constant.int 0
    %int0_881 = torch.constant.int 0
    %717 = torch.prim.ListConstruct %int0_880, %int0_881 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_882 = torch.constant.int 1
    %718 = torch.aten.convolution %711, %712, %713, %714, %715, %716, %false_879, %717, %int1_882 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16>
    %719 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16> -> !torch.vtensor<[256,512,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16>
    %720 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_883 = torch.constant.int 1
    %int1_884 = torch.constant.int 1
    %721 = torch.prim.ListConstruct %int1_883, %int1_884 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_885 = torch.constant.int 0
    %int0_886 = torch.constant.int 0
    %722 = torch.prim.ListConstruct %int0_885, %int0_886 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_887 = torch.constant.int 1
    %int1_888 = torch.constant.int 1
    %723 = torch.prim.ListConstruct %int1_887, %int1_888 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_889 = torch.constant.bool false
    %int0_890 = torch.constant.int 0
    %int0_891 = torch.constant.int 0
    %724 = torch.prim.ListConstruct %int0_890, %int0_891 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_892 = torch.constant.int 1
    %725 = torch.aten.convolution %659, %719, %720, %721, %722, %723, %false_889, %724, %int1_892 : !torch.vtensor<[14,512,512,512],f16>, !torch.vtensor<[256,512,1,1],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %int1_893 = torch.constant.int 1
    %726 = torch.aten.add.Tensor %725, %718, %int1_893 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[14,256,512,512],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %float1.000000e00_894 = torch.constant.float 1.000000e+00
    %727 = torch.aten.div.Scalar %726, %float1.000000e00_894 : !torch.vtensor<[14,256,512,512],f16>, !torch.float -> !torch.vtensor<[14,256,512,512],f16>
    %int14_895 = torch.constant.int 14
    %int32_896 = torch.constant.int 32
    %int8_897 = torch.constant.int 8
    %int262144_898 = torch.constant.int 262144
    %728 = torch.prim.ListConstruct %int14_895, %int32_896, %int8_897, %int262144_898 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %729 = torch.aten.view %727, %728 : !torch.vtensor<[14,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[14,32,8,262144],f16>
    %int6_899 = torch.constant.int 6
    %730 = torch.prims.convert_element_type %729, %int6_899 : !torch.vtensor<[14,32,8,262144],f16>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %int2_900 = torch.constant.int 2
    %int3_901 = torch.constant.int 3
    %731 = torch.prim.ListConstruct %int2_900, %int3_901 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_902 = torch.constant.int 0
    %true_903 = torch.constant.bool true
    %result0_904, %result1_905 = torch.aten.var_mean.correction %730, %731, %int0_902, %true_903 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_906 = torch.constant.float 9.9999999999999995E-7
    %int1_907 = torch.constant.int 1
    %732 = torch.aten.add.Scalar %result0_904, %float9.999990e-07_906, %int1_907 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %733 = torch.aten.rsqrt %732 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_908 = torch.constant.int 1
    %734 = torch.aten.sub.Tensor %729, %result1_905, %int1_908 : !torch.vtensor<[14,32,8,262144],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %735 = torch.aten.mul.Tensor %734, %733 : !torch.vtensor<[14,32,8,262144],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,8,262144],f32>
    %int14_909 = torch.constant.int 14
    %int256_910 = torch.constant.int 256
    %int512_911 = torch.constant.int 512
    %int512_912 = torch.constant.int 512
    %736 = torch.prim.ListConstruct %int14_909, %int256_910, %int512_911, %int512_912 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %737 = torch.aten.view %735, %736 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[14,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16>
    %738 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_913 = torch.constant.int 0
    %739 = torch.aten.unsqueeze %738, %int0_913 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_914 = torch.constant.int 2
    %740 = torch.aten.unsqueeze %739, %int2_914 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_915 = torch.constant.int 3
    %741 = torch.aten.unsqueeze %740, %int3_915 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16>
    %742 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_916 = torch.constant.int 0
    %743 = torch.aten.unsqueeze %742, %int0_916 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_917 = torch.constant.int 2
    %744 = torch.aten.unsqueeze %743, %int2_917 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_918 = torch.constant.int 3
    %745 = torch.aten.unsqueeze %744, %int3_918 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %746 = torch.aten.mul.Tensor %737, %745 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[14,256,512,512],f32>
    %int1_919 = torch.constant.int 1
    %747 = torch.aten.add.Tensor %746, %741, %int1_919 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f32>
    %int5_920 = torch.constant.int 5
    %748 = torch.prims.convert_element_type %747, %int5_920 : !torch.vtensor<[14,256,512,512],f32>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %749 = torch.aten.silu %748 : !torch.vtensor<[14,256,512,512],f16> -> !torch.vtensor<[14,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16>
    %750 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16>
    %751 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_921 = torch.constant.int 1
    %int1_922 = torch.constant.int 1
    %752 = torch.prim.ListConstruct %int1_921, %int1_922 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_923 = torch.constant.int 1
    %int1_924 = torch.constant.int 1
    %753 = torch.prim.ListConstruct %int1_923, %int1_924 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_925 = torch.constant.int 1
    %int1_926 = torch.constant.int 1
    %754 = torch.prim.ListConstruct %int1_925, %int1_926 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_927 = torch.constant.bool false
    %int0_928 = torch.constant.int 0
    %int0_929 = torch.constant.int 0
    %755 = torch.prim.ListConstruct %int0_928, %int0_929 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_930 = torch.constant.int 1
    %756 = torch.aten.convolution %749, %750, %751, %752, %753, %754, %false_927, %755, %int1_930 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %int14_931 = torch.constant.int 14
    %int32_932 = torch.constant.int 32
    %int8_933 = torch.constant.int 8
    %int262144_934 = torch.constant.int 262144
    %757 = torch.prim.ListConstruct %int14_931, %int32_932, %int8_933, %int262144_934 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %758 = torch.aten.view %756, %757 : !torch.vtensor<[14,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[14,32,8,262144],f16>
    %int6_935 = torch.constant.int 6
    %759 = torch.prims.convert_element_type %758, %int6_935 : !torch.vtensor<[14,32,8,262144],f16>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %int2_936 = torch.constant.int 2
    %int3_937 = torch.constant.int 3
    %760 = torch.prim.ListConstruct %int2_936, %int3_937 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_938 = torch.constant.int 0
    %true_939 = torch.constant.bool true
    %result0_940, %result1_941 = torch.aten.var_mean.correction %759, %760, %int0_938, %true_939 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_942 = torch.constant.float 9.9999999999999995E-7
    %int1_943 = torch.constant.int 1
    %761 = torch.aten.add.Scalar %result0_940, %float9.999990e-07_942, %int1_943 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %762 = torch.aten.rsqrt %761 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_944 = torch.constant.int 1
    %763 = torch.aten.sub.Tensor %758, %result1_941, %int1_944 : !torch.vtensor<[14,32,8,262144],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %764 = torch.aten.mul.Tensor %763, %762 : !torch.vtensor<[14,32,8,262144],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,8,262144],f32>
    %int14_945 = torch.constant.int 14
    %int256_946 = torch.constant.int 256
    %int512_947 = torch.constant.int 512
    %int512_948 = torch.constant.int 512
    %765 = torch.prim.ListConstruct %int14_945, %int256_946, %int512_947, %int512_948 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %766 = torch.aten.view %764, %765 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[14,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16>
    %767 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_949 = torch.constant.int 0
    %768 = torch.aten.unsqueeze %767, %int0_949 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_950 = torch.constant.int 2
    %769 = torch.aten.unsqueeze %768, %int2_950 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_951 = torch.constant.int 3
    %770 = torch.aten.unsqueeze %769, %int3_951 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16>
    %771 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_952 = torch.constant.int 0
    %772 = torch.aten.unsqueeze %771, %int0_952 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_953 = torch.constant.int 2
    %773 = torch.aten.unsqueeze %772, %int2_953 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_954 = torch.constant.int 3
    %774 = torch.aten.unsqueeze %773, %int3_954 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %775 = torch.aten.mul.Tensor %766, %774 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[14,256,512,512],f32>
    %int1_955 = torch.constant.int 1
    %776 = torch.aten.add.Tensor %775, %770, %int1_955 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f32>
    %int5_956 = torch.constant.int 5
    %777 = torch.prims.convert_element_type %776, %int5_956 : !torch.vtensor<[14,256,512,512],f32>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %778 = torch.aten.silu %777 : !torch.vtensor<[14,256,512,512],f16> -> !torch.vtensor<[14,256,512,512],f16>
    %none_957 = torch.constant.none
    %779 = torch.aten.clone %778, %none_957 : !torch.vtensor<[14,256,512,512],f16>, !torch.none -> !torch.vtensor<[14,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16>
    %780 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16>
    %781 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_958 = torch.constant.int 1
    %int1_959 = torch.constant.int 1
    %782 = torch.prim.ListConstruct %int1_958, %int1_959 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_960 = torch.constant.int 1
    %int1_961 = torch.constant.int 1
    %783 = torch.prim.ListConstruct %int1_960, %int1_961 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_962 = torch.constant.int 1
    %int1_963 = torch.constant.int 1
    %784 = torch.prim.ListConstruct %int1_962, %int1_963 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_964 = torch.constant.bool false
    %int0_965 = torch.constant.int 0
    %int0_966 = torch.constant.int 0
    %785 = torch.prim.ListConstruct %int0_965, %int0_966 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_967 = torch.constant.int 1
    %786 = torch.aten.convolution %779, %780, %781, %782, %783, %784, %false_964, %785, %int1_967 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %int1_968 = torch.constant.int 1
    %787 = torch.aten.add.Tensor %727, %786, %int1_968 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[14,256,512,512],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %float1.000000e00_969 = torch.constant.float 1.000000e+00
    %788 = torch.aten.div.Scalar %787, %float1.000000e00_969 : !torch.vtensor<[14,256,512,512],f16>, !torch.float -> !torch.vtensor<[14,256,512,512],f16>
    %int14_970 = torch.constant.int 14
    %int32_971 = torch.constant.int 32
    %int8_972 = torch.constant.int 8
    %int262144_973 = torch.constant.int 262144
    %789 = torch.prim.ListConstruct %int14_970, %int32_971, %int8_972, %int262144_973 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %790 = torch.aten.view %788, %789 : !torch.vtensor<[14,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[14,32,8,262144],f16>
    %int6_974 = torch.constant.int 6
    %791 = torch.prims.convert_element_type %790, %int6_974 : !torch.vtensor<[14,32,8,262144],f16>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %int2_975 = torch.constant.int 2
    %int3_976 = torch.constant.int 3
    %792 = torch.prim.ListConstruct %int2_975, %int3_976 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_977 = torch.constant.int 0
    %true_978 = torch.constant.bool true
    %result0_979, %result1_980 = torch.aten.var_mean.correction %791, %792, %int0_977, %true_978 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_981 = torch.constant.float 9.9999999999999995E-7
    %int1_982 = torch.constant.int 1
    %793 = torch.aten.add.Scalar %result0_979, %float9.999990e-07_981, %int1_982 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %794 = torch.aten.rsqrt %793 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_983 = torch.constant.int 1
    %795 = torch.aten.sub.Tensor %790, %result1_980, %int1_983 : !torch.vtensor<[14,32,8,262144],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %796 = torch.aten.mul.Tensor %795, %794 : !torch.vtensor<[14,32,8,262144],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,8,262144],f32>
    %int14_984 = torch.constant.int 14
    %int256_985 = torch.constant.int 256
    %int512_986 = torch.constant.int 512
    %int512_987 = torch.constant.int 512
    %797 = torch.prim.ListConstruct %int14_984, %int256_985, %int512_986, %int512_987 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %798 = torch.aten.view %796, %797 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[14,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16>
    %799 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_988 = torch.constant.int 0
    %800 = torch.aten.unsqueeze %799, %int0_988 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_989 = torch.constant.int 2
    %801 = torch.aten.unsqueeze %800, %int2_989 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_990 = torch.constant.int 3
    %802 = torch.aten.unsqueeze %801, %int3_990 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16>
    %803 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_991 = torch.constant.int 0
    %804 = torch.aten.unsqueeze %803, %int0_991 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_992 = torch.constant.int 2
    %805 = torch.aten.unsqueeze %804, %int2_992 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_993 = torch.constant.int 3
    %806 = torch.aten.unsqueeze %805, %int3_993 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %807 = torch.aten.mul.Tensor %798, %806 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[14,256,512,512],f32>
    %int1_994 = torch.constant.int 1
    %808 = torch.aten.add.Tensor %807, %802, %int1_994 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f32>
    %int5_995 = torch.constant.int 5
    %809 = torch.prims.convert_element_type %808, %int5_995 : !torch.vtensor<[14,256,512,512],f32>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %810 = torch.aten.silu %809 : !torch.vtensor<[14,256,512,512],f16> -> !torch.vtensor<[14,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16>
    %811 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16>
    %812 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_996 = torch.constant.int 1
    %int1_997 = torch.constant.int 1
    %813 = torch.prim.ListConstruct %int1_996, %int1_997 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_998 = torch.constant.int 1
    %int1_999 = torch.constant.int 1
    %814 = torch.prim.ListConstruct %int1_998, %int1_999 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1000 = torch.constant.int 1
    %int1_1001 = torch.constant.int 1
    %815 = torch.prim.ListConstruct %int1_1000, %int1_1001 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1002 = torch.constant.bool false
    %int0_1003 = torch.constant.int 0
    %int0_1004 = torch.constant.int 0
    %816 = torch.prim.ListConstruct %int0_1003, %int0_1004 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1005 = torch.constant.int 1
    %817 = torch.aten.convolution %810, %811, %812, %813, %814, %815, %false_1002, %816, %int1_1005 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %int14_1006 = torch.constant.int 14
    %int32_1007 = torch.constant.int 32
    %int8_1008 = torch.constant.int 8
    %int262144_1009 = torch.constant.int 262144
    %818 = torch.prim.ListConstruct %int14_1006, %int32_1007, %int8_1008, %int262144_1009 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %819 = torch.aten.view %817, %818 : !torch.vtensor<[14,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[14,32,8,262144],f16>
    %int6_1010 = torch.constant.int 6
    %820 = torch.prims.convert_element_type %819, %int6_1010 : !torch.vtensor<[14,32,8,262144],f16>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %int2_1011 = torch.constant.int 2
    %int3_1012 = torch.constant.int 3
    %821 = torch.prim.ListConstruct %int2_1011, %int3_1012 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1013 = torch.constant.int 0
    %true_1014 = torch.constant.bool true
    %result0_1015, %result1_1016 = torch.aten.var_mean.correction %820, %821, %int0_1013, %true_1014 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1017 = torch.constant.float 9.9999999999999995E-7
    %int1_1018 = torch.constant.int 1
    %822 = torch.aten.add.Scalar %result0_1015, %float9.999990e-07_1017, %int1_1018 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %823 = torch.aten.rsqrt %822 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1019 = torch.constant.int 1
    %824 = torch.aten.sub.Tensor %819, %result1_1016, %int1_1019 : !torch.vtensor<[14,32,8,262144],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,8,262144],f32>
    %825 = torch.aten.mul.Tensor %824, %823 : !torch.vtensor<[14,32,8,262144],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,8,262144],f32>
    %int14_1020 = torch.constant.int 14
    %int256_1021 = torch.constant.int 256
    %int512_1022 = torch.constant.int 512
    %int512_1023 = torch.constant.int 512
    %826 = torch.prim.ListConstruct %int14_1020, %int256_1021, %int512_1022, %int512_1023 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %827 = torch.aten.view %825, %826 : !torch.vtensor<[14,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[14,256,512,512],f32>
    %__auto.decoder.up_blocks.2.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16>
    %828 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1024 = torch.constant.int 0
    %829 = torch.aten.unsqueeze %828, %int0_1024 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1025 = torch.constant.int 2
    %830 = torch.aten.unsqueeze %829, %int2_1025 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1026 = torch.constant.int 3
    %831 = torch.aten.unsqueeze %830, %int3_1026 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.2.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16>
    %832 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1027 = torch.constant.int 0
    %833 = torch.aten.unsqueeze %832, %int0_1027 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1028 = torch.constant.int 2
    %834 = torch.aten.unsqueeze %833, %int2_1028 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1029 = torch.constant.int 3
    %835 = torch.aten.unsqueeze %834, %int3_1029 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %836 = torch.aten.mul.Tensor %827, %835 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[14,256,512,512],f32>
    %int1_1030 = torch.constant.int 1
    %837 = torch.aten.add.Tensor %836, %831, %int1_1030 : !torch.vtensor<[14,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f32>
    %int5_1031 = torch.constant.int 5
    %838 = torch.prims.convert_element_type %837, %int5_1031 : !torch.vtensor<[14,256,512,512],f32>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %839 = torch.aten.silu %838 : !torch.vtensor<[14,256,512,512],f16> -> !torch.vtensor<[14,256,512,512],f16>
    %none_1032 = torch.constant.none
    %840 = torch.aten.clone %839, %none_1032 : !torch.vtensor<[14,256,512,512],f16>, !torch.none -> !torch.vtensor<[14,256,512,512],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16>
    %841 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16>
    %842 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1033 = torch.constant.int 1
    %int1_1034 = torch.constant.int 1
    %843 = torch.prim.ListConstruct %int1_1033, %int1_1034 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1035 = torch.constant.int 1
    %int1_1036 = torch.constant.int 1
    %844 = torch.prim.ListConstruct %int1_1035, %int1_1036 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1037 = torch.constant.int 1
    %int1_1038 = torch.constant.int 1
    %845 = torch.prim.ListConstruct %int1_1037, %int1_1038 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1039 = torch.constant.bool false
    %int0_1040 = torch.constant.int 0
    %int0_1041 = torch.constant.int 0
    %846 = torch.prim.ListConstruct %int0_1040, %int0_1041 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1042 = torch.constant.int 1
    %847 = torch.aten.convolution %840, %841, %842, %843, %844, %845, %false_1039, %846, %int1_1042 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %int1_1043 = torch.constant.int 1
    %848 = torch.aten.add.Tensor %788, %847, %int1_1043 : !torch.vtensor<[14,256,512,512],f16>, !torch.vtensor<[14,256,512,512],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f16>
    %float1.000000e00_1044 = torch.constant.float 1.000000e+00
    %849 = torch.aten.div.Scalar %848, %float1.000000e00_1044 : !torch.vtensor<[14,256,512,512],f16>, !torch.float -> !torch.vtensor<[14,256,512,512],f16>
    %int6_1045 = torch.constant.int 6
    %850 = torch.prims.convert_element_type %849, %int6_1045 : !torch.vtensor<[14,256,512,512],f16>, !torch.int -> !torch.vtensor<[14,256,512,512],f32>
    %int1024 = torch.constant.int 1024
    %int6_1046 = torch.constant.int 6
    %none_1047 = torch.constant.none
    %cpu_1048 = torch.constant.device "cpu"
    %false_1049 = torch.constant.bool false
    %851 = torch.aten.arange %int1024, %int6_1046, %none_1047, %cpu_1048, %false_1049 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1050 = torch.constant.float 0.000000e+00
    %int1_1051 = torch.constant.int 1
    %852 = torch.aten.add.Scalar %851, %float0.000000e00_1050, %int1_1051 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1052 = torch.constant.float 5.000000e-01
    %853 = torch.aten.mul.Scalar %852, %float5.000000e-01_1052 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1053 = torch.constant.int 4
    %854 = torch.prims.convert_element_type %853, %int4_1053 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %int-1_1054 = torch.constant.int -1
    %855 = torch.aten.unsqueeze %854, %int-1_1054 : !torch.vtensor<[1024],si64>, !torch.int -> !torch.vtensor<[1024,1],si64>
    %int1024_1055 = torch.constant.int 1024
    %int6_1056 = torch.constant.int 6
    %none_1057 = torch.constant.none
    %cpu_1058 = torch.constant.device "cpu"
    %false_1059 = torch.constant.bool false
    %856 = torch.aten.arange %int1024_1055, %int6_1056, %none_1057, %cpu_1058, %false_1059 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1060 = torch.constant.float 0.000000e+00
    %int1_1061 = torch.constant.int 1
    %857 = torch.aten.add.Scalar %856, %float0.000000e00_1060, %int1_1061 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1062 = torch.constant.float 5.000000e-01
    %858 = torch.aten.mul.Scalar %857, %float5.000000e-01_1062 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1063 = torch.constant.int 4
    %859 = torch.prims.convert_element_type %858, %int4_1063 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %none_1064 = torch.constant.none
    %none_1065 = torch.constant.none
    %860 = torch.prim.ListConstruct %none_1064, %none_1065, %855, %859 : (!torch.none, !torch.none, !torch.vtensor<[1024,1],si64>, !torch.vtensor<[1024],si64>) -> !torch.list<optional<vtensor>>
    %861 = torch.aten.index.Tensor %850, %860 : !torch.vtensor<[14,256,512,512],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[14,256,1024,1024],f32>
    %int2_1066 = torch.constant.int 2
    %862 = torch.aten.clone %861, %int2_1066 : !torch.vtensor<[14,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,256,1024,1024],f32>
    %int5_1067 = torch.constant.int 5
    %863 = torch.prims.convert_element_type %862, %int5_1067 : !torch.vtensor<[14,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,256,1024,1024],f16>
    %__auto.decoder.up_blocks.2.upsamplers.0.conv.weight = util.global.load @__auto.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16>
    %864 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.decoder.up_blocks.2.upsamplers.0.conv.bias = util.global.load @__auto.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16>
    %865 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1068 = torch.constant.int 1
    %int1_1069 = torch.constant.int 1
    %866 = torch.prim.ListConstruct %int1_1068, %int1_1069 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1070 = torch.constant.int 1
    %int1_1071 = torch.constant.int 1
    %867 = torch.prim.ListConstruct %int1_1070, %int1_1071 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1072 = torch.constant.int 1
    %int1_1073 = torch.constant.int 1
    %868 = torch.prim.ListConstruct %int1_1072, %int1_1073 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1074 = torch.constant.bool false
    %int0_1075 = torch.constant.int 0
    %int0_1076 = torch.constant.int 0
    %869 = torch.prim.ListConstruct %int0_1075, %int0_1076 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1077 = torch.constant.int 1
    %870 = torch.aten.convolution %863, %864, %865, %866, %867, %868, %false_1074, %869, %int1_1077 : !torch.vtensor<[14,256,1024,1024],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,256,1024,1024],f16>
    %int14_1078 = torch.constant.int 14
    %int32_1079 = torch.constant.int 32
    %int8_1080 = torch.constant.int 8
    %int1048576 = torch.constant.int 1048576
    %871 = torch.prim.ListConstruct %int14_1078, %int32_1079, %int8_1080, %int1048576 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %872 = torch.aten.view %870, %871 : !torch.vtensor<[14,256,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,8,1048576],f16>
    %int6_1081 = torch.constant.int 6
    %873 = torch.prims.convert_element_type %872, %int6_1081 : !torch.vtensor<[14,32,8,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,8,1048576],f32>
    %int2_1082 = torch.constant.int 2
    %int3_1083 = torch.constant.int 3
    %874 = torch.prim.ListConstruct %int2_1082, %int3_1083 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1084 = torch.constant.int 0
    %true_1085 = torch.constant.bool true
    %result0_1086, %result1_1087 = torch.aten.var_mean.correction %873, %874, %int0_1084, %true_1085 : !torch.vtensor<[14,32,8,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1088 = torch.constant.float 9.9999999999999995E-7
    %int1_1089 = torch.constant.int 1
    %875 = torch.aten.add.Scalar %result0_1086, %float9.999990e-07_1088, %int1_1089 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %876 = torch.aten.rsqrt %875 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1090 = torch.constant.int 1
    %877 = torch.aten.sub.Tensor %872, %result1_1087, %int1_1090 : !torch.vtensor<[14,32,8,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,8,1048576],f32>
    %878 = torch.aten.mul.Tensor %877, %876 : !torch.vtensor<[14,32,8,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,8,1048576],f32>
    %int14_1091 = torch.constant.int 14
    %int256_1092 = torch.constant.int 256
    %int1024_1093 = torch.constant.int 1024
    %int1024_1094 = torch.constant.int 1024
    %879 = torch.prim.ListConstruct %int14_1091, %int256_1092, %int1024_1093, %int1024_1094 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %880 = torch.aten.view %878, %879 : !torch.vtensor<[14,32,8,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,256,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.0.norm1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16>
    %881 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1095 = torch.constant.int 0
    %882 = torch.aten.unsqueeze %881, %int0_1095 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1096 = torch.constant.int 2
    %883 = torch.aten.unsqueeze %882, %int2_1096 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1097 = torch.constant.int 3
    %884 = torch.aten.unsqueeze %883, %int3_1097 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.0.norm1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16>
    %885 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1098 = torch.constant.int 0
    %886 = torch.aten.unsqueeze %885, %int0_1098 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1099 = torch.constant.int 2
    %887 = torch.aten.unsqueeze %886, %int2_1099 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1100 = torch.constant.int 3
    %888 = torch.aten.unsqueeze %887, %int3_1100 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %889 = torch.aten.mul.Tensor %880, %888 : !torch.vtensor<[14,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[14,256,1024,1024],f32>
    %int1_1101 = torch.constant.int 1
    %890 = torch.aten.add.Tensor %889, %884, %int1_1101 : !torch.vtensor<[14,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[14,256,1024,1024],f32>
    %int5_1102 = torch.constant.int 5
    %891 = torch.prims.convert_element_type %890, %int5_1102 : !torch.vtensor<[14,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,256,1024,1024],f16>
    %892 = torch.aten.silu %891 : !torch.vtensor<[14,256,1024,1024],f16> -> !torch.vtensor<[14,256,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16>
    %893 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16> -> !torch.vtensor<[128,256,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16>
    %894 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1103 = torch.constant.int 1
    %int1_1104 = torch.constant.int 1
    %895 = torch.prim.ListConstruct %int1_1103, %int1_1104 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1105 = torch.constant.int 1
    %int1_1106 = torch.constant.int 1
    %896 = torch.prim.ListConstruct %int1_1105, %int1_1106 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1107 = torch.constant.int 1
    %int1_1108 = torch.constant.int 1
    %897 = torch.prim.ListConstruct %int1_1107, %int1_1108 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1109 = torch.constant.bool false
    %int0_1110 = torch.constant.int 0
    %int0_1111 = torch.constant.int 0
    %898 = torch.prim.ListConstruct %int0_1110, %int0_1111 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1112 = torch.constant.int 1
    %899 = torch.aten.convolution %892, %893, %894, %895, %896, %897, %false_1109, %898, %int1_1112 : !torch.vtensor<[14,256,1024,1024],f16>, !torch.vtensor<[128,256,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %int14_1113 = torch.constant.int 14
    %int32_1114 = torch.constant.int 32
    %int4_1115 = torch.constant.int 4
    %int1048576_1116 = torch.constant.int 1048576
    %900 = torch.prim.ListConstruct %int14_1113, %int32_1114, %int4_1115, %int1048576_1116 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %901 = torch.aten.view %899, %900 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,4,1048576],f16>
    %int6_1117 = torch.constant.int 6
    %902 = torch.prims.convert_element_type %901, %int6_1117 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %int2_1118 = torch.constant.int 2
    %int3_1119 = torch.constant.int 3
    %903 = torch.prim.ListConstruct %int2_1118, %int3_1119 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1120 = torch.constant.int 0
    %true_1121 = torch.constant.bool true
    %result0_1122, %result1_1123 = torch.aten.var_mean.correction %902, %903, %int0_1120, %true_1121 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1124 = torch.constant.float 9.9999999999999995E-7
    %int1_1125 = torch.constant.int 1
    %904 = torch.aten.add.Scalar %result0_1122, %float9.999990e-07_1124, %int1_1125 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %905 = torch.aten.rsqrt %904 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1126 = torch.constant.int 1
    %906 = torch.aten.sub.Tensor %901, %result1_1123, %int1_1126 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %907 = torch.aten.mul.Tensor %906, %905 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,4,1048576],f32>
    %int14_1127 = torch.constant.int 14
    %int128_1128 = torch.constant.int 128
    %int1024_1129 = torch.constant.int 1024
    %int1024_1130 = torch.constant.int 1024
    %908 = torch.prim.ListConstruct %int14_1127, %int128_1128, %int1024_1129, %int1024_1130 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %909 = torch.aten.view %907, %908 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.0.norm2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16>
    %910 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1131 = torch.constant.int 0
    %911 = torch.aten.unsqueeze %910, %int0_1131 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1132 = torch.constant.int 2
    %912 = torch.aten.unsqueeze %911, %int2_1132 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1133 = torch.constant.int 3
    %913 = torch.aten.unsqueeze %912, %int3_1133 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.0.norm2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16>
    %914 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1134 = torch.constant.int 0
    %915 = torch.aten.unsqueeze %914, %int0_1134 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1135 = torch.constant.int 2
    %916 = torch.aten.unsqueeze %915, %int2_1135 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1136 = torch.constant.int 3
    %917 = torch.aten.unsqueeze %916, %int3_1136 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %918 = torch.aten.mul.Tensor %909, %917 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[14,128,1024,1024],f32>
    %int1_1137 = torch.constant.int 1
    %919 = torch.aten.add.Tensor %918, %913, %int1_1137 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f32>
    %int5_1138 = torch.constant.int 5
    %920 = torch.prims.convert_element_type %919, %int5_1138 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %921 = torch.aten.silu %920 : !torch.vtensor<[14,128,1024,1024],f16> -> !torch.vtensor<[14,128,1024,1024],f16>
    %none_1139 = torch.constant.none
    %922 = torch.aten.clone %921, %none_1139 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16>
    %923 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16>
    %924 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1140 = torch.constant.int 1
    %int1_1141 = torch.constant.int 1
    %925 = torch.prim.ListConstruct %int1_1140, %int1_1141 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1142 = torch.constant.int 1
    %int1_1143 = torch.constant.int 1
    %926 = torch.prim.ListConstruct %int1_1142, %int1_1143 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1144 = torch.constant.int 1
    %int1_1145 = torch.constant.int 1
    %927 = torch.prim.ListConstruct %int1_1144, %int1_1145 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1146 = torch.constant.bool false
    %int0_1147 = torch.constant.int 0
    %int0_1148 = torch.constant.int 0
    %928 = torch.prim.ListConstruct %int0_1147, %int0_1148 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1149 = torch.constant.int 1
    %929 = torch.aten.convolution %922, %923, %924, %925, %926, %927, %false_1146, %928, %int1_1149 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16>
    %930 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16> -> !torch.vtensor<[128,256,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16>
    %931 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1150 = torch.constant.int 1
    %int1_1151 = torch.constant.int 1
    %932 = torch.prim.ListConstruct %int1_1150, %int1_1151 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1152 = torch.constant.int 0
    %int0_1153 = torch.constant.int 0
    %933 = torch.prim.ListConstruct %int0_1152, %int0_1153 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1154 = torch.constant.int 1
    %int1_1155 = torch.constant.int 1
    %934 = torch.prim.ListConstruct %int1_1154, %int1_1155 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1156 = torch.constant.bool false
    %int0_1157 = torch.constant.int 0
    %int0_1158 = torch.constant.int 0
    %935 = torch.prim.ListConstruct %int0_1157, %int0_1158 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1159 = torch.constant.int 1
    %936 = torch.aten.convolution %870, %930, %931, %932, %933, %934, %false_1156, %935, %int1_1159 : !torch.vtensor<[14,256,1024,1024],f16>, !torch.vtensor<[128,256,1,1],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %int1_1160 = torch.constant.int 1
    %937 = torch.aten.add.Tensor %936, %929, %int1_1160 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[14,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %float1.000000e00_1161 = torch.constant.float 1.000000e+00
    %938 = torch.aten.div.Scalar %937, %float1.000000e00_1161 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[14,128,1024,1024],f16>
    %int14_1162 = torch.constant.int 14
    %int32_1163 = torch.constant.int 32
    %int4_1164 = torch.constant.int 4
    %int1048576_1165 = torch.constant.int 1048576
    %939 = torch.prim.ListConstruct %int14_1162, %int32_1163, %int4_1164, %int1048576_1165 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %940 = torch.aten.view %938, %939 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,4,1048576],f16>
    %int6_1166 = torch.constant.int 6
    %941 = torch.prims.convert_element_type %940, %int6_1166 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %int2_1167 = torch.constant.int 2
    %int3_1168 = torch.constant.int 3
    %942 = torch.prim.ListConstruct %int2_1167, %int3_1168 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1169 = torch.constant.int 0
    %true_1170 = torch.constant.bool true
    %result0_1171, %result1_1172 = torch.aten.var_mean.correction %941, %942, %int0_1169, %true_1170 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1173 = torch.constant.float 9.9999999999999995E-7
    %int1_1174 = torch.constant.int 1
    %943 = torch.aten.add.Scalar %result0_1171, %float9.999990e-07_1173, %int1_1174 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %944 = torch.aten.rsqrt %943 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1175 = torch.constant.int 1
    %945 = torch.aten.sub.Tensor %940, %result1_1172, %int1_1175 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %946 = torch.aten.mul.Tensor %945, %944 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,4,1048576],f32>
    %int14_1176 = torch.constant.int 14
    %int128_1177 = torch.constant.int 128
    %int1024_1178 = torch.constant.int 1024
    %int1024_1179 = torch.constant.int 1024
    %947 = torch.prim.ListConstruct %int14_1176, %int128_1177, %int1024_1178, %int1024_1179 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %948 = torch.aten.view %946, %947 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.1.norm1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16>
    %949 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1180 = torch.constant.int 0
    %950 = torch.aten.unsqueeze %949, %int0_1180 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1181 = torch.constant.int 2
    %951 = torch.aten.unsqueeze %950, %int2_1181 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1182 = torch.constant.int 3
    %952 = torch.aten.unsqueeze %951, %int3_1182 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.1.norm1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16>
    %953 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1183 = torch.constant.int 0
    %954 = torch.aten.unsqueeze %953, %int0_1183 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1184 = torch.constant.int 2
    %955 = torch.aten.unsqueeze %954, %int2_1184 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1185 = torch.constant.int 3
    %956 = torch.aten.unsqueeze %955, %int3_1185 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %957 = torch.aten.mul.Tensor %948, %956 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[14,128,1024,1024],f32>
    %int1_1186 = torch.constant.int 1
    %958 = torch.aten.add.Tensor %957, %952, %int1_1186 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f32>
    %int5_1187 = torch.constant.int 5
    %959 = torch.prims.convert_element_type %958, %int5_1187 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %960 = torch.aten.silu %959 : !torch.vtensor<[14,128,1024,1024],f16> -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16>
    %961 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16>
    %962 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1188 = torch.constant.int 1
    %int1_1189 = torch.constant.int 1
    %963 = torch.prim.ListConstruct %int1_1188, %int1_1189 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1190 = torch.constant.int 1
    %int1_1191 = torch.constant.int 1
    %964 = torch.prim.ListConstruct %int1_1190, %int1_1191 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1192 = torch.constant.int 1
    %int1_1193 = torch.constant.int 1
    %965 = torch.prim.ListConstruct %int1_1192, %int1_1193 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1194 = torch.constant.bool false
    %int0_1195 = torch.constant.int 0
    %int0_1196 = torch.constant.int 0
    %966 = torch.prim.ListConstruct %int0_1195, %int0_1196 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1197 = torch.constant.int 1
    %967 = torch.aten.convolution %960, %961, %962, %963, %964, %965, %false_1194, %966, %int1_1197 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %int14_1198 = torch.constant.int 14
    %int32_1199 = torch.constant.int 32
    %int4_1200 = torch.constant.int 4
    %int1048576_1201 = torch.constant.int 1048576
    %968 = torch.prim.ListConstruct %int14_1198, %int32_1199, %int4_1200, %int1048576_1201 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %969 = torch.aten.view %967, %968 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,4,1048576],f16>
    %int6_1202 = torch.constant.int 6
    %970 = torch.prims.convert_element_type %969, %int6_1202 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %int2_1203 = torch.constant.int 2
    %int3_1204 = torch.constant.int 3
    %971 = torch.prim.ListConstruct %int2_1203, %int3_1204 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1205 = torch.constant.int 0
    %true_1206 = torch.constant.bool true
    %result0_1207, %result1_1208 = torch.aten.var_mean.correction %970, %971, %int0_1205, %true_1206 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1209 = torch.constant.float 9.9999999999999995E-7
    %int1_1210 = torch.constant.int 1
    %972 = torch.aten.add.Scalar %result0_1207, %float9.999990e-07_1209, %int1_1210 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %973 = torch.aten.rsqrt %972 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1211 = torch.constant.int 1
    %974 = torch.aten.sub.Tensor %969, %result1_1208, %int1_1211 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %975 = torch.aten.mul.Tensor %974, %973 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,4,1048576],f32>
    %int14_1212 = torch.constant.int 14
    %int128_1213 = torch.constant.int 128
    %int1024_1214 = torch.constant.int 1024
    %int1024_1215 = torch.constant.int 1024
    %976 = torch.prim.ListConstruct %int14_1212, %int128_1213, %int1024_1214, %int1024_1215 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %977 = torch.aten.view %975, %976 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.1.norm2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16>
    %978 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1216 = torch.constant.int 0
    %979 = torch.aten.unsqueeze %978, %int0_1216 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1217 = torch.constant.int 2
    %980 = torch.aten.unsqueeze %979, %int2_1217 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1218 = torch.constant.int 3
    %981 = torch.aten.unsqueeze %980, %int3_1218 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.1.norm2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16>
    %982 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1219 = torch.constant.int 0
    %983 = torch.aten.unsqueeze %982, %int0_1219 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1220 = torch.constant.int 2
    %984 = torch.aten.unsqueeze %983, %int2_1220 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1221 = torch.constant.int 3
    %985 = torch.aten.unsqueeze %984, %int3_1221 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %986 = torch.aten.mul.Tensor %977, %985 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[14,128,1024,1024],f32>
    %int1_1222 = torch.constant.int 1
    %987 = torch.aten.add.Tensor %986, %981, %int1_1222 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f32>
    %int5_1223 = torch.constant.int 5
    %988 = torch.prims.convert_element_type %987, %int5_1223 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %989 = torch.aten.silu %988 : !torch.vtensor<[14,128,1024,1024],f16> -> !torch.vtensor<[14,128,1024,1024],f16>
    %none_1224 = torch.constant.none
    %990 = torch.aten.clone %989, %none_1224 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16>
    %991 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.1.conv2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16>
    %992 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1225 = torch.constant.int 1
    %int1_1226 = torch.constant.int 1
    %993 = torch.prim.ListConstruct %int1_1225, %int1_1226 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1227 = torch.constant.int 1
    %int1_1228 = torch.constant.int 1
    %994 = torch.prim.ListConstruct %int1_1227, %int1_1228 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1229 = torch.constant.int 1
    %int1_1230 = torch.constant.int 1
    %995 = torch.prim.ListConstruct %int1_1229, %int1_1230 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1231 = torch.constant.bool false
    %int0_1232 = torch.constant.int 0
    %int0_1233 = torch.constant.int 0
    %996 = torch.prim.ListConstruct %int0_1232, %int0_1233 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1234 = torch.constant.int 1
    %997 = torch.aten.convolution %990, %991, %992, %993, %994, %995, %false_1231, %996, %int1_1234 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %int1_1235 = torch.constant.int 1
    %998 = torch.aten.add.Tensor %938, %997, %int1_1235 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[14,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %float1.000000e00_1236 = torch.constant.float 1.000000e+00
    %999 = torch.aten.div.Scalar %998, %float1.000000e00_1236 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[14,128,1024,1024],f16>
    %int14_1237 = torch.constant.int 14
    %int32_1238 = torch.constant.int 32
    %int4_1239 = torch.constant.int 4
    %int1048576_1240 = torch.constant.int 1048576
    %1000 = torch.prim.ListConstruct %int14_1237, %int32_1238, %int4_1239, %int1048576_1240 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1001 = torch.aten.view %999, %1000 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,4,1048576],f16>
    %int6_1241 = torch.constant.int 6
    %1002 = torch.prims.convert_element_type %1001, %int6_1241 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %int2_1242 = torch.constant.int 2
    %int3_1243 = torch.constant.int 3
    %1003 = torch.prim.ListConstruct %int2_1242, %int3_1243 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1244 = torch.constant.int 0
    %true_1245 = torch.constant.bool true
    %result0_1246, %result1_1247 = torch.aten.var_mean.correction %1002, %1003, %int0_1244, %true_1245 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1248 = torch.constant.float 9.9999999999999995E-7
    %int1_1249 = torch.constant.int 1
    %1004 = torch.aten.add.Scalar %result0_1246, %float9.999990e-07_1248, %int1_1249 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %1005 = torch.aten.rsqrt %1004 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1250 = torch.constant.int 1
    %1006 = torch.aten.sub.Tensor %1001, %result1_1247, %int1_1250 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %1007 = torch.aten.mul.Tensor %1006, %1005 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,4,1048576],f32>
    %int14_1251 = torch.constant.int 14
    %int128_1252 = torch.constant.int 128
    %int1024_1253 = torch.constant.int 1024
    %int1024_1254 = torch.constant.int 1024
    %1008 = torch.prim.ListConstruct %int14_1251, %int128_1252, %int1024_1253, %int1024_1254 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1009 = torch.aten.view %1007, %1008 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.2.norm1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16>
    %1010 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1255 = torch.constant.int 0
    %1011 = torch.aten.unsqueeze %1010, %int0_1255 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1256 = torch.constant.int 2
    %1012 = torch.aten.unsqueeze %1011, %int2_1256 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1257 = torch.constant.int 3
    %1013 = torch.aten.unsqueeze %1012, %int3_1257 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.2.norm1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16>
    %1014 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1258 = torch.constant.int 0
    %1015 = torch.aten.unsqueeze %1014, %int0_1258 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1259 = torch.constant.int 2
    %1016 = torch.aten.unsqueeze %1015, %int2_1259 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1260 = torch.constant.int 3
    %1017 = torch.aten.unsqueeze %1016, %int3_1260 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1018 = torch.aten.mul.Tensor %1009, %1017 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[14,128,1024,1024],f32>
    %int1_1261 = torch.constant.int 1
    %1019 = torch.aten.add.Tensor %1018, %1013, %int1_1261 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f32>
    %int5_1262 = torch.constant.int 5
    %1020 = torch.prims.convert_element_type %1019, %int5_1262 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %1021 = torch.aten.silu %1020 : !torch.vtensor<[14,128,1024,1024],f16> -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv1.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16>
    %1022 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv1.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16>
    %1023 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1263 = torch.constant.int 1
    %int1_1264 = torch.constant.int 1
    %1024 = torch.prim.ListConstruct %int1_1263, %int1_1264 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1265 = torch.constant.int 1
    %int1_1266 = torch.constant.int 1
    %1025 = torch.prim.ListConstruct %int1_1265, %int1_1266 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1267 = torch.constant.int 1
    %int1_1268 = torch.constant.int 1
    %1026 = torch.prim.ListConstruct %int1_1267, %int1_1268 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1269 = torch.constant.bool false
    %int0_1270 = torch.constant.int 0
    %int0_1271 = torch.constant.int 0
    %1027 = torch.prim.ListConstruct %int0_1270, %int0_1271 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1272 = torch.constant.int 1
    %1028 = torch.aten.convolution %1021, %1022, %1023, %1024, %1025, %1026, %false_1269, %1027, %int1_1272 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %int14_1273 = torch.constant.int 14
    %int32_1274 = torch.constant.int 32
    %int4_1275 = torch.constant.int 4
    %int1048576_1276 = torch.constant.int 1048576
    %1029 = torch.prim.ListConstruct %int14_1273, %int32_1274, %int4_1275, %int1048576_1276 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1030 = torch.aten.view %1028, %1029 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,4,1048576],f16>
    %int6_1277 = torch.constant.int 6
    %1031 = torch.prims.convert_element_type %1030, %int6_1277 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %int2_1278 = torch.constant.int 2
    %int3_1279 = torch.constant.int 3
    %1032 = torch.prim.ListConstruct %int2_1278, %int3_1279 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1280 = torch.constant.int 0
    %true_1281 = torch.constant.bool true
    %result0_1282, %result1_1283 = torch.aten.var_mean.correction %1031, %1032, %int0_1280, %true_1281 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1284 = torch.constant.float 9.9999999999999995E-7
    %int1_1285 = torch.constant.int 1
    %1033 = torch.aten.add.Scalar %result0_1282, %float9.999990e-07_1284, %int1_1285 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %1034 = torch.aten.rsqrt %1033 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1286 = torch.constant.int 1
    %1035 = torch.aten.sub.Tensor %1030, %result1_1283, %int1_1286 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %1036 = torch.aten.mul.Tensor %1035, %1034 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,4,1048576],f32>
    %int14_1287 = torch.constant.int 14
    %int128_1288 = torch.constant.int 128
    %int1024_1289 = torch.constant.int 1024
    %int1024_1290 = torch.constant.int 1024
    %1037 = torch.prim.ListConstruct %int14_1287, %int128_1288, %int1024_1289, %int1024_1290 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1038 = torch.aten.view %1036, %1037 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,128,1024,1024],f32>
    %__auto.decoder.up_blocks.3.resnets.2.norm2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16>
    %1039 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1291 = torch.constant.int 0
    %1040 = torch.aten.unsqueeze %1039, %int0_1291 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1292 = torch.constant.int 2
    %1041 = torch.aten.unsqueeze %1040, %int2_1292 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1293 = torch.constant.int 3
    %1042 = torch.aten.unsqueeze %1041, %int3_1293 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.up_blocks.3.resnets.2.norm2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16>
    %1043 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1294 = torch.constant.int 0
    %1044 = torch.aten.unsqueeze %1043, %int0_1294 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1295 = torch.constant.int 2
    %1045 = torch.aten.unsqueeze %1044, %int2_1295 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1296 = torch.constant.int 3
    %1046 = torch.aten.unsqueeze %1045, %int3_1296 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1047 = torch.aten.mul.Tensor %1038, %1046 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[14,128,1024,1024],f32>
    %int1_1297 = torch.constant.int 1
    %1048 = torch.aten.add.Tensor %1047, %1042, %int1_1297 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f32>
    %int5_1298 = torch.constant.int 5
    %1049 = torch.prims.convert_element_type %1048, %int5_1298 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %1050 = torch.aten.silu %1049 : !torch.vtensor<[14,128,1024,1024],f16> -> !torch.vtensor<[14,128,1024,1024],f16>
    %none_1299 = torch.constant.none
    %1051 = torch.aten.clone %1050, %none_1299 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv2.weight = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16>
    %1052 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.decoder.up_blocks.3.resnets.2.conv2.bias = util.global.load @__auto.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16>
    %1053 = torch_c.from_builtin_tensor %__auto.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1300 = torch.constant.int 1
    %int1_1301 = torch.constant.int 1
    %1054 = torch.prim.ListConstruct %int1_1300, %int1_1301 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1302 = torch.constant.int 1
    %int1_1303 = torch.constant.int 1
    %1055 = torch.prim.ListConstruct %int1_1302, %int1_1303 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1304 = torch.constant.int 1
    %int1_1305 = torch.constant.int 1
    %1056 = torch.prim.ListConstruct %int1_1304, %int1_1305 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1306 = torch.constant.bool false
    %int0_1307 = torch.constant.int 0
    %int0_1308 = torch.constant.int 0
    %1057 = torch.prim.ListConstruct %int0_1307, %int0_1308 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1309 = torch.constant.int 1
    %1058 = torch.aten.convolution %1051, %1052, %1053, %1054, %1055, %1056, %false_1306, %1057, %int1_1309 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %int1_1310 = torch.constant.int 1
    %1059 = torch.aten.add.Tensor %999, %1058, %int1_1310 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[14,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %float1.000000e00_1311 = torch.constant.float 1.000000e+00
    %1060 = torch.aten.div.Scalar %1059, %float1.000000e00_1311 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[14,128,1024,1024],f16>
    %int14_1312 = torch.constant.int 14
    %int32_1313 = torch.constant.int 32
    %int4_1314 = torch.constant.int 4
    %int1048576_1315 = torch.constant.int 1048576
    %1061 = torch.prim.ListConstruct %int14_1312, %int32_1313, %int4_1314, %int1048576_1315 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1062 = torch.aten.view %1060, %1061 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[14,32,4,1048576],f16>
    %int6_1316 = torch.constant.int 6
    %1063 = torch.prims.convert_element_type %1062, %int6_1316 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %int2_1317 = torch.constant.int 2
    %int3_1318 = torch.constant.int 3
    %1064 = torch.prim.ListConstruct %int2_1317, %int3_1318 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1319 = torch.constant.int 0
    %true_1320 = torch.constant.bool true
    %result0_1321, %result1_1322 = torch.aten.var_mean.correction %1063, %1064, %int0_1319, %true_1320 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[14,32,1,1],f32>, !torch.vtensor<[14,32,1,1],f32>
    %float9.999990e-07_1323 = torch.constant.float 9.9999999999999995E-7
    %int1_1324 = torch.constant.int 1
    %1065 = torch.aten.add.Scalar %result0_1321, %float9.999990e-07_1323, %int1_1324 : !torch.vtensor<[14,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[14,32,1,1],f32>
    %1066 = torch.aten.rsqrt %1065 : !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,1,1],f32>
    %int1_1325 = torch.constant.int 1
    %1067 = torch.aten.sub.Tensor %1062, %result1_1322, %int1_1325 : !torch.vtensor<[14,32,4,1048576],f16>, !torch.vtensor<[14,32,1,1],f32>, !torch.int -> !torch.vtensor<[14,32,4,1048576],f32>
    %1068 = torch.aten.mul.Tensor %1067, %1066 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.vtensor<[14,32,1,1],f32> -> !torch.vtensor<[14,32,4,1048576],f32>
    %int14_1326 = torch.constant.int 14
    %int128_1327 = torch.constant.int 128
    %int1024_1328 = torch.constant.int 1024
    %int1024_1329 = torch.constant.int 1024
    %1069 = torch.prim.ListConstruct %int14_1326, %int128_1327, %int1024_1328, %int1024_1329 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1070 = torch.aten.view %1068, %1069 : !torch.vtensor<[14,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[14,128,1024,1024],f32>
    %__auto.decoder.conv_norm_out.bias = util.global.load @__auto.decoder.conv_norm_out.bias : tensor<128xf16>
    %1071 = torch_c.from_builtin_tensor %__auto.decoder.conv_norm_out.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1330 = torch.constant.int 0
    %1072 = torch.aten.unsqueeze %1071, %int0_1330 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1331 = torch.constant.int 2
    %1073 = torch.aten.unsqueeze %1072, %int2_1331 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1332 = torch.constant.int 3
    %1074 = torch.aten.unsqueeze %1073, %int3_1332 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.decoder.conv_norm_out.weight = util.global.load @__auto.decoder.conv_norm_out.weight : tensor<128xf16>
    %1075 = torch_c.from_builtin_tensor %__auto.decoder.conv_norm_out.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1333 = torch.constant.int 0
    %1076 = torch.aten.unsqueeze %1075, %int0_1333 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1334 = torch.constant.int 2
    %1077 = torch.aten.unsqueeze %1076, %int2_1334 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1335 = torch.constant.int 3
    %1078 = torch.aten.unsqueeze %1077, %int3_1335 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1079 = torch.aten.mul.Tensor %1070, %1078 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[14,128,1024,1024],f32>
    %int1_1336 = torch.constant.int 1
    %1080 = torch.aten.add.Tensor %1079, %1074, %int1_1336 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f32>
    %int5_1337 = torch.constant.int 5
    %1081 = torch.prims.convert_element_type %1080, %int5_1337 : !torch.vtensor<[14,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[14,128,1024,1024],f16>
    %1082 = torch.aten.silu %1081 : !torch.vtensor<[14,128,1024,1024],f16> -> !torch.vtensor<[14,128,1024,1024],f16>
    %__auto.decoder.conv_out.weight = util.global.load @__auto.decoder.conv_out.weight : tensor<3x128x3x3xf16>
    %1083 = torch_c.from_builtin_tensor %__auto.decoder.conv_out.weight : tensor<3x128x3x3xf16> -> !torch.vtensor<[3,128,3,3],f16>
    %__auto.decoder.conv_out.bias = util.global.load @__auto.decoder.conv_out.bias : tensor<3xf16>
    %1084 = torch_c.from_builtin_tensor %__auto.decoder.conv_out.bias : tensor<3xf16> -> !torch.vtensor<[3],f16>
    %int1_1338 = torch.constant.int 1
    %int1_1339 = torch.constant.int 1
    %1085 = torch.prim.ListConstruct %int1_1338, %int1_1339 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1340 = torch.constant.int 1
    %int1_1341 = torch.constant.int 1
    %1086 = torch.prim.ListConstruct %int1_1340, %int1_1341 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1342 = torch.constant.int 1
    %int1_1343 = torch.constant.int 1
    %1087 = torch.prim.ListConstruct %int1_1342, %int1_1343 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1344 = torch.constant.bool false
    %int0_1345 = torch.constant.int 0
    %int0_1346 = torch.constant.int 0
    %1088 = torch.prim.ListConstruct %int0_1345, %int0_1346 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1347 = torch.constant.int 1
    %1089 = torch.aten.convolution %1082, %1083, %1084, %1085, %1086, %1087, %false_1344, %1088, %int1_1347 : !torch.vtensor<[14,128,1024,1024],f16>, !torch.vtensor<[3,128,3,3],f16>, !torch.vtensor<[3],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[14,3,1024,1024],f16>
    %int2_1348 = torch.constant.int 2
    %1090 = torch.aten.div.Scalar %1089, %int2_1348 : !torch.vtensor<[14,3,1024,1024],f16>, !torch.int -> !torch.vtensor<[14,3,1024,1024],f16>
    %float5.000000e-01_1349 = torch.constant.float 5.000000e-01
    %int1_1350 = torch.constant.int 1
    %1091 = torch.aten.add.Scalar %1090, %float5.000000e-01_1349, %int1_1350 : !torch.vtensor<[14,3,1024,1024],f16>, !torch.float, !torch.int -> !torch.vtensor<[14,3,1024,1024],f16>
    %int0_1351 = torch.constant.int 0
    %int1_1352 = torch.constant.int 1
    %1092 = torch.aten.clamp %1091, %int0_1351, %int1_1352 : !torch.vtensor<[14,3,1024,1024],f16>, !torch.int, !torch.int -> !torch.vtensor<[14,3,1024,1024],f16>
    return %1092 : !torch.vtensor<[14,3,1024,1024],f16>
  }
}
