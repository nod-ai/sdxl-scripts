module @compiled_vae {
  util.global private @__auto.vae.post_quant_conv.weight = #stream.parameter.named<"model"::"vae.post_quant_conv.weight"> : tensor<4x4x1x1xf16>
  util.global private @__auto.vae.post_quant_conv.bias = #stream.parameter.named<"model"::"vae.post_quant_conv.bias"> : tensor<4xf16>
  util.global private @__auto.vae.decoder.conv_in.weight = #stream.parameter.named<"model"::"vae.decoder.conv_in.weight"> : tensor<512x4x3x3xf16>
  util.global private @__auto.vae.decoder.conv_in.bias = #stream.parameter.named<"model"::"vae.decoder.conv_in.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.group_norm.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.group_norm.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.group_norm.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.group_norm.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_q.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_q.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_q.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_q.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_k.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_k.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_k.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_k.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_v.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_v.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_v.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_v.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_out.0.weight"> : tensor<512x512xf16>
  util.global private @__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.attentions.0.to_out.0.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.mid_block.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.mid_block.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.0.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.0.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.1.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv1.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.norm2.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv2.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.resnets.2.conv2.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.upsamplers.0.conv.weight"> : tensor<512x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.1.upsamplers.0.conv.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm1.bias"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm1.weight"> : tensor<512xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv1.weight"> : tensor<256x512x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight"> : tensor<256x512x1x1xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.1.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv1.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.norm2.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv2.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.resnets.2.conv2.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.upsamplers.0.conv.weight"> : tensor<256x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.2.upsamplers.0.conv.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm1.bias"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm1.weight"> : tensor<256xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv1.weight"> : tensor<128x256x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight"> : tensor<128x256x1x1xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.1.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm1.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv1.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv1.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.norm2.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv2.weight"> : tensor<128x128x3x3xf16>
  util.global private @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias = #stream.parameter.named<"model"::"vae.decoder.up_blocks.3.resnets.2.conv2.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.conv_norm_out.bias = #stream.parameter.named<"model"::"vae.decoder.conv_norm_out.bias"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.conv_norm_out.weight = #stream.parameter.named<"model"::"vae.decoder.conv_norm_out.weight"> : tensor<128xf16>
  util.global private @__auto.vae.decoder.conv_out.weight = #stream.parameter.named<"model"::"vae.decoder.conv_out.weight"> : tensor<3x128x3x3xf16>
  util.global private @__auto.vae.decoder.conv_out.bias = #stream.parameter.named<"model"::"vae.decoder.conv_out.bias"> : tensor<3xf16>
  func.func @decode(%arg0: !torch.vtensor<[1,4,128,128],f16>) -> !torch.vtensor<[1,3,1024,1024],f16> attributes {torch.assume_strict_symbolic_shapes} {
    %float7.677540e00 = torch.constant.float 7.6775431861804221
    %0 = torch.aten.mul.Scalar %arg0, %float7.677540e00 : !torch.vtensor<[1,4,128,128],f16>, !torch.float -> !torch.vtensor<[1,4,128,128],f16>
    %__auto.vae.post_quant_conv.weight = util.global.load @__auto.vae.post_quant_conv.weight : tensor<4x4x1x1xf16>
    %1 = torch_c.from_builtin_tensor %__auto.vae.post_quant_conv.weight : tensor<4x4x1x1xf16> -> !torch.vtensor<[4,4,1,1],f16>
    %__auto.vae.post_quant_conv.bias = util.global.load @__auto.vae.post_quant_conv.bias : tensor<4xf16>
    %2 = torch_c.from_builtin_tensor %__auto.vae.post_quant_conv.bias : tensor<4xf16> -> !torch.vtensor<[4],f16>
    %int1 = torch.constant.int 1
    %int1_0 = torch.constant.int 1
    %3 = torch.prim.ListConstruct %int1, %int1_0 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0 = torch.constant.int 0
    %int0_1 = torch.constant.int 0
    %4 = torch.prim.ListConstruct %int0, %int0_1 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_2 = torch.constant.int 1
    %int1_3 = torch.constant.int 1
    %5 = torch.prim.ListConstruct %int1_2, %int1_3 : (!torch.int, !torch.int) -> !torch.list<int>
    %false = torch.constant.bool false
    %int0_4 = torch.constant.int 0
    %int0_5 = torch.constant.int 0
    %6 = torch.prim.ListConstruct %int0_4, %int0_5 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_6 = torch.constant.int 1
    %7 = torch.aten.convolution %0, %1, %2, %3, %4, %5, %false, %6, %int1_6 : !torch.vtensor<[1,4,128,128],f16>, !torch.vtensor<[4,4,1,1],f16>, !torch.vtensor<[4],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,4,128,128],f16>
    %__auto.vae.decoder.conv_in.weight = util.global.load @__auto.vae.decoder.conv_in.weight : tensor<512x4x3x3xf16>
    %8 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_in.weight : tensor<512x4x3x3xf16> -> !torch.vtensor<[512,4,3,3],f16>
    %__auto.vae.decoder.conv_in.bias = util.global.load @__auto.vae.decoder.conv_in.bias : tensor<512xf16>
    %9 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_in.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_7 = torch.constant.int 1
    %int1_8 = torch.constant.int 1
    %10 = torch.prim.ListConstruct %int1_7, %int1_8 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_9 = torch.constant.int 1
    %int1_10 = torch.constant.int 1
    %11 = torch.prim.ListConstruct %int1_9, %int1_10 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_11 = torch.constant.int 1
    %int1_12 = torch.constant.int 1
    %12 = torch.prim.ListConstruct %int1_11, %int1_12 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_13 = torch.constant.bool false
    %int0_14 = torch.constant.int 0
    %int0_15 = torch.constant.int 0
    %13 = torch.prim.ListConstruct %int0_14, %int0_15 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_16 = torch.constant.int 1
    %14 = torch.aten.convolution %7, %8, %9, %10, %11, %12, %false_13, %13, %int1_16 : !torch.vtensor<[1,4,128,128],f16>, !torch.vtensor<[512,4,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_17 = torch.constant.int 1
    %int32 = torch.constant.int 32
    %int16 = torch.constant.int 16
    %int16384 = torch.constant.int 16384
    %15 = torch.prim.ListConstruct %int1_17, %int32, %int16, %int16384 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %16 = torch.aten.view %14, %15 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6 = torch.constant.int 6
    %17 = torch.prims.convert_element_type %16, %int6 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2 = torch.constant.int 2
    %int3 = torch.constant.int 3
    %18 = torch.prim.ListConstruct %int2, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_18 = torch.constant.int 0
    %true = torch.constant.bool true
    %result0, %result1 = torch.aten.var_mean.correction %17, %18, %int0_18, %true : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07 = torch.constant.float 9.9999999999999995E-7
    %int1_19 = torch.constant.int 1
    %19 = torch.aten.add.Scalar %result0, %float9.999990e-07, %int1_19 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %20 = torch.aten.rsqrt %19 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_20 = torch.constant.int 1
    %21 = torch.aten.sub.Tensor %16, %result1, %int1_20 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %22 = torch.aten.mul.Tensor %21, %20 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_21 = torch.constant.int 1
    %int512 = torch.constant.int 512
    %int128 = torch.constant.int 128
    %int128_22 = torch.constant.int 128
    %23 = torch.prim.ListConstruct %int1_21, %int512, %int128, %int128_22 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %24 = torch.aten.view %22, %23 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16>
    %25 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_23 = torch.constant.int 0
    %26 = torch.aten.unsqueeze %25, %int0_23 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_24 = torch.constant.int 2
    %27 = torch.aten.unsqueeze %26, %int2_24 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_25 = torch.constant.int 3
    %28 = torch.aten.unsqueeze %27, %int3_25 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16>
    %29 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_26 = torch.constant.int 0
    %30 = torch.aten.unsqueeze %29, %int0_26 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_27 = torch.constant.int 2
    %31 = torch.aten.unsqueeze %30, %int2_27 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_28 = torch.constant.int 3
    %32 = torch.aten.unsqueeze %31, %int3_28 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %33 = torch.aten.mul.Tensor %24, %32 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_29 = torch.constant.int 1
    %34 = torch.aten.add.Tensor %33, %28, %int1_29 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5 = torch.constant.int 5
    %35 = torch.prims.convert_element_type %34, %int5 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %36 = torch.aten.silu %35 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %37 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16>
    %38 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_30 = torch.constant.int 1
    %int1_31 = torch.constant.int 1
    %39 = torch.prim.ListConstruct %int1_30, %int1_31 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_32 = torch.constant.int 1
    %int1_33 = torch.constant.int 1
    %40 = torch.prim.ListConstruct %int1_32, %int1_33 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_34 = torch.constant.int 1
    %int1_35 = torch.constant.int 1
    %41 = torch.prim.ListConstruct %int1_34, %int1_35 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_36 = torch.constant.bool false
    %int0_37 = torch.constant.int 0
    %int0_38 = torch.constant.int 0
    %42 = torch.prim.ListConstruct %int0_37, %int0_38 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_39 = torch.constant.int 1
    %43 = torch.aten.convolution %36, %37, %38, %39, %40, %41, %false_36, %42, %int1_39 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_40 = torch.constant.int 1
    %int32_41 = torch.constant.int 32
    %int16_42 = torch.constant.int 16
    %int16384_43 = torch.constant.int 16384
    %44 = torch.prim.ListConstruct %int1_40, %int32_41, %int16_42, %int16384_43 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %45 = torch.aten.view %43, %44 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_44 = torch.constant.int 6
    %46 = torch.prims.convert_element_type %45, %int6_44 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_45 = torch.constant.int 2
    %int3_46 = torch.constant.int 3
    %47 = torch.prim.ListConstruct %int2_45, %int3_46 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_47 = torch.constant.int 0
    %true_48 = torch.constant.bool true
    %result0_49, %result1_50 = torch.aten.var_mean.correction %46, %47, %int0_47, %true_48 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_51 = torch.constant.float 9.9999999999999995E-7
    %int1_52 = torch.constant.int 1
    %48 = torch.aten.add.Scalar %result0_49, %float9.999990e-07_51, %int1_52 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %49 = torch.aten.rsqrt %48 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_53 = torch.constant.int 1
    %50 = torch.aten.sub.Tensor %45, %result1_50, %int1_53 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %51 = torch.aten.mul.Tensor %50, %49 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_54 = torch.constant.int 1
    %int512_55 = torch.constant.int 512
    %int128_56 = torch.constant.int 128
    %int128_57 = torch.constant.int 128
    %52 = torch.prim.ListConstruct %int1_54, %int512_55, %int128_56, %int128_57 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %53 = torch.aten.view %51, %52 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16>
    %54 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_58 = torch.constant.int 0
    %55 = torch.aten.unsqueeze %54, %int0_58 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_59 = torch.constant.int 2
    %56 = torch.aten.unsqueeze %55, %int2_59 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_60 = torch.constant.int 3
    %57 = torch.aten.unsqueeze %56, %int3_60 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16>
    %58 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_61 = torch.constant.int 0
    %59 = torch.aten.unsqueeze %58, %int0_61 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_62 = torch.constant.int 2
    %60 = torch.aten.unsqueeze %59, %int2_62 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_63 = torch.constant.int 3
    %61 = torch.aten.unsqueeze %60, %int3_63 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %62 = torch.aten.mul.Tensor %53, %61 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_64 = torch.constant.int 1
    %63 = torch.aten.add.Tensor %62, %57, %int1_64 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_65 = torch.constant.int 5
    %64 = torch.prims.convert_element_type %63, %int5_65 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %65 = torch.aten.silu %64 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none = torch.constant.none
    %66 = torch.aten.clone %65, %none : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %67 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16>
    %68 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_66 = torch.constant.int 1
    %int1_67 = torch.constant.int 1
    %69 = torch.prim.ListConstruct %int1_66, %int1_67 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_68 = torch.constant.int 1
    %int1_69 = torch.constant.int 1
    %70 = torch.prim.ListConstruct %int1_68, %int1_69 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_70 = torch.constant.int 1
    %int1_71 = torch.constant.int 1
    %71 = torch.prim.ListConstruct %int1_70, %int1_71 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_72 = torch.constant.bool false
    %int0_73 = torch.constant.int 0
    %int0_74 = torch.constant.int 0
    %72 = torch.prim.ListConstruct %int0_73, %int0_74 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_75 = torch.constant.int 1
    %73 = torch.aten.convolution %66, %67, %68, %69, %70, %71, %false_72, %72, %int1_75 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_76 = torch.constant.int 1
    %74 = torch.aten.add.Tensor %14, %73, %int1_76 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_77 = torch.constant.int 1
    %75 = torch.aten.div.Scalar %74, %int1_77 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_78 = torch.constant.int 1
    %int512_79 = torch.constant.int 512
    %int16384_80 = torch.constant.int 16384
    %76 = torch.prim.ListConstruct %int1_78, %int512_79, %int16384_80 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %77 = torch.aten.view %75, %76 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f16>
    %int1_81 = torch.constant.int 1
    %int2_82 = torch.constant.int 2
    %78 = torch.aten.transpose.int %77, %int1_81, %int2_82 : !torch.vtensor<[1,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int1_83 = torch.constant.int 1
    %int2_84 = torch.constant.int 2
    %79 = torch.aten.transpose.int %78, %int1_83, %int2_84 : !torch.vtensor<[1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_85 = torch.constant.int 1
    %int32_86 = torch.constant.int 32
    %int16_87 = torch.constant.int 16
    %int16384_88 = torch.constant.int 16384
    %80 = torch.prim.ListConstruct %int1_85, %int32_86, %int16_87, %int16384_88 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %81 = torch.aten.view %79, %80 : !torch.vtensor<[1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_89 = torch.constant.int 6
    %82 = torch.prims.convert_element_type %81, %int6_89 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_90 = torch.constant.int 2
    %int3_91 = torch.constant.int 3
    %83 = torch.prim.ListConstruct %int2_90, %int3_91 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_92 = torch.constant.int 0
    %true_93 = torch.constant.bool true
    %result0_94, %result1_95 = torch.aten.var_mean.correction %82, %83, %int0_92, %true_93 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_96 = torch.constant.float 9.9999999999999995E-7
    %int1_97 = torch.constant.int 1
    %84 = torch.aten.add.Scalar %result0_94, %float9.999990e-07_96, %int1_97 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %85 = torch.aten.rsqrt %84 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_98 = torch.constant.int 1
    %86 = torch.aten.sub.Tensor %81, %result1_95, %int1_98 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %87 = torch.aten.mul.Tensor %86, %85 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_99 = torch.constant.int 1
    %int512_100 = torch.constant.int 512
    %int16384_101 = torch.constant.int 16384
    %88 = torch.prim.ListConstruct %int1_99, %int512_100, %int16384_101 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %89 = torch.aten.view %87, %88 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f32>
    %__auto.vae.decoder.mid_block.attentions.0.group_norm.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16>
    %90 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.group_norm.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_102 = torch.constant.int 0
    %91 = torch.aten.unsqueeze %90, %int0_102 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_103 = torch.constant.int 2
    %92 = torch.aten.unsqueeze %91, %int2_103 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %__auto.vae.decoder.mid_block.attentions.0.group_norm.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16>
    %93 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.group_norm.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_104 = torch.constant.int 0
    %94 = torch.aten.unsqueeze %93, %int0_104 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_105 = torch.constant.int 2
    %95 = torch.aten.unsqueeze %94, %int2_105 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %96 = torch.aten.mul.Tensor %89, %95 : !torch.vtensor<[1,512,16384],f32>, !torch.vtensor<[1,512,1],f16> -> !torch.vtensor<[1,512,16384],f32>
    %int1_106 = torch.constant.int 1
    %97 = torch.aten.add.Tensor %96, %92, %int1_106 : !torch.vtensor<[1,512,16384],f32>, !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,16384],f32>
    %int5_107 = torch.constant.int 5
    %98 = torch.prims.convert_element_type %97, %int5_107 : !torch.vtensor<[1,512,16384],f32>, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_108 = torch.constant.int 1
    %int2_109 = torch.constant.int 2
    %99 = torch.aten.transpose.int %98, %int1_108, %int2_109 : !torch.vtensor<[1,512,16384],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_q.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16>
    %100 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_q.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_110 = torch.constant.int 0
    %int1_111 = torch.constant.int 1
    %101 = torch.aten.transpose.int %100, %int0_110, %int1_111 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_112 = torch.constant.int 16384
    %int512_113 = torch.constant.int 512
    %102 = torch.prim.ListConstruct %int16384_112, %int512_113 : (!torch.int, !torch.int) -> !torch.list<int>
    %103 = torch.aten.view %99, %102 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %104 = torch.aten.mm %103, %101 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_114 = torch.constant.int 1
    %int16384_115 = torch.constant.int 16384
    %int512_116 = torch.constant.int 512
    %105 = torch.prim.ListConstruct %int1_114, %int16384_115, %int512_116 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %106 = torch.aten.view %104, %105 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_q.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16>
    %107 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_q.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_117 = torch.constant.int 1
    %108 = torch.aten.add.Tensor %106, %107, %int1_117 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_k.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16>
    %109 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_k.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_118 = torch.constant.int 0
    %int1_119 = torch.constant.int 1
    %110 = torch.aten.transpose.int %109, %int0_118, %int1_119 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_120 = torch.constant.int 16384
    %int512_121 = torch.constant.int 512
    %111 = torch.prim.ListConstruct %int16384_120, %int512_121 : (!torch.int, !torch.int) -> !torch.list<int>
    %112 = torch.aten.view %99, %111 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %113 = torch.aten.mm %112, %110 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_122 = torch.constant.int 1
    %int16384_123 = torch.constant.int 16384
    %int512_124 = torch.constant.int 512
    %114 = torch.prim.ListConstruct %int1_122, %int16384_123, %int512_124 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %115 = torch.aten.view %113, %114 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_k.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16>
    %116 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_k.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_125 = torch.constant.int 1
    %117 = torch.aten.add.Tensor %115, %116, %int1_125 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_v.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16>
    %118 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_v.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_126 = torch.constant.int 0
    %int1_127 = torch.constant.int 1
    %119 = torch.aten.transpose.int %118, %int0_126, %int1_127 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %int16384_128 = torch.constant.int 16384
    %int512_129 = torch.constant.int 512
    %120 = torch.prim.ListConstruct %int16384_128, %int512_129 : (!torch.int, !torch.int) -> !torch.list<int>
    %121 = torch.aten.view %99, %120 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %122 = torch.aten.mm %121, %119 : !torch.vtensor<[16384,512],f16>, !torch.vtensor<[512,512],f16> -> !torch.vtensor<[16384,512],f16>
    %int1_130 = torch.constant.int 1
    %int16384_131 = torch.constant.int 16384
    %int512_132 = torch.constant.int 512
    %123 = torch.prim.ListConstruct %int1_130, %int16384_131, %int512_132 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %124 = torch.aten.view %122, %123 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_v.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16>
    %125 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_v.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_133 = torch.constant.int 1
    %126 = torch.aten.add.Tensor %124, %125, %int1_133 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int1_134 = torch.constant.int 1
    %int-1 = torch.constant.int -1
    %int1_135 = torch.constant.int 1
    %int512_136 = torch.constant.int 512
    %127 = torch.prim.ListConstruct %int1_134, %int-1, %int1_135, %int512_136 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %128 = torch.aten.view %108, %127 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_137 = torch.constant.int 1
    %int2_138 = torch.constant.int 2
    %129 = torch.aten.transpose.int %128, %int1_137, %int2_138 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_139 = torch.constant.int 1
    %int-1_140 = torch.constant.int -1
    %int1_141 = torch.constant.int 1
    %int512_142 = torch.constant.int 512
    %130 = torch.prim.ListConstruct %int1_139, %int-1_140, %int1_141, %int512_142 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %131 = torch.aten.view %117, %130 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_143 = torch.constant.int 1
    %int2_144 = torch.constant.int 2
    %132 = torch.aten.transpose.int %131, %int1_143, %int2_144 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_145 = torch.constant.int 1
    %int-1_146 = torch.constant.int -1
    %int1_147 = torch.constant.int 1
    %int512_148 = torch.constant.int 512
    %133 = torch.prim.ListConstruct %int1_145, %int-1_146, %int1_147, %int512_148 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %134 = torch.aten.view %126, %133 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_149 = torch.constant.int 1
    %int2_150 = torch.constant.int 2
    %135 = torch.aten.transpose.int %134, %int1_149, %int2_150 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %float2.102240e-01 = torch.constant.float 0.21022410381342863
    %136 = torch.aten.mul.Scalar %129, %float2.102240e-01 : !torch.vtensor<[1,1,16384,512],f16>, !torch.float -> !torch.vtensor<[1,1,16384,512],f16>
    %int-2 = torch.constant.int -2
    %int-1_151 = torch.constant.int -1
    %137 = torch.aten.transpose.int %132, %int-2, %int-1_151 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,512,16384],f16>
    %float2.102240e-01_152 = torch.constant.float 0.21022410381342863
    %138 = torch.aten.mul.Scalar %137, %float2.102240e-01_152 : !torch.vtensor<[1,1,512,16384],f16>, !torch.float -> !torch.vtensor<[1,1,512,16384],f16>
    %int1_153 = torch.constant.int 1
    %int1_154 = torch.constant.int 1
    %int16384_155 = torch.constant.int 16384
    %int512_156 = torch.constant.int 512
    %139 = torch.prim.ListConstruct %int1_153, %int1_154, %int16384_155, %int512_156 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_157 = torch.constant.bool false
    %140 = torch.aten.expand %136, %139, %false_157 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_158 = torch.constant.int 1
    %int16384_159 = torch.constant.int 16384
    %int512_160 = torch.constant.int 512
    %141 = torch.prim.ListConstruct %int1_158, %int16384_159, %int512_160 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %142 = torch.aten.view %140, %141 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %int1_161 = torch.constant.int 1
    %int1_162 = torch.constant.int 1
    %int512_163 = torch.constant.int 512
    %int16384_164 = torch.constant.int 16384
    %143 = torch.prim.ListConstruct %int1_161, %int1_162, %int512_163, %int16384_164 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_165 = torch.constant.bool false
    %144 = torch.aten.expand %138, %143, %false_165 : !torch.vtensor<[1,1,512,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,512,16384],f16>
    %int1_166 = torch.constant.int 1
    %int512_167 = torch.constant.int 512
    %int16384_168 = torch.constant.int 16384
    %145 = torch.prim.ListConstruct %int1_166, %int512_167, %int16384_168 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %146 = torch.aten.view %144, %145 : !torch.vtensor<[1,1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,512,16384],f16>
    %147 = torch.aten.bmm %142, %146 : !torch.vtensor<[1,16384,512],f16>, !torch.vtensor<[1,512,16384],f16> -> !torch.vtensor<[1,16384,16384],f16>
    %int1_169 = torch.constant.int 1
    %int1_170 = torch.constant.int 1
    %int16384_171 = torch.constant.int 16384
    %int16384_172 = torch.constant.int 16384
    %148 = torch.prim.ListConstruct %int1_169, %int1_170, %int16384_171, %int16384_172 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %149 = torch.aten.view %147, %148 : !torch.vtensor<[1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,1,16384,16384],f16>
    %int-1_173 = torch.constant.int -1
    %false_174 = torch.constant.bool false
    %150 = torch.aten._softmax %149, %int-1_173, %false_174 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.int, !torch.bool -> !torch.vtensor<[1,1,16384,16384],f16>
    %int1_175 = torch.constant.int 1
    %int1_176 = torch.constant.int 1
    %int16384_177 = torch.constant.int 16384
    %int16384_178 = torch.constant.int 16384
    %151 = torch.prim.ListConstruct %int1_175, %int1_176, %int16384_177, %int16384_178 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_179 = torch.constant.bool false
    %152 = torch.aten.expand %150, %151, %false_179 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,16384],f16>
    %int1_180 = torch.constant.int 1
    %int16384_181 = torch.constant.int 16384
    %int16384_182 = torch.constant.int 16384
    %153 = torch.prim.ListConstruct %int1_180, %int16384_181, %int16384_182 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %154 = torch.aten.view %152, %153 : !torch.vtensor<[1,1,16384,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,16384],f16>
    %int1_183 = torch.constant.int 1
    %int1_184 = torch.constant.int 1
    %int16384_185 = torch.constant.int 16384
    %int512_186 = torch.constant.int 512
    %155 = torch.prim.ListConstruct %int1_183, %int1_184, %int16384_185, %int512_186 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %false_187 = torch.constant.bool false
    %156 = torch.aten.expand %135, %155, %false_187 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_188 = torch.constant.int 1
    %int16384_189 = torch.constant.int 16384
    %int512_190 = torch.constant.int 512
    %157 = torch.prim.ListConstruct %int1_188, %int16384_189, %int512_190 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %158 = torch.aten.view %156, %157 : !torch.vtensor<[1,1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %159 = torch.aten.bmm %154, %158 : !torch.vtensor<[1,16384,16384],f16>, !torch.vtensor<[1,16384,512],f16> -> !torch.vtensor<[1,16384,512],f16>
    %int1_191 = torch.constant.int 1
    %int1_192 = torch.constant.int 1
    %int16384_193 = torch.constant.int 16384
    %int512_194 = torch.constant.int 512
    %160 = torch.prim.ListConstruct %int1_191, %int1_192, %int16384_193, %int512_194 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %161 = torch.aten.view %159, %160 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_195 = torch.constant.int 1
    %int2_196 = torch.constant.int 2
    %162 = torch.aten.transpose.int %161, %int1_195, %int2_196 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_197 = torch.constant.int 1
    %int2_198 = torch.constant.int 2
    %163 = torch.aten.transpose.int %162, %int1_197, %int2_198 : !torch.vtensor<[1,16384,1,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,1,16384,512],f16>
    %int1_199 = torch.constant.int 1
    %int2_200 = torch.constant.int 2
    %164 = torch.aten.transpose.int %163, %int1_199, %int2_200 : !torch.vtensor<[1,1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,16384,1,512],f16>
    %int1_201 = torch.constant.int 1
    %int-1_202 = torch.constant.int -1
    %int512_203 = torch.constant.int 512
    %165 = torch.prim.ListConstruct %int1_201, %int-1_202, %int512_203 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %166 = torch.aten.view %164, %165 : !torch.vtensor<[1,16384,1,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %int5_204 = torch.constant.int 5
    %167 = torch.prims.convert_element_type %166, %int5_204 : !torch.vtensor<[1,16384,512],f16>, !torch.int -> !torch.vtensor<[1,16384,512],f16>
    %int16384_205 = torch.constant.int 16384
    %int512_206 = torch.constant.int 512
    %168 = torch.prim.ListConstruct %int16384_205, %int512_206 : (!torch.int, !torch.int) -> !torch.list<int>
    %169 = torch.aten.view %167, %168 : !torch.vtensor<[1,16384,512],f16>, !torch.list<int> -> !torch.vtensor<[16384,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16>
    %170 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_out.0.weight : tensor<512x512xf16> -> !torch.vtensor<[512,512],f16>
    %int0_207 = torch.constant.int 0
    %int1_208 = torch.constant.int 1
    %171 = torch.aten.transpose.int %170, %int0_207, %int1_208 : !torch.vtensor<[512,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[512,512],f16>
    %__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias = util.global.load @__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16>
    %172 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.attentions.0.to_out.0.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int6_209 = torch.constant.int 6
    %173 = torch.prims.convert_element_type %172, %int6_209 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[512],f32>
    %int6_210 = torch.constant.int 6
    %174 = torch.prims.convert_element_type %169, %int6_210 : !torch.vtensor<[16384,512],f16>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int6_211 = torch.constant.int 6
    %175 = torch.prims.convert_element_type %171, %int6_211 : !torch.vtensor<[512,512],f16>, !torch.int -> !torch.vtensor<[512,512],f32>
    %176 = torch.aten.mm %174, %175 : !torch.vtensor<[16384,512],f32>, !torch.vtensor<[512,512],f32> -> !torch.vtensor<[16384,512],f32>
    %int1_212 = torch.constant.int 1
    %177 = torch.aten.mul.Scalar %176, %int1_212 : !torch.vtensor<[16384,512],f32>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int1_213 = torch.constant.int 1
    %178 = torch.aten.mul.Scalar %173, %int1_213 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],f32>
    %int1_214 = torch.constant.int 1
    %179 = torch.aten.add.Tensor %177, %178, %int1_214 : !torch.vtensor<[16384,512],f32>, !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[16384,512],f32>
    %int5_215 = torch.constant.int 5
    %180 = torch.prims.convert_element_type %179, %int5_215 : !torch.vtensor<[16384,512],f32>, !torch.int -> !torch.vtensor<[16384,512],f16>
    %int1_216 = torch.constant.int 1
    %int16384_217 = torch.constant.int 16384
    %int512_218 = torch.constant.int 512
    %181 = torch.prim.ListConstruct %int1_216, %int16384_217, %int512_218 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %182 = torch.aten.view %180, %181 : !torch.vtensor<[16384,512],f16>, !torch.list<int> -> !torch.vtensor<[1,16384,512],f16>
    %none_219 = torch.constant.none
    %183 = torch.aten.clone %182, %none_219 : !torch.vtensor<[1,16384,512],f16>, !torch.none -> !torch.vtensor<[1,16384,512],f16>
    %int-1_220 = torch.constant.int -1
    %int-2_221 = torch.constant.int -2
    %184 = torch.aten.transpose.int %183, %int-1_220, %int-2_221 : !torch.vtensor<[1,16384,512],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,512,16384],f16>
    %int1_222 = torch.constant.int 1
    %int512_223 = torch.constant.int 512
    %int128_224 = torch.constant.int 128
    %int128_225 = torch.constant.int 128
    %185 = torch.prim.ListConstruct %int1_222, %int512_223, %int128_224, %int128_225 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %186 = torch.aten.view %184, %185 : !torch.vtensor<[1,512,16384],f16>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f16>
    %int1_226 = torch.constant.int 1
    %187 = torch.aten.add.Tensor %186, %75, %int1_226 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_227 = torch.constant.int 1
    %188 = torch.aten.div.Scalar %187, %int1_227 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_228 = torch.constant.int 1
    %int32_229 = torch.constant.int 32
    %int16_230 = torch.constant.int 16
    %int16384_231 = torch.constant.int 16384
    %189 = torch.prim.ListConstruct %int1_228, %int32_229, %int16_230, %int16384_231 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %190 = torch.aten.view %188, %189 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_232 = torch.constant.int 6
    %191 = torch.prims.convert_element_type %190, %int6_232 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_233 = torch.constant.int 2
    %int3_234 = torch.constant.int 3
    %192 = torch.prim.ListConstruct %int2_233, %int3_234 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_235 = torch.constant.int 0
    %true_236 = torch.constant.bool true
    %result0_237, %result1_238 = torch.aten.var_mean.correction %191, %192, %int0_235, %true_236 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_239 = torch.constant.float 9.9999999999999995E-7
    %int1_240 = torch.constant.int 1
    %193 = torch.aten.add.Scalar %result0_237, %float9.999990e-07_239, %int1_240 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %194 = torch.aten.rsqrt %193 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_241 = torch.constant.int 1
    %195 = torch.aten.sub.Tensor %190, %result1_238, %int1_241 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %196 = torch.aten.mul.Tensor %195, %194 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_242 = torch.constant.int 1
    %int512_243 = torch.constant.int 512
    %int128_244 = torch.constant.int 128
    %int128_245 = torch.constant.int 128
    %197 = torch.prim.ListConstruct %int1_242, %int512_243, %int128_244, %int128_245 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %198 = torch.aten.view %196, %197 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16>
    %199 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_246 = torch.constant.int 0
    %200 = torch.aten.unsqueeze %199, %int0_246 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_247 = torch.constant.int 2
    %201 = torch.aten.unsqueeze %200, %int2_247 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_248 = torch.constant.int 3
    %202 = torch.aten.unsqueeze %201, %int3_248 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16>
    %203 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_249 = torch.constant.int 0
    %204 = torch.aten.unsqueeze %203, %int0_249 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_250 = torch.constant.int 2
    %205 = torch.aten.unsqueeze %204, %int2_250 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_251 = torch.constant.int 3
    %206 = torch.aten.unsqueeze %205, %int3_251 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %207 = torch.aten.mul.Tensor %198, %206 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_252 = torch.constant.int 1
    %208 = torch.aten.add.Tensor %207, %202, %int1_252 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_253 = torch.constant.int 5
    %209 = torch.prims.convert_element_type %208, %int5_253 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %210 = torch.aten.silu %209 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %211 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16>
    %212 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_254 = torch.constant.int 1
    %int1_255 = torch.constant.int 1
    %213 = torch.prim.ListConstruct %int1_254, %int1_255 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_256 = torch.constant.int 1
    %int1_257 = torch.constant.int 1
    %214 = torch.prim.ListConstruct %int1_256, %int1_257 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_258 = torch.constant.int 1
    %int1_259 = torch.constant.int 1
    %215 = torch.prim.ListConstruct %int1_258, %int1_259 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_260 = torch.constant.bool false
    %int0_261 = torch.constant.int 0
    %int0_262 = torch.constant.int 0
    %216 = torch.prim.ListConstruct %int0_261, %int0_262 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_263 = torch.constant.int 1
    %217 = torch.aten.convolution %210, %211, %212, %213, %214, %215, %false_260, %216, %int1_263 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_264 = torch.constant.int 1
    %int32_265 = torch.constant.int 32
    %int16_266 = torch.constant.int 16
    %int16384_267 = torch.constant.int 16384
    %218 = torch.prim.ListConstruct %int1_264, %int32_265, %int16_266, %int16384_267 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %219 = torch.aten.view %217, %218 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_268 = torch.constant.int 6
    %220 = torch.prims.convert_element_type %219, %int6_268 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_269 = torch.constant.int 2
    %int3_270 = torch.constant.int 3
    %221 = torch.prim.ListConstruct %int2_269, %int3_270 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_271 = torch.constant.int 0
    %true_272 = torch.constant.bool true
    %result0_273, %result1_274 = torch.aten.var_mean.correction %220, %221, %int0_271, %true_272 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_275 = torch.constant.float 9.9999999999999995E-7
    %int1_276 = torch.constant.int 1
    %222 = torch.aten.add.Scalar %result0_273, %float9.999990e-07_275, %int1_276 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %223 = torch.aten.rsqrt %222 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_277 = torch.constant.int 1
    %224 = torch.aten.sub.Tensor %219, %result1_274, %int1_277 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %225 = torch.aten.mul.Tensor %224, %223 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_278 = torch.constant.int 1
    %int512_279 = torch.constant.int 512
    %int128_280 = torch.constant.int 128
    %int128_281 = torch.constant.int 128
    %226 = torch.prim.ListConstruct %int1_278, %int512_279, %int128_280, %int128_281 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %227 = torch.aten.view %225, %226 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.mid_block.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16>
    %228 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_282 = torch.constant.int 0
    %229 = torch.aten.unsqueeze %228, %int0_282 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_283 = torch.constant.int 2
    %230 = torch.aten.unsqueeze %229, %int2_283 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_284 = torch.constant.int 3
    %231 = torch.aten.unsqueeze %230, %int3_284 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.mid_block.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16>
    %232 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_285 = torch.constant.int 0
    %233 = torch.aten.unsqueeze %232, %int0_285 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_286 = torch.constant.int 2
    %234 = torch.aten.unsqueeze %233, %int2_286 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_287 = torch.constant.int 3
    %235 = torch.aten.unsqueeze %234, %int3_287 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %236 = torch.aten.mul.Tensor %227, %235 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_288 = torch.constant.int 1
    %237 = torch.aten.add.Tensor %236, %231, %int1_288 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_289 = torch.constant.int 5
    %238 = torch.prims.convert_element_type %237, %int5_289 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %239 = torch.aten.silu %238 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_290 = torch.constant.none
    %240 = torch.aten.clone %239, %none_290 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %241 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.mid_block.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16>
    %242 = torch_c.from_builtin_tensor %__auto.vae.decoder.mid_block.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_291 = torch.constant.int 1
    %int1_292 = torch.constant.int 1
    %243 = torch.prim.ListConstruct %int1_291, %int1_292 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_293 = torch.constant.int 1
    %int1_294 = torch.constant.int 1
    %244 = torch.prim.ListConstruct %int1_293, %int1_294 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_295 = torch.constant.int 1
    %int1_296 = torch.constant.int 1
    %245 = torch.prim.ListConstruct %int1_295, %int1_296 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_297 = torch.constant.bool false
    %int0_298 = torch.constant.int 0
    %int0_299 = torch.constant.int 0
    %246 = torch.prim.ListConstruct %int0_298, %int0_299 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_300 = torch.constant.int 1
    %247 = torch.aten.convolution %240, %241, %242, %243, %244, %245, %false_297, %246, %int1_300 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_301 = torch.constant.int 1
    %248 = torch.aten.add.Tensor %188, %247, %int1_301 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_302 = torch.constant.int 1
    %249 = torch.aten.div.Scalar %248, %int1_302 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int5_303 = torch.constant.int 5
    %250 = torch.prims.convert_element_type %249, %int5_303 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_304 = torch.constant.int 1
    %int32_305 = torch.constant.int 32
    %int16_306 = torch.constant.int 16
    %int16384_307 = torch.constant.int 16384
    %251 = torch.prim.ListConstruct %int1_304, %int32_305, %int16_306, %int16384_307 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %252 = torch.aten.view %250, %251 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_308 = torch.constant.int 6
    %253 = torch.prims.convert_element_type %252, %int6_308 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_309 = torch.constant.int 2
    %int3_310 = torch.constant.int 3
    %254 = torch.prim.ListConstruct %int2_309, %int3_310 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_311 = torch.constant.int 0
    %true_312 = torch.constant.bool true
    %result0_313, %result1_314 = torch.aten.var_mean.correction %253, %254, %int0_311, %true_312 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_315 = torch.constant.float 9.9999999999999995E-7
    %int1_316 = torch.constant.int 1
    %255 = torch.aten.add.Scalar %result0_313, %float9.999990e-07_315, %int1_316 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %256 = torch.aten.rsqrt %255 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_317 = torch.constant.int 1
    %257 = torch.aten.sub.Tensor %252, %result1_314, %int1_317 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %258 = torch.aten.mul.Tensor %257, %256 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_318 = torch.constant.int 1
    %int512_319 = torch.constant.int 512
    %int128_320 = torch.constant.int 128
    %int128_321 = torch.constant.int 128
    %259 = torch.prim.ListConstruct %int1_318, %int512_319, %int128_320, %int128_321 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %260 = torch.aten.view %258, %259 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16>
    %261 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_322 = torch.constant.int 0
    %262 = torch.aten.unsqueeze %261, %int0_322 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_323 = torch.constant.int 2
    %263 = torch.aten.unsqueeze %262, %int2_323 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_324 = torch.constant.int 3
    %264 = torch.aten.unsqueeze %263, %int3_324 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16>
    %265 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_325 = torch.constant.int 0
    %266 = torch.aten.unsqueeze %265, %int0_325 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_326 = torch.constant.int 2
    %267 = torch.aten.unsqueeze %266, %int2_326 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_327 = torch.constant.int 3
    %268 = torch.aten.unsqueeze %267, %int3_327 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %269 = torch.aten.mul.Tensor %260, %268 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_328 = torch.constant.int 1
    %270 = torch.aten.add.Tensor %269, %264, %int1_328 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_329 = torch.constant.int 5
    %271 = torch.prims.convert_element_type %270, %int5_329 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %272 = torch.aten.silu %271 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %273 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16>
    %274 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_330 = torch.constant.int 1
    %int1_331 = torch.constant.int 1
    %275 = torch.prim.ListConstruct %int1_330, %int1_331 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_332 = torch.constant.int 1
    %int1_333 = torch.constant.int 1
    %276 = torch.prim.ListConstruct %int1_332, %int1_333 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_334 = torch.constant.int 1
    %int1_335 = torch.constant.int 1
    %277 = torch.prim.ListConstruct %int1_334, %int1_335 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_336 = torch.constant.bool false
    %int0_337 = torch.constant.int 0
    %int0_338 = torch.constant.int 0
    %278 = torch.prim.ListConstruct %int0_337, %int0_338 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_339 = torch.constant.int 1
    %279 = torch.aten.convolution %272, %273, %274, %275, %276, %277, %false_336, %278, %int1_339 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_340 = torch.constant.int 1
    %int32_341 = torch.constant.int 32
    %int16_342 = torch.constant.int 16
    %int16384_343 = torch.constant.int 16384
    %280 = torch.prim.ListConstruct %int1_340, %int32_341, %int16_342, %int16384_343 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %281 = torch.aten.view %279, %280 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_344 = torch.constant.int 6
    %282 = torch.prims.convert_element_type %281, %int6_344 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_345 = torch.constant.int 2
    %int3_346 = torch.constant.int 3
    %283 = torch.prim.ListConstruct %int2_345, %int3_346 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_347 = torch.constant.int 0
    %true_348 = torch.constant.bool true
    %result0_349, %result1_350 = torch.aten.var_mean.correction %282, %283, %int0_347, %true_348 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_351 = torch.constant.float 9.9999999999999995E-7
    %int1_352 = torch.constant.int 1
    %284 = torch.aten.add.Scalar %result0_349, %float9.999990e-07_351, %int1_352 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %285 = torch.aten.rsqrt %284 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_353 = torch.constant.int 1
    %286 = torch.aten.sub.Tensor %281, %result1_350, %int1_353 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %287 = torch.aten.mul.Tensor %286, %285 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_354 = torch.constant.int 1
    %int512_355 = torch.constant.int 512
    %int128_356 = torch.constant.int 128
    %int128_357 = torch.constant.int 128
    %288 = torch.prim.ListConstruct %int1_354, %int512_355, %int128_356, %int128_357 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %289 = torch.aten.view %287, %288 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16>
    %290 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_358 = torch.constant.int 0
    %291 = torch.aten.unsqueeze %290, %int0_358 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_359 = torch.constant.int 2
    %292 = torch.aten.unsqueeze %291, %int2_359 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_360 = torch.constant.int 3
    %293 = torch.aten.unsqueeze %292, %int3_360 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16>
    %294 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_361 = torch.constant.int 0
    %295 = torch.aten.unsqueeze %294, %int0_361 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_362 = torch.constant.int 2
    %296 = torch.aten.unsqueeze %295, %int2_362 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_363 = torch.constant.int 3
    %297 = torch.aten.unsqueeze %296, %int3_363 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %298 = torch.aten.mul.Tensor %289, %297 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_364 = torch.constant.int 1
    %299 = torch.aten.add.Tensor %298, %293, %int1_364 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_365 = torch.constant.int 5
    %300 = torch.prims.convert_element_type %299, %int5_365 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %301 = torch.aten.silu %300 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_366 = torch.constant.none
    %302 = torch.aten.clone %301, %none_366 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %303 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16>
    %304 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_367 = torch.constant.int 1
    %int1_368 = torch.constant.int 1
    %305 = torch.prim.ListConstruct %int1_367, %int1_368 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_369 = torch.constant.int 1
    %int1_370 = torch.constant.int 1
    %306 = torch.prim.ListConstruct %int1_369, %int1_370 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_371 = torch.constant.int 1
    %int1_372 = torch.constant.int 1
    %307 = torch.prim.ListConstruct %int1_371, %int1_372 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_373 = torch.constant.bool false
    %int0_374 = torch.constant.int 0
    %int0_375 = torch.constant.int 0
    %308 = torch.prim.ListConstruct %int0_374, %int0_375 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_376 = torch.constant.int 1
    %309 = torch.aten.convolution %302, %303, %304, %305, %306, %307, %false_373, %308, %int1_376 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_377 = torch.constant.int 1
    %310 = torch.aten.add.Tensor %250, %309, %int1_377 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00 = torch.constant.float 1.000000e+00
    %311 = torch.aten.div.Scalar %310, %float1.000000e00 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int1_378 = torch.constant.int 1
    %int32_379 = torch.constant.int 32
    %int16_380 = torch.constant.int 16
    %int16384_381 = torch.constant.int 16384
    %312 = torch.prim.ListConstruct %int1_378, %int32_379, %int16_380, %int16384_381 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %313 = torch.aten.view %311, %312 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_382 = torch.constant.int 6
    %314 = torch.prims.convert_element_type %313, %int6_382 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_383 = torch.constant.int 2
    %int3_384 = torch.constant.int 3
    %315 = torch.prim.ListConstruct %int2_383, %int3_384 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_385 = torch.constant.int 0
    %true_386 = torch.constant.bool true
    %result0_387, %result1_388 = torch.aten.var_mean.correction %314, %315, %int0_385, %true_386 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_389 = torch.constant.float 9.9999999999999995E-7
    %int1_390 = torch.constant.int 1
    %316 = torch.aten.add.Scalar %result0_387, %float9.999990e-07_389, %int1_390 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %317 = torch.aten.rsqrt %316 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_391 = torch.constant.int 1
    %318 = torch.aten.sub.Tensor %313, %result1_388, %int1_391 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %319 = torch.aten.mul.Tensor %318, %317 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_392 = torch.constant.int 1
    %int512_393 = torch.constant.int 512
    %int128_394 = torch.constant.int 128
    %int128_395 = torch.constant.int 128
    %320 = torch.prim.ListConstruct %int1_392, %int512_393, %int128_394, %int128_395 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %321 = torch.aten.view %319, %320 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16>
    %322 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_396 = torch.constant.int 0
    %323 = torch.aten.unsqueeze %322, %int0_396 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_397 = torch.constant.int 2
    %324 = torch.aten.unsqueeze %323, %int2_397 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_398 = torch.constant.int 3
    %325 = torch.aten.unsqueeze %324, %int3_398 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16>
    %326 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_399 = torch.constant.int 0
    %327 = torch.aten.unsqueeze %326, %int0_399 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_400 = torch.constant.int 2
    %328 = torch.aten.unsqueeze %327, %int2_400 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_401 = torch.constant.int 3
    %329 = torch.aten.unsqueeze %328, %int3_401 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %330 = torch.aten.mul.Tensor %321, %329 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_402 = torch.constant.int 1
    %331 = torch.aten.add.Tensor %330, %325, %int1_402 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_403 = torch.constant.int 5
    %332 = torch.prims.convert_element_type %331, %int5_403 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %333 = torch.aten.silu %332 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %334 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16>
    %335 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_404 = torch.constant.int 1
    %int1_405 = torch.constant.int 1
    %336 = torch.prim.ListConstruct %int1_404, %int1_405 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_406 = torch.constant.int 1
    %int1_407 = torch.constant.int 1
    %337 = torch.prim.ListConstruct %int1_406, %int1_407 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_408 = torch.constant.int 1
    %int1_409 = torch.constant.int 1
    %338 = torch.prim.ListConstruct %int1_408, %int1_409 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_410 = torch.constant.bool false
    %int0_411 = torch.constant.int 0
    %int0_412 = torch.constant.int 0
    %339 = torch.prim.ListConstruct %int0_411, %int0_412 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_413 = torch.constant.int 1
    %340 = torch.aten.convolution %333, %334, %335, %336, %337, %338, %false_410, %339, %int1_413 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_414 = torch.constant.int 1
    %int32_415 = torch.constant.int 32
    %int16_416 = torch.constant.int 16
    %int16384_417 = torch.constant.int 16384
    %341 = torch.prim.ListConstruct %int1_414, %int32_415, %int16_416, %int16384_417 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %342 = torch.aten.view %340, %341 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_418 = torch.constant.int 6
    %343 = torch.prims.convert_element_type %342, %int6_418 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_419 = torch.constant.int 2
    %int3_420 = torch.constant.int 3
    %344 = torch.prim.ListConstruct %int2_419, %int3_420 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_421 = torch.constant.int 0
    %true_422 = torch.constant.bool true
    %result0_423, %result1_424 = torch.aten.var_mean.correction %343, %344, %int0_421, %true_422 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_425 = torch.constant.float 9.9999999999999995E-7
    %int1_426 = torch.constant.int 1
    %345 = torch.aten.add.Scalar %result0_423, %float9.999990e-07_425, %int1_426 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %346 = torch.aten.rsqrt %345 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_427 = torch.constant.int 1
    %347 = torch.aten.sub.Tensor %342, %result1_424, %int1_427 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %348 = torch.aten.mul.Tensor %347, %346 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_428 = torch.constant.int 1
    %int512_429 = torch.constant.int 512
    %int128_430 = torch.constant.int 128
    %int128_431 = torch.constant.int 128
    %349 = torch.prim.ListConstruct %int1_428, %int512_429, %int128_430, %int128_431 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %350 = torch.aten.view %348, %349 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16>
    %351 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_432 = torch.constant.int 0
    %352 = torch.aten.unsqueeze %351, %int0_432 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_433 = torch.constant.int 2
    %353 = torch.aten.unsqueeze %352, %int2_433 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_434 = torch.constant.int 3
    %354 = torch.aten.unsqueeze %353, %int3_434 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16>
    %355 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_435 = torch.constant.int 0
    %356 = torch.aten.unsqueeze %355, %int0_435 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_436 = torch.constant.int 2
    %357 = torch.aten.unsqueeze %356, %int2_436 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_437 = torch.constant.int 3
    %358 = torch.aten.unsqueeze %357, %int3_437 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %359 = torch.aten.mul.Tensor %350, %358 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_438 = torch.constant.int 1
    %360 = torch.aten.add.Tensor %359, %354, %int1_438 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_439 = torch.constant.int 5
    %361 = torch.prims.convert_element_type %360, %int5_439 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %362 = torch.aten.silu %361 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_440 = torch.constant.none
    %363 = torch.aten.clone %362, %none_440 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %364 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16>
    %365 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_441 = torch.constant.int 1
    %int1_442 = torch.constant.int 1
    %366 = torch.prim.ListConstruct %int1_441, %int1_442 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_443 = torch.constant.int 1
    %int1_444 = torch.constant.int 1
    %367 = torch.prim.ListConstruct %int1_443, %int1_444 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_445 = torch.constant.int 1
    %int1_446 = torch.constant.int 1
    %368 = torch.prim.ListConstruct %int1_445, %int1_446 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_447 = torch.constant.bool false
    %int0_448 = torch.constant.int 0
    %int0_449 = torch.constant.int 0
    %369 = torch.prim.ListConstruct %int0_448, %int0_449 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_450 = torch.constant.int 1
    %370 = torch.aten.convolution %363, %364, %365, %366, %367, %368, %false_447, %369, %int1_450 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_451 = torch.constant.int 1
    %371 = torch.aten.add.Tensor %311, %370, %int1_451 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00_452 = torch.constant.float 1.000000e+00
    %372 = torch.aten.div.Scalar %371, %float1.000000e00_452 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int1_453 = torch.constant.int 1
    %int32_454 = torch.constant.int 32
    %int16_455 = torch.constant.int 16
    %int16384_456 = torch.constant.int 16384
    %373 = torch.prim.ListConstruct %int1_453, %int32_454, %int16_455, %int16384_456 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %374 = torch.aten.view %372, %373 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_457 = torch.constant.int 6
    %375 = torch.prims.convert_element_type %374, %int6_457 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_458 = torch.constant.int 2
    %int3_459 = torch.constant.int 3
    %376 = torch.prim.ListConstruct %int2_458, %int3_459 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_460 = torch.constant.int 0
    %true_461 = torch.constant.bool true
    %result0_462, %result1_463 = torch.aten.var_mean.correction %375, %376, %int0_460, %true_461 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_464 = torch.constant.float 9.9999999999999995E-7
    %int1_465 = torch.constant.int 1
    %377 = torch.aten.add.Scalar %result0_462, %float9.999990e-07_464, %int1_465 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %378 = torch.aten.rsqrt %377 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_466 = torch.constant.int 1
    %379 = torch.aten.sub.Tensor %374, %result1_463, %int1_466 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %380 = torch.aten.mul.Tensor %379, %378 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_467 = torch.constant.int 1
    %int512_468 = torch.constant.int 512
    %int128_469 = torch.constant.int 128
    %int128_470 = torch.constant.int 128
    %381 = torch.prim.ListConstruct %int1_467, %int512_468, %int128_469, %int128_470 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %382 = torch.aten.view %380, %381 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16>
    %383 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_471 = torch.constant.int 0
    %384 = torch.aten.unsqueeze %383, %int0_471 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_472 = torch.constant.int 2
    %385 = torch.aten.unsqueeze %384, %int2_472 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_473 = torch.constant.int 3
    %386 = torch.aten.unsqueeze %385, %int3_473 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16>
    %387 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_474 = torch.constant.int 0
    %388 = torch.aten.unsqueeze %387, %int0_474 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_475 = torch.constant.int 2
    %389 = torch.aten.unsqueeze %388, %int2_475 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_476 = torch.constant.int 3
    %390 = torch.aten.unsqueeze %389, %int3_476 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %391 = torch.aten.mul.Tensor %382, %390 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_477 = torch.constant.int 1
    %392 = torch.aten.add.Tensor %391, %386, %int1_477 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_478 = torch.constant.int 5
    %393 = torch.prims.convert_element_type %392, %int5_478 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %394 = torch.aten.silu %393 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %395 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16>
    %396 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_479 = torch.constant.int 1
    %int1_480 = torch.constant.int 1
    %397 = torch.prim.ListConstruct %int1_479, %int1_480 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_481 = torch.constant.int 1
    %int1_482 = torch.constant.int 1
    %398 = torch.prim.ListConstruct %int1_481, %int1_482 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_483 = torch.constant.int 1
    %int1_484 = torch.constant.int 1
    %399 = torch.prim.ListConstruct %int1_483, %int1_484 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_485 = torch.constant.bool false
    %int0_486 = torch.constant.int 0
    %int0_487 = torch.constant.int 0
    %400 = torch.prim.ListConstruct %int0_486, %int0_487 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_488 = torch.constant.int 1
    %401 = torch.aten.convolution %394, %395, %396, %397, %398, %399, %false_485, %400, %int1_488 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_489 = torch.constant.int 1
    %int32_490 = torch.constant.int 32
    %int16_491 = torch.constant.int 16
    %int16384_492 = torch.constant.int 16384
    %402 = torch.prim.ListConstruct %int1_489, %int32_490, %int16_491, %int16384_492 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %403 = torch.aten.view %401, %402 : !torch.vtensor<[1,512,128,128],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,16384],f16>
    %int6_493 = torch.constant.int 6
    %404 = torch.prims.convert_element_type %403, %int6_493 : !torch.vtensor<[1,32,16,16384],f16>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %int2_494 = torch.constant.int 2
    %int3_495 = torch.constant.int 3
    %405 = torch.prim.ListConstruct %int2_494, %int3_495 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_496 = torch.constant.int 0
    %true_497 = torch.constant.bool true
    %result0_498, %result1_499 = torch.aten.var_mean.correction %404, %405, %int0_496, %true_497 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_500 = torch.constant.float 9.9999999999999995E-7
    %int1_501 = torch.constant.int 1
    %406 = torch.aten.add.Scalar %result0_498, %float9.999990e-07_500, %int1_501 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %407 = torch.aten.rsqrt %406 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_502 = torch.constant.int 1
    %408 = torch.aten.sub.Tensor %403, %result1_499, %int1_502 : !torch.vtensor<[1,32,16,16384],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,16384],f32>
    %409 = torch.aten.mul.Tensor %408, %407 : !torch.vtensor<[1,32,16,16384],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,16384],f32>
    %int1_503 = torch.constant.int 1
    %int512_504 = torch.constant.int 512
    %int128_505 = torch.constant.int 128
    %int128_506 = torch.constant.int 128
    %410 = torch.prim.ListConstruct %int1_503, %int512_504, %int128_505, %int128_506 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %411 = torch.aten.view %409, %410 : !torch.vtensor<[1,32,16,16384],f32>, !torch.list<int> -> !torch.vtensor<[1,512,128,128],f32>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16>
    %412 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_507 = torch.constant.int 0
    %413 = torch.aten.unsqueeze %412, %int0_507 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_508 = torch.constant.int 2
    %414 = torch.aten.unsqueeze %413, %int2_508 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_509 = torch.constant.int 3
    %415 = torch.aten.unsqueeze %414, %int3_509 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16>
    %416 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_510 = torch.constant.int 0
    %417 = torch.aten.unsqueeze %416, %int0_510 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_511 = torch.constant.int 2
    %418 = torch.aten.unsqueeze %417, %int2_511 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_512 = torch.constant.int 3
    %419 = torch.aten.unsqueeze %418, %int3_512 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %420 = torch.aten.mul.Tensor %411, %419 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,128,128],f32>
    %int1_513 = torch.constant.int 1
    %421 = torch.aten.add.Tensor %420, %415, %int1_513 : !torch.vtensor<[1,512,128,128],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int5_514 = torch.constant.int 5
    %422 = torch.prims.convert_element_type %421, %int5_514 : !torch.vtensor<[1,512,128,128],f32>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %423 = torch.aten.silu %422 : !torch.vtensor<[1,512,128,128],f16> -> !torch.vtensor<[1,512,128,128],f16>
    %none_515 = torch.constant.none
    %424 = torch.aten.clone %423, %none_515 : !torch.vtensor<[1,512,128,128],f16>, !torch.none -> !torch.vtensor<[1,512,128,128],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %425 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16>
    %426 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_516 = torch.constant.int 1
    %int1_517 = torch.constant.int 1
    %427 = torch.prim.ListConstruct %int1_516, %int1_517 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_518 = torch.constant.int 1
    %int1_519 = torch.constant.int 1
    %428 = torch.prim.ListConstruct %int1_518, %int1_519 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_520 = torch.constant.int 1
    %int1_521 = torch.constant.int 1
    %429 = torch.prim.ListConstruct %int1_520, %int1_521 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_522 = torch.constant.bool false
    %int0_523 = torch.constant.int 0
    %int0_524 = torch.constant.int 0
    %430 = torch.prim.ListConstruct %int0_523, %int0_524 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_525 = torch.constant.int 1
    %431 = torch.aten.convolution %424, %425, %426, %427, %428, %429, %false_522, %430, %int1_525 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %int1_526 = torch.constant.int 1
    %432 = torch.aten.add.Tensor %372, %431, %int1_526 : !torch.vtensor<[1,512,128,128],f16>, !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f16>
    %float1.000000e00_527 = torch.constant.float 1.000000e+00
    %433 = torch.aten.div.Scalar %432, %float1.000000e00_527 : !torch.vtensor<[1,512,128,128],f16>, !torch.float -> !torch.vtensor<[1,512,128,128],f16>
    %int6_528 = torch.constant.int 6
    %434 = torch.prims.convert_element_type %433, %int6_528 : !torch.vtensor<[1,512,128,128],f16>, !torch.int -> !torch.vtensor<[1,512,128,128],f32>
    %int256 = torch.constant.int 256
    %int6_529 = torch.constant.int 6
    %none_530 = torch.constant.none
    %cpu = torch.constant.device "cpu"
    %false_531 = torch.constant.bool false
    %435 = torch.aten.arange %int256, %int6_529, %none_530, %cpu, %false_531 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00 = torch.constant.float 0.000000e+00
    %int1_532 = torch.constant.int 1
    %436 = torch.aten.add.Scalar %435, %float0.000000e00, %int1_532 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01 = torch.constant.float 5.000000e-01
    %437 = torch.aten.mul.Scalar %436, %float5.000000e-01 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4 = torch.constant.int 4
    %438 = torch.prims.convert_element_type %437, %int4 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %int-1_533 = torch.constant.int -1
    %439 = torch.aten.unsqueeze %438, %int-1_533 : !torch.vtensor<[256],si64>, !torch.int -> !torch.vtensor<[256,1],si64>
    %int256_534 = torch.constant.int 256
    %int6_535 = torch.constant.int 6
    %none_536 = torch.constant.none
    %cpu_537 = torch.constant.device "cpu"
    %false_538 = torch.constant.bool false
    %440 = torch.aten.arange %int256_534, %int6_535, %none_536, %cpu_537, %false_538 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[256],f32>
    %float0.000000e00_539 = torch.constant.float 0.000000e+00
    %int1_540 = torch.constant.int 1
    %441 = torch.aten.add.Scalar %440, %float0.000000e00_539, %int1_540 : !torch.vtensor<[256],f32>, !torch.float, !torch.int -> !torch.vtensor<[256],f32>
    %float5.000000e-01_541 = torch.constant.float 5.000000e-01
    %442 = torch.aten.mul.Scalar %441, %float5.000000e-01_541 : !torch.vtensor<[256],f32>, !torch.float -> !torch.vtensor<[256],f32>
    %int4_542 = torch.constant.int 4
    %443 = torch.prims.convert_element_type %442, %int4_542 : !torch.vtensor<[256],f32>, !torch.int -> !torch.vtensor<[256],si64>
    %none_543 = torch.constant.none
    %none_544 = torch.constant.none
    %444 = torch.prim.ListConstruct %none_543, %none_544, %439, %443 : (!torch.none, !torch.none, !torch.vtensor<[256,1],si64>, !torch.vtensor<[256],si64>) -> !torch.list<optional<vtensor>>
    %445 = torch.aten.index.Tensor %434, %444 : !torch.vtensor<[1,512,128,128],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,512,256,256],f32>
    %int2_545 = torch.constant.int 2
    %446 = torch.aten.clone %445, %int2_545 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_546 = torch.constant.int 5
    %447 = torch.prims.convert_element_type %446, %int5_546 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight = util.global.load @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %448 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias = util.global.load @__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16>
    %449 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.0.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_547 = torch.constant.int 1
    %int1_548 = torch.constant.int 1
    %450 = torch.prim.ListConstruct %int1_547, %int1_548 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_549 = torch.constant.int 1
    %int1_550 = torch.constant.int 1
    %451 = torch.prim.ListConstruct %int1_549, %int1_550 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_551 = torch.constant.int 1
    %int1_552 = torch.constant.int 1
    %452 = torch.prim.ListConstruct %int1_551, %int1_552 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_553 = torch.constant.bool false
    %int0_554 = torch.constant.int 0
    %int0_555 = torch.constant.int 0
    %453 = torch.prim.ListConstruct %int0_554, %int0_555 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_556 = torch.constant.int 1
    %454 = torch.aten.convolution %447, %448, %449, %450, %451, %452, %false_553, %453, %int1_556 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_557 = torch.constant.int 1
    %int32_558 = torch.constant.int 32
    %int16_559 = torch.constant.int 16
    %int65536 = torch.constant.int 65536
    %455 = torch.prim.ListConstruct %int1_557, %int32_558, %int16_559, %int65536 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %456 = torch.aten.view %454, %455 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_560 = torch.constant.int 6
    %457 = torch.prims.convert_element_type %456, %int6_560 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_561 = torch.constant.int 2
    %int3_562 = torch.constant.int 3
    %458 = torch.prim.ListConstruct %int2_561, %int3_562 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_563 = torch.constant.int 0
    %true_564 = torch.constant.bool true
    %result0_565, %result1_566 = torch.aten.var_mean.correction %457, %458, %int0_563, %true_564 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_567 = torch.constant.float 9.9999999999999995E-7
    %int1_568 = torch.constant.int 1
    %459 = torch.aten.add.Scalar %result0_565, %float9.999990e-07_567, %int1_568 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %460 = torch.aten.rsqrt %459 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_569 = torch.constant.int 1
    %461 = torch.aten.sub.Tensor %456, %result1_566, %int1_569 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %462 = torch.aten.mul.Tensor %461, %460 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_570 = torch.constant.int 1
    %int512_571 = torch.constant.int 512
    %int256_572 = torch.constant.int 256
    %int256_573 = torch.constant.int 256
    %463 = torch.prim.ListConstruct %int1_570, %int512_571, %int256_572, %int256_573 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %464 = torch.aten.view %462, %463 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16>
    %465 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_574 = torch.constant.int 0
    %466 = torch.aten.unsqueeze %465, %int0_574 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_575 = torch.constant.int 2
    %467 = torch.aten.unsqueeze %466, %int2_575 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_576 = torch.constant.int 3
    %468 = torch.aten.unsqueeze %467, %int3_576 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16>
    %469 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_577 = torch.constant.int 0
    %470 = torch.aten.unsqueeze %469, %int0_577 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_578 = torch.constant.int 2
    %471 = torch.aten.unsqueeze %470, %int2_578 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_579 = torch.constant.int 3
    %472 = torch.aten.unsqueeze %471, %int3_579 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %473 = torch.aten.mul.Tensor %464, %472 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_580 = torch.constant.int 1
    %474 = torch.aten.add.Tensor %473, %468, %int1_580 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_581 = torch.constant.int 5
    %475 = torch.prims.convert_element_type %474, %int5_581 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %476 = torch.aten.silu %475 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16>
    %477 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16>
    %478 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_582 = torch.constant.int 1
    %int1_583 = torch.constant.int 1
    %479 = torch.prim.ListConstruct %int1_582, %int1_583 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_584 = torch.constant.int 1
    %int1_585 = torch.constant.int 1
    %480 = torch.prim.ListConstruct %int1_584, %int1_585 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_586 = torch.constant.int 1
    %int1_587 = torch.constant.int 1
    %481 = torch.prim.ListConstruct %int1_586, %int1_587 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_588 = torch.constant.bool false
    %int0_589 = torch.constant.int 0
    %int0_590 = torch.constant.int 0
    %482 = torch.prim.ListConstruct %int0_589, %int0_590 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_591 = torch.constant.int 1
    %483 = torch.aten.convolution %476, %477, %478, %479, %480, %481, %false_588, %482, %int1_591 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_592 = torch.constant.int 1
    %int32_593 = torch.constant.int 32
    %int16_594 = torch.constant.int 16
    %int65536_595 = torch.constant.int 65536
    %484 = torch.prim.ListConstruct %int1_592, %int32_593, %int16_594, %int65536_595 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %485 = torch.aten.view %483, %484 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_596 = torch.constant.int 6
    %486 = torch.prims.convert_element_type %485, %int6_596 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_597 = torch.constant.int 2
    %int3_598 = torch.constant.int 3
    %487 = torch.prim.ListConstruct %int2_597, %int3_598 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_599 = torch.constant.int 0
    %true_600 = torch.constant.bool true
    %result0_601, %result1_602 = torch.aten.var_mean.correction %486, %487, %int0_599, %true_600 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_603 = torch.constant.float 9.9999999999999995E-7
    %int1_604 = torch.constant.int 1
    %488 = torch.aten.add.Scalar %result0_601, %float9.999990e-07_603, %int1_604 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %489 = torch.aten.rsqrt %488 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_605 = torch.constant.int 1
    %490 = torch.aten.sub.Tensor %485, %result1_602, %int1_605 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %491 = torch.aten.mul.Tensor %490, %489 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_606 = torch.constant.int 1
    %int512_607 = torch.constant.int 512
    %int256_608 = torch.constant.int 256
    %int256_609 = torch.constant.int 256
    %492 = torch.prim.ListConstruct %int1_606, %int512_607, %int256_608, %int256_609 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %493 = torch.aten.view %491, %492 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16>
    %494 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_610 = torch.constant.int 0
    %495 = torch.aten.unsqueeze %494, %int0_610 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_611 = torch.constant.int 2
    %496 = torch.aten.unsqueeze %495, %int2_611 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_612 = torch.constant.int 3
    %497 = torch.aten.unsqueeze %496, %int3_612 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16>
    %498 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_613 = torch.constant.int 0
    %499 = torch.aten.unsqueeze %498, %int0_613 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_614 = torch.constant.int 2
    %500 = torch.aten.unsqueeze %499, %int2_614 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_615 = torch.constant.int 3
    %501 = torch.aten.unsqueeze %500, %int3_615 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %502 = torch.aten.mul.Tensor %493, %501 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_616 = torch.constant.int 1
    %503 = torch.aten.add.Tensor %502, %497, %int1_616 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_617 = torch.constant.int 5
    %504 = torch.prims.convert_element_type %503, %int5_617 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %505 = torch.aten.silu %504 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_618 = torch.constant.none
    %506 = torch.aten.clone %505, %none_618 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16>
    %507 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16>
    %508 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.0.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_619 = torch.constant.int 1
    %int1_620 = torch.constant.int 1
    %509 = torch.prim.ListConstruct %int1_619, %int1_620 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_621 = torch.constant.int 1
    %int1_622 = torch.constant.int 1
    %510 = torch.prim.ListConstruct %int1_621, %int1_622 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_623 = torch.constant.int 1
    %int1_624 = torch.constant.int 1
    %511 = torch.prim.ListConstruct %int1_623, %int1_624 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_625 = torch.constant.bool false
    %int0_626 = torch.constant.int 0
    %int0_627 = torch.constant.int 0
    %512 = torch.prim.ListConstruct %int0_626, %int0_627 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_628 = torch.constant.int 1
    %513 = torch.aten.convolution %506, %507, %508, %509, %510, %511, %false_625, %512, %int1_628 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_629 = torch.constant.int 1
    %514 = torch.aten.add.Tensor %454, %513, %int1_629 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_630 = torch.constant.float 1.000000e+00
    %515 = torch.aten.div.Scalar %514, %float1.000000e00_630 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int1_631 = torch.constant.int 1
    %int32_632 = torch.constant.int 32
    %int16_633 = torch.constant.int 16
    %int65536_634 = torch.constant.int 65536
    %516 = torch.prim.ListConstruct %int1_631, %int32_632, %int16_633, %int65536_634 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %517 = torch.aten.view %515, %516 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_635 = torch.constant.int 6
    %518 = torch.prims.convert_element_type %517, %int6_635 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_636 = torch.constant.int 2
    %int3_637 = torch.constant.int 3
    %519 = torch.prim.ListConstruct %int2_636, %int3_637 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_638 = torch.constant.int 0
    %true_639 = torch.constant.bool true
    %result0_640, %result1_641 = torch.aten.var_mean.correction %518, %519, %int0_638, %true_639 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_642 = torch.constant.float 9.9999999999999995E-7
    %int1_643 = torch.constant.int 1
    %520 = torch.aten.add.Scalar %result0_640, %float9.999990e-07_642, %int1_643 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %521 = torch.aten.rsqrt %520 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_644 = torch.constant.int 1
    %522 = torch.aten.sub.Tensor %517, %result1_641, %int1_644 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %523 = torch.aten.mul.Tensor %522, %521 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_645 = torch.constant.int 1
    %int512_646 = torch.constant.int 512
    %int256_647 = torch.constant.int 256
    %int256_648 = torch.constant.int 256
    %524 = torch.prim.ListConstruct %int1_645, %int512_646, %int256_647, %int256_648 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %525 = torch.aten.view %523, %524 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16>
    %526 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_649 = torch.constant.int 0
    %527 = torch.aten.unsqueeze %526, %int0_649 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_650 = torch.constant.int 2
    %528 = torch.aten.unsqueeze %527, %int2_650 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_651 = torch.constant.int 3
    %529 = torch.aten.unsqueeze %528, %int3_651 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16>
    %530 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_652 = torch.constant.int 0
    %531 = torch.aten.unsqueeze %530, %int0_652 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_653 = torch.constant.int 2
    %532 = torch.aten.unsqueeze %531, %int2_653 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_654 = torch.constant.int 3
    %533 = torch.aten.unsqueeze %532, %int3_654 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %534 = torch.aten.mul.Tensor %525, %533 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_655 = torch.constant.int 1
    %535 = torch.aten.add.Tensor %534, %529, %int1_655 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_656 = torch.constant.int 5
    %536 = torch.prims.convert_element_type %535, %int5_656 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %537 = torch.aten.silu %536 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16>
    %538 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16>
    %539 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_657 = torch.constant.int 1
    %int1_658 = torch.constant.int 1
    %540 = torch.prim.ListConstruct %int1_657, %int1_658 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_659 = torch.constant.int 1
    %int1_660 = torch.constant.int 1
    %541 = torch.prim.ListConstruct %int1_659, %int1_660 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_661 = torch.constant.int 1
    %int1_662 = torch.constant.int 1
    %542 = torch.prim.ListConstruct %int1_661, %int1_662 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_663 = torch.constant.bool false
    %int0_664 = torch.constant.int 0
    %int0_665 = torch.constant.int 0
    %543 = torch.prim.ListConstruct %int0_664, %int0_665 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_666 = torch.constant.int 1
    %544 = torch.aten.convolution %537, %538, %539, %540, %541, %542, %false_663, %543, %int1_666 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_667 = torch.constant.int 1
    %int32_668 = torch.constant.int 32
    %int16_669 = torch.constant.int 16
    %int65536_670 = torch.constant.int 65536
    %545 = torch.prim.ListConstruct %int1_667, %int32_668, %int16_669, %int65536_670 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %546 = torch.aten.view %544, %545 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_671 = torch.constant.int 6
    %547 = torch.prims.convert_element_type %546, %int6_671 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_672 = torch.constant.int 2
    %int3_673 = torch.constant.int 3
    %548 = torch.prim.ListConstruct %int2_672, %int3_673 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_674 = torch.constant.int 0
    %true_675 = torch.constant.bool true
    %result0_676, %result1_677 = torch.aten.var_mean.correction %547, %548, %int0_674, %true_675 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_678 = torch.constant.float 9.9999999999999995E-7
    %int1_679 = torch.constant.int 1
    %549 = torch.aten.add.Scalar %result0_676, %float9.999990e-07_678, %int1_679 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %550 = torch.aten.rsqrt %549 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_680 = torch.constant.int 1
    %551 = torch.aten.sub.Tensor %546, %result1_677, %int1_680 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %552 = torch.aten.mul.Tensor %551, %550 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_681 = torch.constant.int 1
    %int512_682 = torch.constant.int 512
    %int256_683 = torch.constant.int 256
    %int256_684 = torch.constant.int 256
    %553 = torch.prim.ListConstruct %int1_681, %int512_682, %int256_683, %int256_684 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %554 = torch.aten.view %552, %553 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16>
    %555 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_685 = torch.constant.int 0
    %556 = torch.aten.unsqueeze %555, %int0_685 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_686 = torch.constant.int 2
    %557 = torch.aten.unsqueeze %556, %int2_686 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_687 = torch.constant.int 3
    %558 = torch.aten.unsqueeze %557, %int3_687 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16>
    %559 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_688 = torch.constant.int 0
    %560 = torch.aten.unsqueeze %559, %int0_688 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_689 = torch.constant.int 2
    %561 = torch.aten.unsqueeze %560, %int2_689 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_690 = torch.constant.int 3
    %562 = torch.aten.unsqueeze %561, %int3_690 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %563 = torch.aten.mul.Tensor %554, %562 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_691 = torch.constant.int 1
    %564 = torch.aten.add.Tensor %563, %558, %int1_691 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_692 = torch.constant.int 5
    %565 = torch.prims.convert_element_type %564, %int5_692 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %566 = torch.aten.silu %565 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_693 = torch.constant.none
    %567 = torch.aten.clone %566, %none_693 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16>
    %568 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16>
    %569 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.1.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_694 = torch.constant.int 1
    %int1_695 = torch.constant.int 1
    %570 = torch.prim.ListConstruct %int1_694, %int1_695 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_696 = torch.constant.int 1
    %int1_697 = torch.constant.int 1
    %571 = torch.prim.ListConstruct %int1_696, %int1_697 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_698 = torch.constant.int 1
    %int1_699 = torch.constant.int 1
    %572 = torch.prim.ListConstruct %int1_698, %int1_699 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_700 = torch.constant.bool false
    %int0_701 = torch.constant.int 0
    %int0_702 = torch.constant.int 0
    %573 = torch.prim.ListConstruct %int0_701, %int0_702 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_703 = torch.constant.int 1
    %574 = torch.aten.convolution %567, %568, %569, %570, %571, %572, %false_700, %573, %int1_703 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_704 = torch.constant.int 1
    %575 = torch.aten.add.Tensor %515, %574, %int1_704 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_705 = torch.constant.float 1.000000e+00
    %576 = torch.aten.div.Scalar %575, %float1.000000e00_705 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int1_706 = torch.constant.int 1
    %int32_707 = torch.constant.int 32
    %int16_708 = torch.constant.int 16
    %int65536_709 = torch.constant.int 65536
    %577 = torch.prim.ListConstruct %int1_706, %int32_707, %int16_708, %int65536_709 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %578 = torch.aten.view %576, %577 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_710 = torch.constant.int 6
    %579 = torch.prims.convert_element_type %578, %int6_710 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_711 = torch.constant.int 2
    %int3_712 = torch.constant.int 3
    %580 = torch.prim.ListConstruct %int2_711, %int3_712 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_713 = torch.constant.int 0
    %true_714 = torch.constant.bool true
    %result0_715, %result1_716 = torch.aten.var_mean.correction %579, %580, %int0_713, %true_714 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_717 = torch.constant.float 9.9999999999999995E-7
    %int1_718 = torch.constant.int 1
    %581 = torch.aten.add.Scalar %result0_715, %float9.999990e-07_717, %int1_718 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %582 = torch.aten.rsqrt %581 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_719 = torch.constant.int 1
    %583 = torch.aten.sub.Tensor %578, %result1_716, %int1_719 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %584 = torch.aten.mul.Tensor %583, %582 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_720 = torch.constant.int 1
    %int512_721 = torch.constant.int 512
    %int256_722 = torch.constant.int 256
    %int256_723 = torch.constant.int 256
    %585 = torch.prim.ListConstruct %int1_720, %int512_721, %int256_722, %int256_723 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %586 = torch.aten.view %584, %585 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16>
    %587 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_724 = torch.constant.int 0
    %588 = torch.aten.unsqueeze %587, %int0_724 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_725 = torch.constant.int 2
    %589 = torch.aten.unsqueeze %588, %int2_725 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_726 = torch.constant.int 3
    %590 = torch.aten.unsqueeze %589, %int3_726 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16>
    %591 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_727 = torch.constant.int 0
    %592 = torch.aten.unsqueeze %591, %int0_727 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_728 = torch.constant.int 2
    %593 = torch.aten.unsqueeze %592, %int2_728 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_729 = torch.constant.int 3
    %594 = torch.aten.unsqueeze %593, %int3_729 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %595 = torch.aten.mul.Tensor %586, %594 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_730 = torch.constant.int 1
    %596 = torch.aten.add.Tensor %595, %590, %int1_730 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_731 = torch.constant.int 5
    %597 = torch.prims.convert_element_type %596, %int5_731 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %598 = torch.aten.silu %597 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16>
    %599 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16>
    %600 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_732 = torch.constant.int 1
    %int1_733 = torch.constant.int 1
    %601 = torch.prim.ListConstruct %int1_732, %int1_733 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_734 = torch.constant.int 1
    %int1_735 = torch.constant.int 1
    %602 = torch.prim.ListConstruct %int1_734, %int1_735 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_736 = torch.constant.int 1
    %int1_737 = torch.constant.int 1
    %603 = torch.prim.ListConstruct %int1_736, %int1_737 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_738 = torch.constant.bool false
    %int0_739 = torch.constant.int 0
    %int0_740 = torch.constant.int 0
    %604 = torch.prim.ListConstruct %int0_739, %int0_740 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_741 = torch.constant.int 1
    %605 = torch.aten.convolution %598, %599, %600, %601, %602, %603, %false_738, %604, %int1_741 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_742 = torch.constant.int 1
    %int32_743 = torch.constant.int 32
    %int16_744 = torch.constant.int 16
    %int65536_745 = torch.constant.int 65536
    %606 = torch.prim.ListConstruct %int1_742, %int32_743, %int16_744, %int65536_745 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %607 = torch.aten.view %605, %606 : !torch.vtensor<[1,512,256,256],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,65536],f16>
    %int6_746 = torch.constant.int 6
    %608 = torch.prims.convert_element_type %607, %int6_746 : !torch.vtensor<[1,32,16,65536],f16>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %int2_747 = torch.constant.int 2
    %int3_748 = torch.constant.int 3
    %609 = torch.prim.ListConstruct %int2_747, %int3_748 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_749 = torch.constant.int 0
    %true_750 = torch.constant.bool true
    %result0_751, %result1_752 = torch.aten.var_mean.correction %608, %609, %int0_749, %true_750 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_753 = torch.constant.float 9.9999999999999995E-7
    %int1_754 = torch.constant.int 1
    %610 = torch.aten.add.Scalar %result0_751, %float9.999990e-07_753, %int1_754 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %611 = torch.aten.rsqrt %610 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_755 = torch.constant.int 1
    %612 = torch.aten.sub.Tensor %607, %result1_752, %int1_755 : !torch.vtensor<[1,32,16,65536],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,65536],f32>
    %613 = torch.aten.mul.Tensor %612, %611 : !torch.vtensor<[1,32,16,65536],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,65536],f32>
    %int1_756 = torch.constant.int 1
    %int512_757 = torch.constant.int 512
    %int256_758 = torch.constant.int 256
    %int256_759 = torch.constant.int 256
    %614 = torch.prim.ListConstruct %int1_756, %int512_757, %int256_758, %int256_759 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %615 = torch.aten.view %613, %614 : !torch.vtensor<[1,32,16,65536],f32>, !torch.list<int> -> !torch.vtensor<[1,512,256,256],f32>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16>
    %616 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_760 = torch.constant.int 0
    %617 = torch.aten.unsqueeze %616, %int0_760 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_761 = torch.constant.int 2
    %618 = torch.aten.unsqueeze %617, %int2_761 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_762 = torch.constant.int 3
    %619 = torch.aten.unsqueeze %618, %int3_762 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16>
    %620 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.norm2.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_763 = torch.constant.int 0
    %621 = torch.aten.unsqueeze %620, %int0_763 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_764 = torch.constant.int 2
    %622 = torch.aten.unsqueeze %621, %int2_764 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_765 = torch.constant.int 3
    %623 = torch.aten.unsqueeze %622, %int3_765 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %624 = torch.aten.mul.Tensor %615, %623 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,256,256],f32>
    %int1_766 = torch.constant.int 1
    %625 = torch.aten.add.Tensor %624, %619, %int1_766 : !torch.vtensor<[1,512,256,256],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int5_767 = torch.constant.int 5
    %626 = torch.prims.convert_element_type %625, %int5_767 : !torch.vtensor<[1,512,256,256],f32>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %627 = torch.aten.silu %626 : !torch.vtensor<[1,512,256,256],f16> -> !torch.vtensor<[1,512,256,256],f16>
    %none_768 = torch.constant.none
    %628 = torch.aten.clone %627, %none_768 : !torch.vtensor<[1,512,256,256],f16>, !torch.none -> !torch.vtensor<[1,512,256,256],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16>
    %629 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16>
    %630 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.resnets.2.conv2.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_769 = torch.constant.int 1
    %int1_770 = torch.constant.int 1
    %631 = torch.prim.ListConstruct %int1_769, %int1_770 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_771 = torch.constant.int 1
    %int1_772 = torch.constant.int 1
    %632 = torch.prim.ListConstruct %int1_771, %int1_772 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_773 = torch.constant.int 1
    %int1_774 = torch.constant.int 1
    %633 = torch.prim.ListConstruct %int1_773, %int1_774 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_775 = torch.constant.bool false
    %int0_776 = torch.constant.int 0
    %int0_777 = torch.constant.int 0
    %634 = torch.prim.ListConstruct %int0_776, %int0_777 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_778 = torch.constant.int 1
    %635 = torch.aten.convolution %628, %629, %630, %631, %632, %633, %false_775, %634, %int1_778 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %int1_779 = torch.constant.int 1
    %636 = torch.aten.add.Tensor %576, %635, %int1_779 : !torch.vtensor<[1,512,256,256],f16>, !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f16>
    %float1.000000e00_780 = torch.constant.float 1.000000e+00
    %637 = torch.aten.div.Scalar %636, %float1.000000e00_780 : !torch.vtensor<[1,512,256,256],f16>, !torch.float -> !torch.vtensor<[1,512,256,256],f16>
    %int6_781 = torch.constant.int 6
    %638 = torch.prims.convert_element_type %637, %int6_781 : !torch.vtensor<[1,512,256,256],f16>, !torch.int -> !torch.vtensor<[1,512,256,256],f32>
    %int512_782 = torch.constant.int 512
    %int6_783 = torch.constant.int 6
    %none_784 = torch.constant.none
    %cpu_785 = torch.constant.device "cpu"
    %false_786 = torch.constant.bool false
    %639 = torch.aten.arange %int512_782, %int6_783, %none_784, %cpu_785, %false_786 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_787 = torch.constant.float 0.000000e+00
    %int1_788 = torch.constant.int 1
    %640 = torch.aten.add.Scalar %639, %float0.000000e00_787, %int1_788 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_789 = torch.constant.float 5.000000e-01
    %641 = torch.aten.mul.Scalar %640, %float5.000000e-01_789 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_790 = torch.constant.int 4
    %642 = torch.prims.convert_element_type %641, %int4_790 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %int-1_791 = torch.constant.int -1
    %643 = torch.aten.unsqueeze %642, %int-1_791 : !torch.vtensor<[512],si64>, !torch.int -> !torch.vtensor<[512,1],si64>
    %int512_792 = torch.constant.int 512
    %int6_793 = torch.constant.int 6
    %none_794 = torch.constant.none
    %cpu_795 = torch.constant.device "cpu"
    %false_796 = torch.constant.bool false
    %644 = torch.aten.arange %int512_792, %int6_793, %none_794, %cpu_795, %false_796 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[512],f32>
    %float0.000000e00_797 = torch.constant.float 0.000000e+00
    %int1_798 = torch.constant.int 1
    %645 = torch.aten.add.Scalar %644, %float0.000000e00_797, %int1_798 : !torch.vtensor<[512],f32>, !torch.float, !torch.int -> !torch.vtensor<[512],f32>
    %float5.000000e-01_799 = torch.constant.float 5.000000e-01
    %646 = torch.aten.mul.Scalar %645, %float5.000000e-01_799 : !torch.vtensor<[512],f32>, !torch.float -> !torch.vtensor<[512],f32>
    %int4_800 = torch.constant.int 4
    %647 = torch.prims.convert_element_type %646, %int4_800 : !torch.vtensor<[512],f32>, !torch.int -> !torch.vtensor<[512],si64>
    %none_801 = torch.constant.none
    %none_802 = torch.constant.none
    %648 = torch.prim.ListConstruct %none_801, %none_802, %643, %647 : (!torch.none, !torch.none, !torch.vtensor<[512,1],si64>, !torch.vtensor<[512],si64>) -> !torch.list<optional<vtensor>>
    %649 = torch.aten.index.Tensor %638, %648 : !torch.vtensor<[1,512,256,256],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,512,512,512],f32>
    %int2_803 = torch.constant.int 2
    %650 = torch.aten.clone %649, %int2_803 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f32>
    %int5_804 = torch.constant.int 5
    %651 = torch.prims.convert_element_type %650, %int5_804 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight = util.global.load @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16>
    %652 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.weight : tensor<512x512x3x3xf16> -> !torch.vtensor<[512,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias = util.global.load @__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16>
    %653 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.1.upsamplers.0.conv.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int1_805 = torch.constant.int 1
    %int1_806 = torch.constant.int 1
    %654 = torch.prim.ListConstruct %int1_805, %int1_806 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_807 = torch.constant.int 1
    %int1_808 = torch.constant.int 1
    %655 = torch.prim.ListConstruct %int1_807, %int1_808 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_809 = torch.constant.int 1
    %int1_810 = torch.constant.int 1
    %656 = torch.prim.ListConstruct %int1_809, %int1_810 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_811 = torch.constant.bool false
    %int0_812 = torch.constant.int 0
    %int0_813 = torch.constant.int 0
    %657 = torch.prim.ListConstruct %int0_812, %int0_813 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_814 = torch.constant.int 1
    %658 = torch.aten.convolution %651, %652, %653, %654, %655, %656, %false_811, %657, %int1_814 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[512,512,3,3],f16>, !torch.vtensor<[512],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %int1_815 = torch.constant.int 1
    %int32_816 = torch.constant.int 32
    %int16_817 = torch.constant.int 16
    %int262144 = torch.constant.int 262144
    %659 = torch.prim.ListConstruct %int1_815, %int32_816, %int16_817, %int262144 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %660 = torch.aten.view %658, %659 : !torch.vtensor<[1,512,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,16,262144],f16>
    %int6_818 = torch.constant.int 6
    %661 = torch.prims.convert_element_type %660, %int6_818 : !torch.vtensor<[1,32,16,262144],f16>, !torch.int -> !torch.vtensor<[1,32,16,262144],f32>
    %int2_819 = torch.constant.int 2
    %int3_820 = torch.constant.int 3
    %662 = torch.prim.ListConstruct %int2_819, %int3_820 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_821 = torch.constant.int 0
    %true_822 = torch.constant.bool true
    %result0_823, %result1_824 = torch.aten.var_mean.correction %661, %662, %int0_821, %true_822 : !torch.vtensor<[1,32,16,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_825 = torch.constant.float 9.9999999999999995E-7
    %int1_826 = torch.constant.int 1
    %663 = torch.aten.add.Scalar %result0_823, %float9.999990e-07_825, %int1_826 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %664 = torch.aten.rsqrt %663 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_827 = torch.constant.int 1
    %665 = torch.aten.sub.Tensor %660, %result1_824, %int1_827 : !torch.vtensor<[1,32,16,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,16,262144],f32>
    %666 = torch.aten.mul.Tensor %665, %664 : !torch.vtensor<[1,32,16,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,16,262144],f32>
    %int1_828 = torch.constant.int 1
    %int512_829 = torch.constant.int 512
    %int512_830 = torch.constant.int 512
    %int512_831 = torch.constant.int 512
    %667 = torch.prim.ListConstruct %int1_828, %int512_829, %int512_830, %int512_831 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %668 = torch.aten.view %666, %667 : !torch.vtensor<[1,32,16,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,512,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16>
    %669 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.bias : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_832 = torch.constant.int 0
    %670 = torch.aten.unsqueeze %669, %int0_832 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_833 = torch.constant.int 2
    %671 = torch.aten.unsqueeze %670, %int2_833 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_834 = torch.constant.int 3
    %672 = torch.aten.unsqueeze %671, %int3_834 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16>
    %673 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm1.weight : tensor<512xf16> -> !torch.vtensor<[512],f16>
    %int0_835 = torch.constant.int 0
    %674 = torch.aten.unsqueeze %673, %int0_835 : !torch.vtensor<[512],f16>, !torch.int -> !torch.vtensor<[1,512],f16>
    %int2_836 = torch.constant.int 2
    %675 = torch.aten.unsqueeze %674, %int2_836 : !torch.vtensor<[1,512],f16>, !torch.int -> !torch.vtensor<[1,512,1],f16>
    %int3_837 = torch.constant.int 3
    %676 = torch.aten.unsqueeze %675, %int3_837 : !torch.vtensor<[1,512,1],f16>, !torch.int -> !torch.vtensor<[1,512,1,1],f16>
    %677 = torch.aten.mul.Tensor %668, %676 : !torch.vtensor<[1,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16> -> !torch.vtensor<[1,512,512,512],f32>
    %int1_838 = torch.constant.int 1
    %678 = torch.aten.add.Tensor %677, %672, %int1_838 : !torch.vtensor<[1,512,512,512],f32>, !torch.vtensor<[1,512,1,1],f16>, !torch.int -> !torch.vtensor<[1,512,512,512],f32>
    %int5_839 = torch.constant.int 5
    %679 = torch.prims.convert_element_type %678, %int5_839 : !torch.vtensor<[1,512,512,512],f32>, !torch.int -> !torch.vtensor<[1,512,512,512],f16>
    %680 = torch.aten.silu %679 : !torch.vtensor<[1,512,512,512],f16> -> !torch.vtensor<[1,512,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16>
    %681 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.weight : tensor<256x512x3x3xf16> -> !torch.vtensor<[256,512,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16>
    %682 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_840 = torch.constant.int 1
    %int1_841 = torch.constant.int 1
    %683 = torch.prim.ListConstruct %int1_840, %int1_841 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_842 = torch.constant.int 1
    %int1_843 = torch.constant.int 1
    %684 = torch.prim.ListConstruct %int1_842, %int1_843 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_844 = torch.constant.int 1
    %int1_845 = torch.constant.int 1
    %685 = torch.prim.ListConstruct %int1_844, %int1_845 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_846 = torch.constant.bool false
    %int0_847 = torch.constant.int 0
    %int0_848 = torch.constant.int 0
    %686 = torch.prim.ListConstruct %int0_847, %int0_848 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_849 = torch.constant.int 1
    %687 = torch.aten.convolution %680, %681, %682, %683, %684, %685, %false_846, %686, %int1_849 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[256,512,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_850 = torch.constant.int 1
    %int32_851 = torch.constant.int 32
    %int8 = torch.constant.int 8
    %int262144_852 = torch.constant.int 262144
    %688 = torch.prim.ListConstruct %int1_850, %int32_851, %int8, %int262144_852 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %689 = torch.aten.view %687, %688 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_853 = torch.constant.int 6
    %690 = torch.prims.convert_element_type %689, %int6_853 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_854 = torch.constant.int 2
    %int3_855 = torch.constant.int 3
    %691 = torch.prim.ListConstruct %int2_854, %int3_855 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_856 = torch.constant.int 0
    %true_857 = torch.constant.bool true
    %result0_858, %result1_859 = torch.aten.var_mean.correction %690, %691, %int0_856, %true_857 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_860 = torch.constant.float 9.9999999999999995E-7
    %int1_861 = torch.constant.int 1
    %692 = torch.aten.add.Scalar %result0_858, %float9.999990e-07_860, %int1_861 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %693 = torch.aten.rsqrt %692 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_862 = torch.constant.int 1
    %694 = torch.aten.sub.Tensor %689, %result1_859, %int1_862 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %695 = torch.aten.mul.Tensor %694, %693 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_863 = torch.constant.int 1
    %int256_864 = torch.constant.int 256
    %int512_865 = torch.constant.int 512
    %int512_866 = torch.constant.int 512
    %696 = torch.prim.ListConstruct %int1_863, %int256_864, %int512_865, %int512_866 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %697 = torch.aten.view %695, %696 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16>
    %698 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_867 = torch.constant.int 0
    %699 = torch.aten.unsqueeze %698, %int0_867 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_868 = torch.constant.int 2
    %700 = torch.aten.unsqueeze %699, %int2_868 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_869 = torch.constant.int 3
    %701 = torch.aten.unsqueeze %700, %int3_869 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16>
    %702 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_870 = torch.constant.int 0
    %703 = torch.aten.unsqueeze %702, %int0_870 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_871 = torch.constant.int 2
    %704 = torch.aten.unsqueeze %703, %int2_871 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_872 = torch.constant.int 3
    %705 = torch.aten.unsqueeze %704, %int3_872 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %706 = torch.aten.mul.Tensor %697, %705 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_873 = torch.constant.int 1
    %707 = torch.aten.add.Tensor %706, %701, %int1_873 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_874 = torch.constant.int 5
    %708 = torch.prims.convert_element_type %707, %int5_874 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %709 = torch.aten.silu %708 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_875 = torch.constant.none
    %710 = torch.aten.clone %709, %none_875 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16>
    %711 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16>
    %712 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_876 = torch.constant.int 1
    %int1_877 = torch.constant.int 1
    %713 = torch.prim.ListConstruct %int1_876, %int1_877 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_878 = torch.constant.int 1
    %int1_879 = torch.constant.int 1
    %714 = torch.prim.ListConstruct %int1_878, %int1_879 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_880 = torch.constant.int 1
    %int1_881 = torch.constant.int 1
    %715 = torch.prim.ListConstruct %int1_880, %int1_881 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_882 = torch.constant.bool false
    %int0_883 = torch.constant.int 0
    %int0_884 = torch.constant.int 0
    %716 = torch.prim.ListConstruct %int0_883, %int0_884 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_885 = torch.constant.int 1
    %717 = torch.aten.convolution %710, %711, %712, %713, %714, %715, %false_882, %716, %int1_885 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16>
    %718 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.weight : tensor<256x512x1x1xf16> -> !torch.vtensor<[256,512,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16>
    %719 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.0.conv_shortcut.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_886 = torch.constant.int 1
    %int1_887 = torch.constant.int 1
    %720 = torch.prim.ListConstruct %int1_886, %int1_887 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_888 = torch.constant.int 0
    %int0_889 = torch.constant.int 0
    %721 = torch.prim.ListConstruct %int0_888, %int0_889 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_890 = torch.constant.int 1
    %int1_891 = torch.constant.int 1
    %722 = torch.prim.ListConstruct %int1_890, %int1_891 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_892 = torch.constant.bool false
    %int0_893 = torch.constant.int 0
    %int0_894 = torch.constant.int 0
    %723 = torch.prim.ListConstruct %int0_893, %int0_894 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_895 = torch.constant.int 1
    %724 = torch.aten.convolution %658, %718, %719, %720, %721, %722, %false_892, %723, %int1_895 : !torch.vtensor<[1,512,512,512],f16>, !torch.vtensor<[256,512,1,1],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_896 = torch.constant.int 1
    %725 = torch.aten.add.Tensor %724, %717, %int1_896 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_897 = torch.constant.float 1.000000e+00
    %726 = torch.aten.div.Scalar %725, %float1.000000e00_897 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int1_898 = torch.constant.int 1
    %int32_899 = torch.constant.int 32
    %int8_900 = torch.constant.int 8
    %int262144_901 = torch.constant.int 262144
    %727 = torch.prim.ListConstruct %int1_898, %int32_899, %int8_900, %int262144_901 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %728 = torch.aten.view %726, %727 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_902 = torch.constant.int 6
    %729 = torch.prims.convert_element_type %728, %int6_902 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_903 = torch.constant.int 2
    %int3_904 = torch.constant.int 3
    %730 = torch.prim.ListConstruct %int2_903, %int3_904 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_905 = torch.constant.int 0
    %true_906 = torch.constant.bool true
    %result0_907, %result1_908 = torch.aten.var_mean.correction %729, %730, %int0_905, %true_906 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_909 = torch.constant.float 9.9999999999999995E-7
    %int1_910 = torch.constant.int 1
    %731 = torch.aten.add.Scalar %result0_907, %float9.999990e-07_909, %int1_910 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %732 = torch.aten.rsqrt %731 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_911 = torch.constant.int 1
    %733 = torch.aten.sub.Tensor %728, %result1_908, %int1_911 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %734 = torch.aten.mul.Tensor %733, %732 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_912 = torch.constant.int 1
    %int256_913 = torch.constant.int 256
    %int512_914 = torch.constant.int 512
    %int512_915 = torch.constant.int 512
    %735 = torch.prim.ListConstruct %int1_912, %int256_913, %int512_914, %int512_915 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %736 = torch.aten.view %734, %735 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16>
    %737 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_916 = torch.constant.int 0
    %738 = torch.aten.unsqueeze %737, %int0_916 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_917 = torch.constant.int 2
    %739 = torch.aten.unsqueeze %738, %int2_917 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_918 = torch.constant.int 3
    %740 = torch.aten.unsqueeze %739, %int3_918 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16>
    %741 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_919 = torch.constant.int 0
    %742 = torch.aten.unsqueeze %741, %int0_919 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_920 = torch.constant.int 2
    %743 = torch.aten.unsqueeze %742, %int2_920 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_921 = torch.constant.int 3
    %744 = torch.aten.unsqueeze %743, %int3_921 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %745 = torch.aten.mul.Tensor %736, %744 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_922 = torch.constant.int 1
    %746 = torch.aten.add.Tensor %745, %740, %int1_922 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_923 = torch.constant.int 5
    %747 = torch.prims.convert_element_type %746, %int5_923 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %748 = torch.aten.silu %747 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16>
    %749 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16>
    %750 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_924 = torch.constant.int 1
    %int1_925 = torch.constant.int 1
    %751 = torch.prim.ListConstruct %int1_924, %int1_925 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_926 = torch.constant.int 1
    %int1_927 = torch.constant.int 1
    %752 = torch.prim.ListConstruct %int1_926, %int1_927 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_928 = torch.constant.int 1
    %int1_929 = torch.constant.int 1
    %753 = torch.prim.ListConstruct %int1_928, %int1_929 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_930 = torch.constant.bool false
    %int0_931 = torch.constant.int 0
    %int0_932 = torch.constant.int 0
    %754 = torch.prim.ListConstruct %int0_931, %int0_932 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_933 = torch.constant.int 1
    %755 = torch.aten.convolution %748, %749, %750, %751, %752, %753, %false_930, %754, %int1_933 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_934 = torch.constant.int 1
    %int32_935 = torch.constant.int 32
    %int8_936 = torch.constant.int 8
    %int262144_937 = torch.constant.int 262144
    %756 = torch.prim.ListConstruct %int1_934, %int32_935, %int8_936, %int262144_937 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %757 = torch.aten.view %755, %756 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_938 = torch.constant.int 6
    %758 = torch.prims.convert_element_type %757, %int6_938 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_939 = torch.constant.int 2
    %int3_940 = torch.constant.int 3
    %759 = torch.prim.ListConstruct %int2_939, %int3_940 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_941 = torch.constant.int 0
    %true_942 = torch.constant.bool true
    %result0_943, %result1_944 = torch.aten.var_mean.correction %758, %759, %int0_941, %true_942 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_945 = torch.constant.float 9.9999999999999995E-7
    %int1_946 = torch.constant.int 1
    %760 = torch.aten.add.Scalar %result0_943, %float9.999990e-07_945, %int1_946 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %761 = torch.aten.rsqrt %760 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_947 = torch.constant.int 1
    %762 = torch.aten.sub.Tensor %757, %result1_944, %int1_947 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %763 = torch.aten.mul.Tensor %762, %761 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_948 = torch.constant.int 1
    %int256_949 = torch.constant.int 256
    %int512_950 = torch.constant.int 512
    %int512_951 = torch.constant.int 512
    %764 = torch.prim.ListConstruct %int1_948, %int256_949, %int512_950, %int512_951 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %765 = torch.aten.view %763, %764 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16>
    %766 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_952 = torch.constant.int 0
    %767 = torch.aten.unsqueeze %766, %int0_952 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_953 = torch.constant.int 2
    %768 = torch.aten.unsqueeze %767, %int2_953 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_954 = torch.constant.int 3
    %769 = torch.aten.unsqueeze %768, %int3_954 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16>
    %770 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_955 = torch.constant.int 0
    %771 = torch.aten.unsqueeze %770, %int0_955 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_956 = torch.constant.int 2
    %772 = torch.aten.unsqueeze %771, %int2_956 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_957 = torch.constant.int 3
    %773 = torch.aten.unsqueeze %772, %int3_957 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %774 = torch.aten.mul.Tensor %765, %773 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_958 = torch.constant.int 1
    %775 = torch.aten.add.Tensor %774, %769, %int1_958 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_959 = torch.constant.int 5
    %776 = torch.prims.convert_element_type %775, %int5_959 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %777 = torch.aten.silu %776 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_960 = torch.constant.none
    %778 = torch.aten.clone %777, %none_960 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16>
    %779 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16>
    %780 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.1.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_961 = torch.constant.int 1
    %int1_962 = torch.constant.int 1
    %781 = torch.prim.ListConstruct %int1_961, %int1_962 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_963 = torch.constant.int 1
    %int1_964 = torch.constant.int 1
    %782 = torch.prim.ListConstruct %int1_963, %int1_964 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_965 = torch.constant.int 1
    %int1_966 = torch.constant.int 1
    %783 = torch.prim.ListConstruct %int1_965, %int1_966 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_967 = torch.constant.bool false
    %int0_968 = torch.constant.int 0
    %int0_969 = torch.constant.int 0
    %784 = torch.prim.ListConstruct %int0_968, %int0_969 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_970 = torch.constant.int 1
    %785 = torch.aten.convolution %778, %779, %780, %781, %782, %783, %false_967, %784, %int1_970 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_971 = torch.constant.int 1
    %786 = torch.aten.add.Tensor %726, %785, %int1_971 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_972 = torch.constant.float 1.000000e+00
    %787 = torch.aten.div.Scalar %786, %float1.000000e00_972 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int1_973 = torch.constant.int 1
    %int32_974 = torch.constant.int 32
    %int8_975 = torch.constant.int 8
    %int262144_976 = torch.constant.int 262144
    %788 = torch.prim.ListConstruct %int1_973, %int32_974, %int8_975, %int262144_976 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %789 = torch.aten.view %787, %788 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_977 = torch.constant.int 6
    %790 = torch.prims.convert_element_type %789, %int6_977 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_978 = torch.constant.int 2
    %int3_979 = torch.constant.int 3
    %791 = torch.prim.ListConstruct %int2_978, %int3_979 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_980 = torch.constant.int 0
    %true_981 = torch.constant.bool true
    %result0_982, %result1_983 = torch.aten.var_mean.correction %790, %791, %int0_980, %true_981 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_984 = torch.constant.float 9.9999999999999995E-7
    %int1_985 = torch.constant.int 1
    %792 = torch.aten.add.Scalar %result0_982, %float9.999990e-07_984, %int1_985 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %793 = torch.aten.rsqrt %792 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_986 = torch.constant.int 1
    %794 = torch.aten.sub.Tensor %789, %result1_983, %int1_986 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %795 = torch.aten.mul.Tensor %794, %793 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_987 = torch.constant.int 1
    %int256_988 = torch.constant.int 256
    %int512_989 = torch.constant.int 512
    %int512_990 = torch.constant.int 512
    %796 = torch.prim.ListConstruct %int1_987, %int256_988, %int512_989, %int512_990 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %797 = torch.aten.view %795, %796 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16>
    %798 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_991 = torch.constant.int 0
    %799 = torch.aten.unsqueeze %798, %int0_991 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_992 = torch.constant.int 2
    %800 = torch.aten.unsqueeze %799, %int2_992 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_993 = torch.constant.int 3
    %801 = torch.aten.unsqueeze %800, %int3_993 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16>
    %802 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_994 = torch.constant.int 0
    %803 = torch.aten.unsqueeze %802, %int0_994 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_995 = torch.constant.int 2
    %804 = torch.aten.unsqueeze %803, %int2_995 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_996 = torch.constant.int 3
    %805 = torch.aten.unsqueeze %804, %int3_996 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %806 = torch.aten.mul.Tensor %797, %805 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_997 = torch.constant.int 1
    %807 = torch.aten.add.Tensor %806, %801, %int1_997 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_998 = torch.constant.int 5
    %808 = torch.prims.convert_element_type %807, %int5_998 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %809 = torch.aten.silu %808 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16>
    %810 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16>
    %811 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_999 = torch.constant.int 1
    %int1_1000 = torch.constant.int 1
    %812 = torch.prim.ListConstruct %int1_999, %int1_1000 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1001 = torch.constant.int 1
    %int1_1002 = torch.constant.int 1
    %813 = torch.prim.ListConstruct %int1_1001, %int1_1002 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1003 = torch.constant.int 1
    %int1_1004 = torch.constant.int 1
    %814 = torch.prim.ListConstruct %int1_1003, %int1_1004 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1005 = torch.constant.bool false
    %int0_1006 = torch.constant.int 0
    %int0_1007 = torch.constant.int 0
    %815 = torch.prim.ListConstruct %int0_1006, %int0_1007 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1008 = torch.constant.int 1
    %816 = torch.aten.convolution %809, %810, %811, %812, %813, %814, %false_1005, %815, %int1_1008 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1009 = torch.constant.int 1
    %int32_1010 = torch.constant.int 32
    %int8_1011 = torch.constant.int 8
    %int262144_1012 = torch.constant.int 262144
    %817 = torch.prim.ListConstruct %int1_1009, %int32_1010, %int8_1011, %int262144_1012 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %818 = torch.aten.view %816, %817 : !torch.vtensor<[1,256,512,512],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,262144],f16>
    %int6_1013 = torch.constant.int 6
    %819 = torch.prims.convert_element_type %818, %int6_1013 : !torch.vtensor<[1,32,8,262144],f16>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %int2_1014 = torch.constant.int 2
    %int3_1015 = torch.constant.int 3
    %820 = torch.prim.ListConstruct %int2_1014, %int3_1015 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1016 = torch.constant.int 0
    %true_1017 = torch.constant.bool true
    %result0_1018, %result1_1019 = torch.aten.var_mean.correction %819, %820, %int0_1016, %true_1017 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1020 = torch.constant.float 9.9999999999999995E-7
    %int1_1021 = torch.constant.int 1
    %821 = torch.aten.add.Scalar %result0_1018, %float9.999990e-07_1020, %int1_1021 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %822 = torch.aten.rsqrt %821 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1022 = torch.constant.int 1
    %823 = torch.aten.sub.Tensor %818, %result1_1019, %int1_1022 : !torch.vtensor<[1,32,8,262144],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,262144],f32>
    %824 = torch.aten.mul.Tensor %823, %822 : !torch.vtensor<[1,32,8,262144],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,262144],f32>
    %int1_1023 = torch.constant.int 1
    %int256_1024 = torch.constant.int 256
    %int512_1025 = torch.constant.int 512
    %int512_1026 = torch.constant.int 512
    %825 = torch.prim.ListConstruct %int1_1023, %int256_1024, %int512_1025, %int512_1026 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %826 = torch.aten.view %824, %825 : !torch.vtensor<[1,32,8,262144],f32>, !torch.list<int> -> !torch.vtensor<[1,256,512,512],f32>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16>
    %827 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1027 = torch.constant.int 0
    %828 = torch.aten.unsqueeze %827, %int0_1027 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1028 = torch.constant.int 2
    %829 = torch.aten.unsqueeze %828, %int2_1028 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1029 = torch.constant.int 3
    %830 = torch.aten.unsqueeze %829, %int3_1029 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16>
    %831 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.norm2.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1030 = torch.constant.int 0
    %832 = torch.aten.unsqueeze %831, %int0_1030 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1031 = torch.constant.int 2
    %833 = torch.aten.unsqueeze %832, %int2_1031 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1032 = torch.constant.int 3
    %834 = torch.aten.unsqueeze %833, %int3_1032 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %835 = torch.aten.mul.Tensor %826, %834 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,512,512],f32>
    %int1_1033 = torch.constant.int 1
    %836 = torch.aten.add.Tensor %835, %830, %int1_1033 : !torch.vtensor<[1,256,512,512],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int5_1034 = torch.constant.int 5
    %837 = torch.prims.convert_element_type %836, %int5_1034 : !torch.vtensor<[1,256,512,512],f32>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %838 = torch.aten.silu %837 : !torch.vtensor<[1,256,512,512],f16> -> !torch.vtensor<[1,256,512,512],f16>
    %none_1035 = torch.constant.none
    %839 = torch.aten.clone %838, %none_1035 : !torch.vtensor<[1,256,512,512],f16>, !torch.none -> !torch.vtensor<[1,256,512,512],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16>
    %840 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16>
    %841 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.resnets.2.conv2.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1036 = torch.constant.int 1
    %int1_1037 = torch.constant.int 1
    %842 = torch.prim.ListConstruct %int1_1036, %int1_1037 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1038 = torch.constant.int 1
    %int1_1039 = torch.constant.int 1
    %843 = torch.prim.ListConstruct %int1_1038, %int1_1039 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1040 = torch.constant.int 1
    %int1_1041 = torch.constant.int 1
    %844 = torch.prim.ListConstruct %int1_1040, %int1_1041 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1042 = torch.constant.bool false
    %int0_1043 = torch.constant.int 0
    %int0_1044 = torch.constant.int 0
    %845 = torch.prim.ListConstruct %int0_1043, %int0_1044 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1045 = torch.constant.int 1
    %846 = torch.aten.convolution %839, %840, %841, %842, %843, %844, %false_1042, %845, %int1_1045 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %int1_1046 = torch.constant.int 1
    %847 = torch.aten.add.Tensor %787, %846, %int1_1046 : !torch.vtensor<[1,256,512,512],f16>, !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f16>
    %float1.000000e00_1047 = torch.constant.float 1.000000e+00
    %848 = torch.aten.div.Scalar %847, %float1.000000e00_1047 : !torch.vtensor<[1,256,512,512],f16>, !torch.float -> !torch.vtensor<[1,256,512,512],f16>
    %int6_1048 = torch.constant.int 6
    %849 = torch.prims.convert_element_type %848, %int6_1048 : !torch.vtensor<[1,256,512,512],f16>, !torch.int -> !torch.vtensor<[1,256,512,512],f32>
    %int1024 = torch.constant.int 1024
    %int6_1049 = torch.constant.int 6
    %none_1050 = torch.constant.none
    %cpu_1051 = torch.constant.device "cpu"
    %false_1052 = torch.constant.bool false
    %850 = torch.aten.arange %int1024, %int6_1049, %none_1050, %cpu_1051, %false_1052 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1053 = torch.constant.float 0.000000e+00
    %int1_1054 = torch.constant.int 1
    %851 = torch.aten.add.Scalar %850, %float0.000000e00_1053, %int1_1054 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1055 = torch.constant.float 5.000000e-01
    %852 = torch.aten.mul.Scalar %851, %float5.000000e-01_1055 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1056 = torch.constant.int 4
    %853 = torch.prims.convert_element_type %852, %int4_1056 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %int-1_1057 = torch.constant.int -1
    %854 = torch.aten.unsqueeze %853, %int-1_1057 : !torch.vtensor<[1024],si64>, !torch.int -> !torch.vtensor<[1024,1],si64>
    %int1024_1058 = torch.constant.int 1024
    %int6_1059 = torch.constant.int 6
    %none_1060 = torch.constant.none
    %cpu_1061 = torch.constant.device "cpu"
    %false_1062 = torch.constant.bool false
    %855 = torch.aten.arange %int1024_1058, %int6_1059, %none_1060, %cpu_1061, %false_1062 : !torch.int, !torch.int, !torch.none, !torch.Device, !torch.bool -> !torch.vtensor<[1024],f32>
    %float0.000000e00_1063 = torch.constant.float 0.000000e+00
    %int1_1064 = torch.constant.int 1
    %856 = torch.aten.add.Scalar %855, %float0.000000e00_1063, %int1_1064 : !torch.vtensor<[1024],f32>, !torch.float, !torch.int -> !torch.vtensor<[1024],f32>
    %float5.000000e-01_1065 = torch.constant.float 5.000000e-01
    %857 = torch.aten.mul.Scalar %856, %float5.000000e-01_1065 : !torch.vtensor<[1024],f32>, !torch.float -> !torch.vtensor<[1024],f32>
    %int4_1066 = torch.constant.int 4
    %858 = torch.prims.convert_element_type %857, %int4_1066 : !torch.vtensor<[1024],f32>, !torch.int -> !torch.vtensor<[1024],si64>
    %none_1067 = torch.constant.none
    %none_1068 = torch.constant.none
    %859 = torch.prim.ListConstruct %none_1067, %none_1068, %854, %858 : (!torch.none, !torch.none, !torch.vtensor<[1024,1],si64>, !torch.vtensor<[1024],si64>) -> !torch.list<optional<vtensor>>
    %860 = torch.aten.index.Tensor %849, %859 : !torch.vtensor<[1,256,512,512],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[1,256,1024,1024],f32>
    %int2_1069 = torch.constant.int 2
    %861 = torch.aten.clone %860, %int2_1069 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f32>
    %int5_1070 = torch.constant.int 5
    %862 = torch.prims.convert_element_type %861, %int5_1070 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight = util.global.load @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16>
    %863 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.weight : tensor<256x256x3x3xf16> -> !torch.vtensor<[256,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias = util.global.load @__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16>
    %864 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.2.upsamplers.0.conv.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int1_1071 = torch.constant.int 1
    %int1_1072 = torch.constant.int 1
    %865 = torch.prim.ListConstruct %int1_1071, %int1_1072 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1073 = torch.constant.int 1
    %int1_1074 = torch.constant.int 1
    %866 = torch.prim.ListConstruct %int1_1073, %int1_1074 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1075 = torch.constant.int 1
    %int1_1076 = torch.constant.int 1
    %867 = torch.prim.ListConstruct %int1_1075, %int1_1076 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1077 = torch.constant.bool false
    %int0_1078 = torch.constant.int 0
    %int0_1079 = torch.constant.int 0
    %868 = torch.prim.ListConstruct %int0_1078, %int0_1079 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1080 = torch.constant.int 1
    %869 = torch.aten.convolution %862, %863, %864, %865, %866, %867, %false_1077, %868, %int1_1080 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[256,256,3,3],f16>, !torch.vtensor<[256],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %int1_1081 = torch.constant.int 1
    %int32_1082 = torch.constant.int 32
    %int8_1083 = torch.constant.int 8
    %int1048576 = torch.constant.int 1048576
    %870 = torch.prim.ListConstruct %int1_1081, %int32_1082, %int8_1083, %int1048576 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %871 = torch.aten.view %869, %870 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,8,1048576],f16>
    %int6_1084 = torch.constant.int 6
    %872 = torch.prims.convert_element_type %871, %int6_1084 : !torch.vtensor<[1,32,8,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,8,1048576],f32>
    %int2_1085 = torch.constant.int 2
    %int3_1086 = torch.constant.int 3
    %873 = torch.prim.ListConstruct %int2_1085, %int3_1086 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1087 = torch.constant.int 0
    %true_1088 = torch.constant.bool true
    %result0_1089, %result1_1090 = torch.aten.var_mean.correction %872, %873, %int0_1087, %true_1088 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1091 = torch.constant.float 9.9999999999999995E-7
    %int1_1092 = torch.constant.int 1
    %874 = torch.aten.add.Scalar %result0_1089, %float9.999990e-07_1091, %int1_1092 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %875 = torch.aten.rsqrt %874 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1093 = torch.constant.int 1
    %876 = torch.aten.sub.Tensor %871, %result1_1090, %int1_1093 : !torch.vtensor<[1,32,8,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,8,1048576],f32>
    %877 = torch.aten.mul.Tensor %876, %875 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,8,1048576],f32>
    %int1_1094 = torch.constant.int 1
    %int256_1095 = torch.constant.int 256
    %int1024_1096 = torch.constant.int 1024
    %int1024_1097 = torch.constant.int 1024
    %878 = torch.prim.ListConstruct %int1_1094, %int256_1095, %int1024_1096, %int1024_1097 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %879 = torch.aten.view %877, %878 : !torch.vtensor<[1,32,8,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,256,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16>
    %880 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.bias : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1098 = torch.constant.int 0
    %881 = torch.aten.unsqueeze %880, %int0_1098 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1099 = torch.constant.int 2
    %882 = torch.aten.unsqueeze %881, %int2_1099 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1100 = torch.constant.int 3
    %883 = torch.aten.unsqueeze %882, %int3_1100 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16>
    %884 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm1.weight : tensor<256xf16> -> !torch.vtensor<[256],f16>
    %int0_1101 = torch.constant.int 0
    %885 = torch.aten.unsqueeze %884, %int0_1101 : !torch.vtensor<[256],f16>, !torch.int -> !torch.vtensor<[1,256],f16>
    %int2_1102 = torch.constant.int 2
    %886 = torch.aten.unsqueeze %885, %int2_1102 : !torch.vtensor<[1,256],f16>, !torch.int -> !torch.vtensor<[1,256,1],f16>
    %int3_1103 = torch.constant.int 3
    %887 = torch.aten.unsqueeze %886, %int3_1103 : !torch.vtensor<[1,256,1],f16>, !torch.int -> !torch.vtensor<[1,256,1,1],f16>
    %888 = torch.aten.mul.Tensor %879, %887 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16> -> !torch.vtensor<[1,256,1024,1024],f32>
    %int1_1104 = torch.constant.int 1
    %889 = torch.aten.add.Tensor %888, %883, %int1_1104 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.vtensor<[1,256,1,1],f16>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f32>
    %int5_1105 = torch.constant.int 5
    %890 = torch.prims.convert_element_type %889, %int5_1105 : !torch.vtensor<[1,256,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,256,1024,1024],f16>
    %891 = torch.aten.silu %890 : !torch.vtensor<[1,256,1024,1024],f16> -> !torch.vtensor<[1,256,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16>
    %892 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.weight : tensor<128x256x3x3xf16> -> !torch.vtensor<[128,256,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16>
    %893 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1106 = torch.constant.int 1
    %int1_1107 = torch.constant.int 1
    %894 = torch.prim.ListConstruct %int1_1106, %int1_1107 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1108 = torch.constant.int 1
    %int1_1109 = torch.constant.int 1
    %895 = torch.prim.ListConstruct %int1_1108, %int1_1109 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1110 = torch.constant.int 1
    %int1_1111 = torch.constant.int 1
    %896 = torch.prim.ListConstruct %int1_1110, %int1_1111 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1112 = torch.constant.bool false
    %int0_1113 = torch.constant.int 0
    %int0_1114 = torch.constant.int 0
    %897 = torch.prim.ListConstruct %int0_1113, %int0_1114 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1115 = torch.constant.int 1
    %898 = torch.aten.convolution %891, %892, %893, %894, %895, %896, %false_1112, %897, %int1_1115 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[128,256,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1116 = torch.constant.int 1
    %int32_1117 = torch.constant.int 32
    %int4_1118 = torch.constant.int 4
    %int1048576_1119 = torch.constant.int 1048576
    %899 = torch.prim.ListConstruct %int1_1116, %int32_1117, %int4_1118, %int1048576_1119 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %900 = torch.aten.view %898, %899 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1120 = torch.constant.int 6
    %901 = torch.prims.convert_element_type %900, %int6_1120 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1121 = torch.constant.int 2
    %int3_1122 = torch.constant.int 3
    %902 = torch.prim.ListConstruct %int2_1121, %int3_1122 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1123 = torch.constant.int 0
    %true_1124 = torch.constant.bool true
    %result0_1125, %result1_1126 = torch.aten.var_mean.correction %901, %902, %int0_1123, %true_1124 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1127 = torch.constant.float 9.9999999999999995E-7
    %int1_1128 = torch.constant.int 1
    %903 = torch.aten.add.Scalar %result0_1125, %float9.999990e-07_1127, %int1_1128 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %904 = torch.aten.rsqrt %903 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1129 = torch.constant.int 1
    %905 = torch.aten.sub.Tensor %900, %result1_1126, %int1_1129 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %906 = torch.aten.mul.Tensor %905, %904 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1130 = torch.constant.int 1
    %int128_1131 = torch.constant.int 128
    %int1024_1132 = torch.constant.int 1024
    %int1024_1133 = torch.constant.int 1024
    %907 = torch.prim.ListConstruct %int1_1130, %int128_1131, %int1024_1132, %int1024_1133 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %908 = torch.aten.view %906, %907 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16>
    %909 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1134 = torch.constant.int 0
    %910 = torch.aten.unsqueeze %909, %int0_1134 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1135 = torch.constant.int 2
    %911 = torch.aten.unsqueeze %910, %int2_1135 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1136 = torch.constant.int 3
    %912 = torch.aten.unsqueeze %911, %int3_1136 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16>
    %913 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1137 = torch.constant.int 0
    %914 = torch.aten.unsqueeze %913, %int0_1137 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1138 = torch.constant.int 2
    %915 = torch.aten.unsqueeze %914, %int2_1138 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1139 = torch.constant.int 3
    %916 = torch.aten.unsqueeze %915, %int3_1139 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %917 = torch.aten.mul.Tensor %908, %916 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1140 = torch.constant.int 1
    %918 = torch.aten.add.Tensor %917, %912, %int1_1140 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1141 = torch.constant.int 5
    %919 = torch.prims.convert_element_type %918, %int5_1141 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %920 = torch.aten.silu %919 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1142 = torch.constant.none
    %921 = torch.aten.clone %920, %none_1142 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16>
    %922 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16>
    %923 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1143 = torch.constant.int 1
    %int1_1144 = torch.constant.int 1
    %924 = torch.prim.ListConstruct %int1_1143, %int1_1144 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1145 = torch.constant.int 1
    %int1_1146 = torch.constant.int 1
    %925 = torch.prim.ListConstruct %int1_1145, %int1_1146 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1147 = torch.constant.int 1
    %int1_1148 = torch.constant.int 1
    %926 = torch.prim.ListConstruct %int1_1147, %int1_1148 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1149 = torch.constant.bool false
    %int0_1150 = torch.constant.int 0
    %int0_1151 = torch.constant.int 0
    %927 = torch.prim.ListConstruct %int0_1150, %int0_1151 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1152 = torch.constant.int 1
    %928 = torch.aten.convolution %921, %922, %923, %924, %925, %926, %false_1149, %927, %int1_1152 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16>
    %929 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.weight : tensor<128x256x1x1xf16> -> !torch.vtensor<[128,256,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16>
    %930 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.0.conv_shortcut.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1153 = torch.constant.int 1
    %int1_1154 = torch.constant.int 1
    %931 = torch.prim.ListConstruct %int1_1153, %int1_1154 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1155 = torch.constant.int 0
    %int0_1156 = torch.constant.int 0
    %932 = torch.prim.ListConstruct %int0_1155, %int0_1156 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1157 = torch.constant.int 1
    %int1_1158 = torch.constant.int 1
    %933 = torch.prim.ListConstruct %int1_1157, %int1_1158 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1159 = torch.constant.bool false
    %int0_1160 = torch.constant.int 0
    %int0_1161 = torch.constant.int 0
    %934 = torch.prim.ListConstruct %int0_1160, %int0_1161 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1162 = torch.constant.int 1
    %935 = torch.aten.convolution %869, %929, %930, %931, %932, %933, %false_1159, %934, %int1_1162 : !torch.vtensor<[1,256,1024,1024],f16>, !torch.vtensor<[128,256,1,1],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1163 = torch.constant.int 1
    %936 = torch.aten.add.Tensor %935, %928, %int1_1163 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1164 = torch.constant.float 1.000000e+00
    %937 = torch.aten.div.Scalar %936, %float1.000000e00_1164 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1165 = torch.constant.int 1
    %int32_1166 = torch.constant.int 32
    %int4_1167 = torch.constant.int 4
    %int1048576_1168 = torch.constant.int 1048576
    %938 = torch.prim.ListConstruct %int1_1165, %int32_1166, %int4_1167, %int1048576_1168 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %939 = torch.aten.view %937, %938 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1169 = torch.constant.int 6
    %940 = torch.prims.convert_element_type %939, %int6_1169 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1170 = torch.constant.int 2
    %int3_1171 = torch.constant.int 3
    %941 = torch.prim.ListConstruct %int2_1170, %int3_1171 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1172 = torch.constant.int 0
    %true_1173 = torch.constant.bool true
    %result0_1174, %result1_1175 = torch.aten.var_mean.correction %940, %941, %int0_1172, %true_1173 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1176 = torch.constant.float 9.9999999999999995E-7
    %int1_1177 = torch.constant.int 1
    %942 = torch.aten.add.Scalar %result0_1174, %float9.999990e-07_1176, %int1_1177 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %943 = torch.aten.rsqrt %942 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1178 = torch.constant.int 1
    %944 = torch.aten.sub.Tensor %939, %result1_1175, %int1_1178 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %945 = torch.aten.mul.Tensor %944, %943 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1179 = torch.constant.int 1
    %int128_1180 = torch.constant.int 128
    %int1024_1181 = torch.constant.int 1024
    %int1024_1182 = torch.constant.int 1024
    %946 = torch.prim.ListConstruct %int1_1179, %int128_1180, %int1024_1181, %int1024_1182 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %947 = torch.aten.view %945, %946 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16>
    %948 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1183 = torch.constant.int 0
    %949 = torch.aten.unsqueeze %948, %int0_1183 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1184 = torch.constant.int 2
    %950 = torch.aten.unsqueeze %949, %int2_1184 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1185 = torch.constant.int 3
    %951 = torch.aten.unsqueeze %950, %int3_1185 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16>
    %952 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1186 = torch.constant.int 0
    %953 = torch.aten.unsqueeze %952, %int0_1186 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1187 = torch.constant.int 2
    %954 = torch.aten.unsqueeze %953, %int2_1187 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1188 = torch.constant.int 3
    %955 = torch.aten.unsqueeze %954, %int3_1188 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %956 = torch.aten.mul.Tensor %947, %955 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1189 = torch.constant.int 1
    %957 = torch.aten.add.Tensor %956, %951, %int1_1189 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1190 = torch.constant.int 5
    %958 = torch.prims.convert_element_type %957, %int5_1190 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %959 = torch.aten.silu %958 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16>
    %960 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16>
    %961 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1191 = torch.constant.int 1
    %int1_1192 = torch.constant.int 1
    %962 = torch.prim.ListConstruct %int1_1191, %int1_1192 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1193 = torch.constant.int 1
    %int1_1194 = torch.constant.int 1
    %963 = torch.prim.ListConstruct %int1_1193, %int1_1194 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1195 = torch.constant.int 1
    %int1_1196 = torch.constant.int 1
    %964 = torch.prim.ListConstruct %int1_1195, %int1_1196 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1197 = torch.constant.bool false
    %int0_1198 = torch.constant.int 0
    %int0_1199 = torch.constant.int 0
    %965 = torch.prim.ListConstruct %int0_1198, %int0_1199 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1200 = torch.constant.int 1
    %966 = torch.aten.convolution %959, %960, %961, %962, %963, %964, %false_1197, %965, %int1_1200 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1201 = torch.constant.int 1
    %int32_1202 = torch.constant.int 32
    %int4_1203 = torch.constant.int 4
    %int1048576_1204 = torch.constant.int 1048576
    %967 = torch.prim.ListConstruct %int1_1201, %int32_1202, %int4_1203, %int1048576_1204 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %968 = torch.aten.view %966, %967 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1205 = torch.constant.int 6
    %969 = torch.prims.convert_element_type %968, %int6_1205 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1206 = torch.constant.int 2
    %int3_1207 = torch.constant.int 3
    %970 = torch.prim.ListConstruct %int2_1206, %int3_1207 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1208 = torch.constant.int 0
    %true_1209 = torch.constant.bool true
    %result0_1210, %result1_1211 = torch.aten.var_mean.correction %969, %970, %int0_1208, %true_1209 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1212 = torch.constant.float 9.9999999999999995E-7
    %int1_1213 = torch.constant.int 1
    %971 = torch.aten.add.Scalar %result0_1210, %float9.999990e-07_1212, %int1_1213 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %972 = torch.aten.rsqrt %971 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1214 = torch.constant.int 1
    %973 = torch.aten.sub.Tensor %968, %result1_1211, %int1_1214 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %974 = torch.aten.mul.Tensor %973, %972 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1215 = torch.constant.int 1
    %int128_1216 = torch.constant.int 128
    %int1024_1217 = torch.constant.int 1024
    %int1024_1218 = torch.constant.int 1024
    %975 = torch.prim.ListConstruct %int1_1215, %int128_1216, %int1024_1217, %int1024_1218 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %976 = torch.aten.view %974, %975 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16>
    %977 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1219 = torch.constant.int 0
    %978 = torch.aten.unsqueeze %977, %int0_1219 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1220 = torch.constant.int 2
    %979 = torch.aten.unsqueeze %978, %int2_1220 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1221 = torch.constant.int 3
    %980 = torch.aten.unsqueeze %979, %int3_1221 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16>
    %981 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1222 = torch.constant.int 0
    %982 = torch.aten.unsqueeze %981, %int0_1222 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1223 = torch.constant.int 2
    %983 = torch.aten.unsqueeze %982, %int2_1223 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1224 = torch.constant.int 3
    %984 = torch.aten.unsqueeze %983, %int3_1224 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %985 = torch.aten.mul.Tensor %976, %984 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1225 = torch.constant.int 1
    %986 = torch.aten.add.Tensor %985, %980, %int1_1225 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1226 = torch.constant.int 5
    %987 = torch.prims.convert_element_type %986, %int5_1226 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %988 = torch.aten.silu %987 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1227 = torch.constant.none
    %989 = torch.aten.clone %988, %none_1227 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16>
    %990 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16>
    %991 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.1.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1228 = torch.constant.int 1
    %int1_1229 = torch.constant.int 1
    %992 = torch.prim.ListConstruct %int1_1228, %int1_1229 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1230 = torch.constant.int 1
    %int1_1231 = torch.constant.int 1
    %993 = torch.prim.ListConstruct %int1_1230, %int1_1231 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1232 = torch.constant.int 1
    %int1_1233 = torch.constant.int 1
    %994 = torch.prim.ListConstruct %int1_1232, %int1_1233 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1234 = torch.constant.bool false
    %int0_1235 = torch.constant.int 0
    %int0_1236 = torch.constant.int 0
    %995 = torch.prim.ListConstruct %int0_1235, %int0_1236 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1237 = torch.constant.int 1
    %996 = torch.aten.convolution %989, %990, %991, %992, %993, %994, %false_1234, %995, %int1_1237 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1238 = torch.constant.int 1
    %997 = torch.aten.add.Tensor %937, %996, %int1_1238 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1239 = torch.constant.float 1.000000e+00
    %998 = torch.aten.div.Scalar %997, %float1.000000e00_1239 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1240 = torch.constant.int 1
    %int32_1241 = torch.constant.int 32
    %int4_1242 = torch.constant.int 4
    %int1048576_1243 = torch.constant.int 1048576
    %999 = torch.prim.ListConstruct %int1_1240, %int32_1241, %int4_1242, %int1048576_1243 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1000 = torch.aten.view %998, %999 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1244 = torch.constant.int 6
    %1001 = torch.prims.convert_element_type %1000, %int6_1244 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1245 = torch.constant.int 2
    %int3_1246 = torch.constant.int 3
    %1002 = torch.prim.ListConstruct %int2_1245, %int3_1246 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1247 = torch.constant.int 0
    %true_1248 = torch.constant.bool true
    %result0_1249, %result1_1250 = torch.aten.var_mean.correction %1001, %1002, %int0_1247, %true_1248 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1251 = torch.constant.float 9.9999999999999995E-7
    %int1_1252 = torch.constant.int 1
    %1003 = torch.aten.add.Scalar %result0_1249, %float9.999990e-07_1251, %int1_1252 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1004 = torch.aten.rsqrt %1003 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1253 = torch.constant.int 1
    %1005 = torch.aten.sub.Tensor %1000, %result1_1250, %int1_1253 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1006 = torch.aten.mul.Tensor %1005, %1004 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1254 = torch.constant.int 1
    %int128_1255 = torch.constant.int 128
    %int1024_1256 = torch.constant.int 1024
    %int1024_1257 = torch.constant.int 1024
    %1007 = torch.prim.ListConstruct %int1_1254, %int128_1255, %int1024_1256, %int1024_1257 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1008 = torch.aten.view %1006, %1007 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16>
    %1009 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1258 = torch.constant.int 0
    %1010 = torch.aten.unsqueeze %1009, %int0_1258 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1259 = torch.constant.int 2
    %1011 = torch.aten.unsqueeze %1010, %int2_1259 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1260 = torch.constant.int 3
    %1012 = torch.aten.unsqueeze %1011, %int3_1260 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16>
    %1013 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm1.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1261 = torch.constant.int 0
    %1014 = torch.aten.unsqueeze %1013, %int0_1261 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1262 = torch.constant.int 2
    %1015 = torch.aten.unsqueeze %1014, %int2_1262 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1263 = torch.constant.int 3
    %1016 = torch.aten.unsqueeze %1015, %int3_1263 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1017 = torch.aten.mul.Tensor %1008, %1016 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1264 = torch.constant.int 1
    %1018 = torch.aten.add.Tensor %1017, %1012, %int1_1264 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1265 = torch.constant.int 5
    %1019 = torch.prims.convert_element_type %1018, %int5_1265 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %1020 = torch.aten.silu %1019 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16>
    %1021 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16>
    %1022 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv1.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1266 = torch.constant.int 1
    %int1_1267 = torch.constant.int 1
    %1023 = torch.prim.ListConstruct %int1_1266, %int1_1267 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1268 = torch.constant.int 1
    %int1_1269 = torch.constant.int 1
    %1024 = torch.prim.ListConstruct %int1_1268, %int1_1269 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1270 = torch.constant.int 1
    %int1_1271 = torch.constant.int 1
    %1025 = torch.prim.ListConstruct %int1_1270, %int1_1271 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1272 = torch.constant.bool false
    %int0_1273 = torch.constant.int 0
    %int0_1274 = torch.constant.int 0
    %1026 = torch.prim.ListConstruct %int0_1273, %int0_1274 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1275 = torch.constant.int 1
    %1027 = torch.aten.convolution %1020, %1021, %1022, %1023, %1024, %1025, %false_1272, %1026, %int1_1275 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1276 = torch.constant.int 1
    %int32_1277 = torch.constant.int 32
    %int4_1278 = torch.constant.int 4
    %int1048576_1279 = torch.constant.int 1048576
    %1028 = torch.prim.ListConstruct %int1_1276, %int32_1277, %int4_1278, %int1048576_1279 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1029 = torch.aten.view %1027, %1028 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1280 = torch.constant.int 6
    %1030 = torch.prims.convert_element_type %1029, %int6_1280 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1281 = torch.constant.int 2
    %int3_1282 = torch.constant.int 3
    %1031 = torch.prim.ListConstruct %int2_1281, %int3_1282 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1283 = torch.constant.int 0
    %true_1284 = torch.constant.bool true
    %result0_1285, %result1_1286 = torch.aten.var_mean.correction %1030, %1031, %int0_1283, %true_1284 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1287 = torch.constant.float 9.9999999999999995E-7
    %int1_1288 = torch.constant.int 1
    %1032 = torch.aten.add.Scalar %result0_1285, %float9.999990e-07_1287, %int1_1288 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1033 = torch.aten.rsqrt %1032 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1289 = torch.constant.int 1
    %1034 = torch.aten.sub.Tensor %1029, %result1_1286, %int1_1289 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1035 = torch.aten.mul.Tensor %1034, %1033 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1290 = torch.constant.int 1
    %int128_1291 = torch.constant.int 128
    %int1024_1292 = torch.constant.int 1024
    %int1024_1293 = torch.constant.int 1024
    %1036 = torch.prim.ListConstruct %int1_1290, %int128_1291, %int1024_1292, %int1024_1293 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1037 = torch.aten.view %1035, %1036 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16>
    %1038 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1294 = torch.constant.int 0
    %1039 = torch.aten.unsqueeze %1038, %int0_1294 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1295 = torch.constant.int 2
    %1040 = torch.aten.unsqueeze %1039, %int2_1295 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1296 = torch.constant.int 3
    %1041 = torch.aten.unsqueeze %1040, %int3_1296 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16>
    %1042 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.norm2.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1297 = torch.constant.int 0
    %1043 = torch.aten.unsqueeze %1042, %int0_1297 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1298 = torch.constant.int 2
    %1044 = torch.aten.unsqueeze %1043, %int2_1298 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1299 = torch.constant.int 3
    %1045 = torch.aten.unsqueeze %1044, %int3_1299 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1046 = torch.aten.mul.Tensor %1037, %1045 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1300 = torch.constant.int 1
    %1047 = torch.aten.add.Tensor %1046, %1041, %int1_1300 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1301 = torch.constant.int 5
    %1048 = torch.prims.convert_element_type %1047, %int5_1301 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %1049 = torch.aten.silu %1048 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %none_1302 = torch.constant.none
    %1050 = torch.aten.clone %1049, %none_1302 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.none -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16>
    %1051 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.weight : tensor<128x128x3x3xf16> -> !torch.vtensor<[128,128,3,3],f16>
    %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias = util.global.load @__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16>
    %1052 = torch_c.from_builtin_tensor %__auto.vae.decoder.up_blocks.3.resnets.2.conv2.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int1_1303 = torch.constant.int 1
    %int1_1304 = torch.constant.int 1
    %1053 = torch.prim.ListConstruct %int1_1303, %int1_1304 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1305 = torch.constant.int 1
    %int1_1306 = torch.constant.int 1
    %1054 = torch.prim.ListConstruct %int1_1305, %int1_1306 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1307 = torch.constant.int 1
    %int1_1308 = torch.constant.int 1
    %1055 = torch.prim.ListConstruct %int1_1307, %int1_1308 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1309 = torch.constant.bool false
    %int0_1310 = torch.constant.int 0
    %int0_1311 = torch.constant.int 0
    %1056 = torch.prim.ListConstruct %int0_1310, %int0_1311 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1312 = torch.constant.int 1
    %1057 = torch.aten.convolution %1050, %1051, %1052, %1053, %1054, %1055, %false_1309, %1056, %int1_1312 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[128,128,3,3],f16>, !torch.vtensor<[128],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1313 = torch.constant.int 1
    %1058 = torch.aten.add.Tensor %998, %1057, %int1_1313 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[1,128,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %float1.000000e00_1314 = torch.constant.float 1.000000e+00
    %1059 = torch.aten.div.Scalar %1058, %float1.000000e00_1314 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.float -> !torch.vtensor<[1,128,1024,1024],f16>
    %int1_1315 = torch.constant.int 1
    %int32_1316 = torch.constant.int 32
    %int4_1317 = torch.constant.int 4
    %int1048576_1318 = torch.constant.int 1048576
    %1060 = torch.prim.ListConstruct %int1_1315, %int32_1316, %int4_1317, %int1048576_1318 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1061 = torch.aten.view %1059, %1060 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.list<int> -> !torch.vtensor<[1,32,4,1048576],f16>
    %int6_1319 = torch.constant.int 6
    %1062 = torch.prims.convert_element_type %1061, %int6_1319 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %int2_1320 = torch.constant.int 2
    %int3_1321 = torch.constant.int 3
    %1063 = torch.prim.ListConstruct %int2_1320, %int3_1321 : (!torch.int, !torch.int) -> !torch.list<int>
    %int0_1322 = torch.constant.int 0
    %true_1323 = torch.constant.bool true
    %result0_1324, %result1_1325 = torch.aten.var_mean.correction %1062, %1063, %int0_1322, %true_1323 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int>, !torch.int, !torch.bool -> !torch.vtensor<[1,32,1,1],f32>, !torch.vtensor<[1,32,1,1],f32>
    %float9.999990e-07_1326 = torch.constant.float 9.9999999999999995E-7
    %int1_1327 = torch.constant.int 1
    %1064 = torch.aten.add.Scalar %result0_1324, %float9.999990e-07_1326, %int1_1327 : !torch.vtensor<[1,32,1,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,32,1,1],f32>
    %1065 = torch.aten.rsqrt %1064 : !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,1,1],f32>
    %int1_1328 = torch.constant.int 1
    %1066 = torch.aten.sub.Tensor %1061, %result1_1325, %int1_1328 : !torch.vtensor<[1,32,4,1048576],f16>, !torch.vtensor<[1,32,1,1],f32>, !torch.int -> !torch.vtensor<[1,32,4,1048576],f32>
    %1067 = torch.aten.mul.Tensor %1066, %1065 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.vtensor<[1,32,1,1],f32> -> !torch.vtensor<[1,32,4,1048576],f32>
    %int1_1329 = torch.constant.int 1
    %int128_1330 = torch.constant.int 128
    %int1024_1331 = torch.constant.int 1024
    %int1024_1332 = torch.constant.int 1024
    %1068 = torch.prim.ListConstruct %int1_1329, %int128_1330, %int1024_1331, %int1024_1332 : (!torch.int, !torch.int, !torch.int, !torch.int) -> !torch.list<int>
    %1069 = torch.aten.view %1067, %1068 : !torch.vtensor<[1,32,4,1048576],f32>, !torch.list<int> -> !torch.vtensor<[1,128,1024,1024],f32>
    %__auto.vae.decoder.conv_norm_out.bias = util.global.load @__auto.vae.decoder.conv_norm_out.bias : tensor<128xf16>
    %1070 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_norm_out.bias : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1333 = torch.constant.int 0
    %1071 = torch.aten.unsqueeze %1070, %int0_1333 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1334 = torch.constant.int 2
    %1072 = torch.aten.unsqueeze %1071, %int2_1334 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1335 = torch.constant.int 3
    %1073 = torch.aten.unsqueeze %1072, %int3_1335 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %__auto.vae.decoder.conv_norm_out.weight = util.global.load @__auto.vae.decoder.conv_norm_out.weight : tensor<128xf16>
    %1074 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_norm_out.weight : tensor<128xf16> -> !torch.vtensor<[128],f16>
    %int0_1336 = torch.constant.int 0
    %1075 = torch.aten.unsqueeze %1074, %int0_1336 : !torch.vtensor<[128],f16>, !torch.int -> !torch.vtensor<[1,128],f16>
    %int2_1337 = torch.constant.int 2
    %1076 = torch.aten.unsqueeze %1075, %int2_1337 : !torch.vtensor<[1,128],f16>, !torch.int -> !torch.vtensor<[1,128,1],f16>
    %int3_1338 = torch.constant.int 3
    %1077 = torch.aten.unsqueeze %1076, %int3_1338 : !torch.vtensor<[1,128,1],f16>, !torch.int -> !torch.vtensor<[1,128,1,1],f16>
    %1078 = torch.aten.mul.Tensor %1069, %1077 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16> -> !torch.vtensor<[1,128,1024,1024],f32>
    %int1_1339 = torch.constant.int 1
    %1079 = torch.aten.add.Tensor %1078, %1073, %int1_1339 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.vtensor<[1,128,1,1],f16>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f32>
    %int5_1340 = torch.constant.int 5
    %1080 = torch.prims.convert_element_type %1079, %int5_1340 : !torch.vtensor<[1,128,1024,1024],f32>, !torch.int -> !torch.vtensor<[1,128,1024,1024],f16>
    %1081 = torch.aten.silu %1080 : !torch.vtensor<[1,128,1024,1024],f16> -> !torch.vtensor<[1,128,1024,1024],f16>
    %__auto.vae.decoder.conv_out.weight = util.global.load @__auto.vae.decoder.conv_out.weight : tensor<3x128x3x3xf16>
    %1082 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_out.weight : tensor<3x128x3x3xf16> -> !torch.vtensor<[3,128,3,3],f16>
    %__auto.vae.decoder.conv_out.bias = util.global.load @__auto.vae.decoder.conv_out.bias : tensor<3xf16>
    %1083 = torch_c.from_builtin_tensor %__auto.vae.decoder.conv_out.bias : tensor<3xf16> -> !torch.vtensor<[3],f16>
    %int1_1341 = torch.constant.int 1
    %int1_1342 = torch.constant.int 1
    %1084 = torch.prim.ListConstruct %int1_1341, %int1_1342 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1343 = torch.constant.int 1
    %int1_1344 = torch.constant.int 1
    %1085 = torch.prim.ListConstruct %int1_1343, %int1_1344 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1345 = torch.constant.int 1
    %int1_1346 = torch.constant.int 1
    %1086 = torch.prim.ListConstruct %int1_1345, %int1_1346 : (!torch.int, !torch.int) -> !torch.list<int>
    %false_1347 = torch.constant.bool false
    %int0_1348 = torch.constant.int 0
    %int0_1349 = torch.constant.int 0
    %1087 = torch.prim.ListConstruct %int0_1348, %int0_1349 : (!torch.int, !torch.int) -> !torch.list<int>
    %int1_1350 = torch.constant.int 1
    %1088 = torch.aten.convolution %1081, %1082, %1083, %1084, %1085, %1086, %false_1347, %1087, %int1_1350 : !torch.vtensor<[1,128,1024,1024],f16>, !torch.vtensor<[3,128,3,3],f16>, !torch.vtensor<[3],f16>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %int2_1351 = torch.constant.int 2
    %1089 = torch.aten.div.Scalar %1088, %int2_1351 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %float5.000000e-01_1352 = torch.constant.float 5.000000e-01
    %int1_1353 = torch.constant.int 1
    %1090 = torch.aten.add.Scalar %1089, %float5.000000e-01_1352, %int1_1353 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.float, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    %int0_1354 = torch.constant.int 0
    %int1_1355 = torch.constant.int 1
    %1091 = torch.aten.clamp %1090, %int0_1354, %int1_1355 : !torch.vtensor<[1,3,1024,1024],f16>, !torch.int, !torch.int -> !torch.vtensor<[1,3,1024,1024],f16>
    return %1091 : !torch.vtensor<[1,3,1024,1024],f16>
  }
}
